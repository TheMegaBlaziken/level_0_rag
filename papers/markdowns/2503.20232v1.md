# Learnable Sequence Augmenter for Triplet Contrastive Learning in Sequential Recommendation

## [WEI WANG](https://orcid.org/0000-0002-7080-3381)

202120421@mail.sdu.edu.cn School of Information Science and Engineering, Shandong University QingDao, CHINA

## [Zhumin Chen](https://orcid.org/0000-0003-4592-4074)

chenzhumin@sdu.edu.cn School of Computer Science and Technology, Shandong University QingDao, CHINA

[Yujie Lin](https://orcid.org/0000-0002-2146-0626)

yu.jie.lin@outlook.com Zhejiang Lab Hangzhou, CHINA

# [Jianli Zhao](https://orcid.org/0000-0002-7291-9003)

jlzhao@sdust.edu.cn School of Computer Science and Engineering, Shandong University of Science and Technology QingDao, CHINA

# [Pengjie Ren](https://orcid.org/0000-0003-2964-6422)

renpengjie@sdu.edu.cn School of Computer Science and Technology, Shandong University QingDao, CHINA

## [Moyan Zhang](https://orcid.org/0000-0001-6130-1286)

zmy20001122@163.com School of Information Science and Engineering, Shandong University QingDao, CHINA

# [Xianye Ben](https://orcid.org/0000-0001-8083-3501)

benxianye@gmail.com School of Information Science and Engineering, Shandong University QingDao, CHINA

## [Yujun Li](https://orcid.org/0000-0003-4455-5991)

liyujun@sdu.edu.cn School of Information Science and Engineering, Shandong University QingDao, CHINA

# Abstract

Most existing contrastive learning-based sequential recommendation (SR) methods rely on random operations (e.g., crop, reorder, and substitute) to generate augmented sequences. These methods often struggle to create positive sample pairs that closely resemble the representations of the raw sequences, potentially disrupting item correlations by deleting key items or introducing noisy iterac, which misguides the contrastive learning process.

To address this limitation, we propose Learnable sequence Augmentor for triplet Contrastive Learning in sequential Recommendation (LACLRec). Specifically, the self-supervised learning-based augmenter can automatically delete noisy items from sequences and insert new items that better capture item transition patterns, generating a higher-quality augmented sequence. Subsequently, we randomly generate another augmented sequence and design a ranking-based

, ,

ACM ISBN XXXXXXXXXXXX <https://doi.org/XXXXXXX.XXXXXXX> triplet contrastive loss to differentiate the similarities between the raw sequence, the augmented sequence from augmenter, and the randomly augmented sequence, providing more fine-grained contrastive signals. Extensive experiments on three real-world datasets demonstrate that both the sequence augmenter and the triplet contrast contribute to improving recommendation accuracy. LACLRec significantly outperforms the baseline model CL4SRec, and demonstrates superior performance compared to several state-of-the-art sequential recommendation algorithms.

## CCS Concepts: • Information systems → Recommender systems.

Keywords: Sequential recommendation, Contrastive learning, Self-supervised learning

## ACM Reference Format:

WEI WANG, Yujie Lin, Pengjie Ren, Zhumin Chen, Jianli Zhao, Moyan Zhang, Xianye Ben, and Yujun Li. 2024. Learnable Sequence Augmenter for Triplet Contrastive Learning in Sequential Recommendation . In Proceedings of . ACM, New York, NY, USA, [12](#page-11-0) pages. <https://doi.org/XXXXXXX.XXXXXXX>

# 1 INTRODUCTION

Sequential recommendation (SR) [\[4,](#page-9-0) [29,](#page-10-0) [30,](#page-10-1) [35,](#page-10-2) [38\]](#page-11-1), which predicts user preferences based on their historical interactions, has garnered increased attention in recent recommendations studies. SR algorithms account for the temporal and sequential order of user behavior, capturing the transfer relationship between items, so as to recommend the next item for users according to the ordered interaction records over a period of time. Recently, self-supervised learning (SSL) has been

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

<sup>©</sup> 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.

introduced to sequential recommendation for extracting robust item correlations by semi-automatically exploiting raw item sequences [\[16,](#page-10-3) [18,](#page-10-4) [33,](#page-10-5) [43\]](#page-11-2). Despite their effectiveness, sequential recommendation systems face notable challenges, including data sparsity and cold-start.

As an important branch of SSL, contrastive learning (CL) has been introduced into recommendation systems [\[25,](#page-10-6) [44,](#page-11-3) [49,](#page-11-4) [50\]](#page-11-5) in recent years. Contrastive learning in recommendation systems mainly consists of two parts: constructing augmented data from the original user interaction data for training, and designing contrastive loss to provide additional supervisory signals [\[48\]](#page-11-6). The specific approach maximizes the similarity between positive pairs (augmented data from the same source) while improving discrimination ability to the negatives samples. Contrastive learning effectively alleviates the data sparsity and cold-start problems in recommendation systems, and CL-based models [\[10,](#page-10-7) [20,](#page-10-8) [26,](#page-10-9) [37\]](#page-11-7) have demonstrated more competitive recommendation performance.

<span id="page-1-0"></span>![](_page_1_Figure_3.jpeg)

**Caption:** Figure 1 illustrates the triplet contrastive learning framework employed in LACLRec. It highlights the relationships between the raw sequence, the SSL-augmented sequence, and the randomly augmented sequence, emphasizing the goal of maximizing similarity between the raw and SSL-augmented sequences while minimizing it with the random sequence. This approach enhances the model's ability to capture item transition correlations effectively.

Figure 1. Illustration of triplet contrastive learning.

However, existing CL-based sequential recommendation methods still have the following shortcomings: (1) Most models such as CL4SRec [\[34\]](#page-10-10) adopt random data augmentation to generate contrastive sequences, where mask and crop operations may delete key items and further amplify the data sparsity problem, and the reorder operation significantly disrupts the item transition correlations in the raw sequence. Moreover, the two contrastive sequences generated by the random method may be overly similar. (2) Although other works such as CoSeRec [\[17\]](#page-10-11) and TiCoSeRec[\[3\]](#page-9-1) adopt SSL to perform substitute and insertion operations, they randomly select items to modify from the raw sequence, which still carries a high probability of deleting key items. (3) Real-world sequences may contain some noisy interactions (such as promotions), leading to negative feedback. Existing augmentation methods are not effective in deleting such noise. (4) Finally, the above works treat the two augmented sequences equally, and the raw sequence is not directly considered in the contrastive loss, leading to a lack of more fine-grained supervisory signals.

To address the aforementioned issues, we propose a triplet contrastive learning framework for sequential recommendation with a learnable sequence augmenter (LACLRec). Unlike existing methods, we utilize a trained SSL-augmenter to generate augmented sequence from the raw sequence (referred to as SSL-augmented sequence) and consider the differences in representation similarity among the SSL-augmented sequence, random augmented sequence, and the raw sequence. Specifically, (1) We first disrupt the raw sequence by randomly deleting and inserting items, and the augmenter is trained to restore the disrupted sequence. This trained augmenter can automatically delete noise and insert new items, generating SSL-augmented sequence without manually designed heuristics. (2) Then, we take one SSL-augmented sequence and one random augmented sequence as positive pair, while using augmented sequences from other raw sequences as negative samples. By optimizing the contrastive loss , self-supervised signals are provided to the recommender. (3) Compared to random augmented sequence, we find that SSL-augmented sequence enables the recommender to more accurately capture item transition correlations and predict the next interaction. Therefore, we design a triplet consisting of the raw sequence and its two augmented sequences, and introduce a BPR contrastive loss to maximize the similarity between the raw sequence and the SSL-augmented sequence, while minimizing the similarity between the raw sequence and the random augmented sequence. As shown in Figure [1,](#page-1-0) we aim to maximize the representational distance between different triplets, while within the triplet, the SSL-augmented sequence provides more positive feedback. Finally, we jointly optimize and , providing finergrained contrastive signals for model training. We conduct extensive experiments on three datasets, and LACLRec significantly outperforms the baseline model CL4SRec, with a single metric improving by up to 13.5%, demonstrating the effectiveness of the sequence augmenter and the triplet contrastive learning. LACLRec also outperforms several other state-of-the-art sequential recommendation models.

To sum up, the main contributions of this work are as follows:

- We propose a novel contrastive learning-based sequential recommendation framework (LACLRec), which incorporates a SSL sequence augmenter.
- The SSL-augmenter can automatically delete noise from raw sequence and insert new items, generating higher-quality augmented sequence.
- A ranking-based contrastive loss is designed to differentiate the representation similarities between the raw sequence, the randomly augmented sequence, and the SSL-augmented sequence, providing more fine-grained contrastive signals.

• We conduct extensive experiments to demonstrate the state-of-the-art performance of LACLRec. To facilitate reproducibility, we release the code and data at https://github.com/.

## 2 RELATED WORK

This section reviews contrastive learning (CL)-based recommendation systems, categorizing them into two types: research on data augmentation methods and research on contrastive learning-based recommendation framework.

#### 2.1 Data Augmentation Research

The main objective of contrastive learning is to maximize the similarity between positive samples while minimizing the similarity between positive and negative samples. Therefore, sampling positive and negative samples is a key challenge in contrastive learning. Many works have focused on developing better data augmentation methods to improve the performance of contrastive learning in recommendation systems.

Xie et al. [\[34\]](#page-10-10) propose CL4SRec, an early work that applies contrastive learning to sequential recommendation. They design random augmentation methods such as mask, crop, and reorder, which enhance the accuracy of sequential recommendations. Liu et al. [\[17\]](#page-10-11) introduce CoSeRec, which selects new items with the highest representation similarity and inserts or replaces them in the sequence at a predetermined ratio. Dang et al. [\[3\]](#page-9-1) advocate for sequence augmentation from a time interval perspective and improve upon CoSeRec by generating augmented sequences with uniform time intervals. Huang et al. [\[9\]](#page-10-12) propose a dual contrastive learning model that enhances both low-level (item) and high-level (item attribute) preference learning for users. Dai et al. [\[2\]](#page-9-2) design rule-based augmentation, replacing items in the sequence based on item attributes. Zhou et al. [\[47\]](#page-11-8) introduce equivariant contrastive learning, which makes user representations sensitive to intrusive augmentations (such as substitute) and robust to mild augmentations (such as mask). Zhang et al. [\[45\]](#page-11-9) introduce spatiotemporal frequency domain techniques from computer vision and design a data augmentation strategy to model users' interest trends. Chen et al. [\[1\]](#page-9-3) and Li et al. [\[15\]](#page-10-13) design intent contrastive learning frameworks, while Qin et al. [\[21\]](#page-10-14) segment the original sequence into multiple subsequences, assuming that different subsequences with the same target item represent the same intention. They use coarse-grained contrastive learning to put the two subsequences with the same intention closer.

Unlike the aforementioned studies, our LACLRec automatically deletes noise from the raw sequence and inserts new items to assist in learning item transition correlations, without relying on manual heuristics.

#### 2.2 CL-based Recommendation Framework

Other research has proposed various CL-based recommendation frameworks to improve different recommendation tasks. [\[6,](#page-9-4) [8,](#page-9-5) [11,](#page-10-15) [24,](#page-10-16) [28,](#page-10-17) [40,](#page-11-10) [42\]](#page-11-11) apply graph contrastive learning techniques to GNN-based recommendation and explore how to create more optimal contrastive views. Yang et al. [\[39\]](#page-11-12), Zou et al. [\[51\]](#page-11-13) introduce knowledge graph contrastive learning frameworks for recommendation. He et al. [\[7\]](#page-9-6) design two CL tasks for CTR (Click-Through Rate) prediction. [\[5,](#page-9-7) [13,](#page-10-18) [46\]](#page-11-14) propose CL-based next point-of-interest (POI) recommendation models, which aim to uncover users' latent preferences. Wang et al. [\[31\]](#page-10-19) identify a vulnerability in CL-based recommendation systems, noting that they are more susceptible to poisoning attacks designed to promote specific items. Ye et al. [\[41\]](#page-11-15) design a supervised contrastive learning framework to model relationships between sequences, facilitating crossdomain sequential recommendation. [\[23,](#page-10-20) [32,](#page-10-21) [36\]](#page-11-16) propose multi-behavior contrastive learning to distill transferable knowledge from users' different types of behaviors. Qiu et al. [\[22\]](#page-10-22) introduce contrastive regularization to reshape the distribution of sequence representations, preventing excessive semantic similarity among item embeddings.

Unlike the aforementioned works, we focus on the sequential recommendation task and explore finer-grained contrastive signals between augmented data and raw data, proposing a triplet contrastive learning framework.

## 3 PRELIMINARIES

#### 3.1 Sequential Recommender

We denote the set of users and items as and , the interaction sequence of user ∈ as = -1,2, . . . ,| <sup>|</sup> , where ∈ represents the item that user interacted with at the -th time step and | | represents the length of the sequence. The task of sequential recommender is to predict the user's next interaction item. We follow the baseline sequential recommendation framework SASRec [\[12\]](#page-10-23), mask the last position of the sequence and require the recommender to predict the item. The recommendation task is formulated as follows:

$$
\underset{i_t \in \mathcal{I}}{\arg \max} P\left(i_{|S_u|+1} = i_t \mid S_u\right),\tag{1}
$$

which selects the item from the candidate set that has the highest probability for recommendation.

## 3.2 Random Sequence Augmentation

In this paper, we select three random sequence augmentation methods from CL4SRec [\[34\]](#page-10-10) to generate a randomly augmented sequence for each raw sequence.

• Mask. We randomly mask | |items in the sequence according to a predefined ratio .

$$
S_u^M = [i_1, mask, i_3, mask, ..., i_{|S_u|}],
$$
 (2)

where denotes the masked sequence, denotes the masked item.

• Crop. We randomly select a position in the sequence and then crop a continuous subsequence of length | |.

$$
S_u^C = [i_c, i_{c+1}, \dots, i_{c+\eta|S_u|-1}], \qquad (3)
$$

where denotes the beginning position.

• Reorder. We randomly select a subsequence of length | | and shuffle its items.

$$
S_u^R = [i_1, i_2, \dots, i'_r, i'_{r+1}, \dots, i'_{r+\beta|S_u|-1}, \dots, i_{|S_u|}], \qquad (4)
$$

where <sup>h</sup> ′ , ′ +1 , . . . , ′ + | |−1 i denotes the shuffled subsequence.

When model training, we randomly select an augmentation method for each sequence at each epoch, and generate an augmentation sequence.

# 4 METHODS

## 4.1 Overview

As illustrated in Figure [2,](#page-4-0) LACLRec consists of four modules: a shared encoder, a self-supervised sequence augmenter, contrastive learning module, and a sequential recommender. During training, we use a Transformer-based encoder to encode the input sequence into embeddings, the encoder is shared between the augmenter and the recommender. The sequence augmenter then modifies the input sequence. It first determines the operation to perform on each position in : 'keep', 'delete', or 'insert'. For 'insert' operation, a reverse generator calculates the probability of each candidate item being inserted, and then a subsequence is inserted in reverse. This study does not consider 'substitute', as this can be achieved by 'delete' at the -th position and 'insert' at the next position. To train the augmenter, we randomly modify and require the augmenter to restore it through a self-supervised training task. Subsequently, for sequences in a batch, we adopt the trained augmenter to generate a SSL-augmented sequence 1 for each raw sequence, and generate another augmented sequence 2 by traditional random methods. In the contrastive learning module, we apply a coarse-grained contrastive loss to increase the representation similarity between positive pairs (the two augmented sequences derived from the same raw sequence) while reducing their similarity with the other 2 − 2 negative samples. Next, we design a finer-grained triplet contrastive loss to directly reduce the distance between the raw sequence and the SSL-augmented sequence, making the augmenter provides more self-supervised signals for recommendation compared to the random augmentation. Finally, the recommender is used to predict the user's next interaction. By jointly optimizing , , and the recommender loss , we improve the recommendation performance of LACLRec.

## 4.2 Sequence Encoder

The encoder is used to encode the input sequence into hidden representations, and it is shared by the augmenter and the recommender.

Specifically, we first define the item embedding matrix ∈ R | |× to project the representation of each item into a low-dimensional dense vector, where is the dimension of the embedding vector, denotes the number of candidate items. For an item in the input sequence , we index the embedding matrix to obtain its embedding vector: ∈ R , and inject position information to get its initial hidden representation ℎ 0 :

$$
h_t^0 = e_t + p_t,\tag{5}
$$

where represents the position embedding at the -th position. After stacking the initial representation vectors of all items, we get the initial representation matrix 0 ∈ R | |× .

We follow SASRec to update 0 by a Transformer [\[12,](#page-10-23) [34\]](#page-10-10) with layers:

$$
H_e^l = \text{Trm}\left(H_e^{l-1}\right),\tag{6}
$$

where Trm denotes a Transformer block, denotes the representation matrix at the -th layer. Finally, the encoder inputs the last layer of into the augmenter and recommender. We omit the superscript (i.e., ) in the following sections to simplify the notation.

## 4.3 SSL Sequence Augmenter

The self-supervised sequence augmenter is used to perform data augmentation on the input sequence. Considering two issues in real-world user interaction sequences: (1) Noisy interactions, where items in the sequence may not reflect true item relevance (e.g., promotions or group purchases for discounts), and (2) Data sparsity, where many items strongly related to user preferences are not interacted with by the user, we designed three augmentation operations: 'keep', 'delete', and 'insert'.

As shown in Figure 3, for an item in the sequence , the augmenter first calculates the probability distribution for the three operations and selects the operation with the highest probability. If the chosen operation is 'keep', the augmenter skips the item. If the operation is 'delete', the item is deleted. If the operation is 'insert', the augmenter uses a reverse generator to insert new items before . We follow Eq. [7](#page-3-0) to calculate the probability distribution of performing the three operations.

<span id="page-3-0"></span>
$$
P\left(\hat{o}_t \mid S\right) = \text{softmax}\left(Wh_t\right),\tag{7}
$$

where ℎ ∈ R is the representation of , ˆ denotes the predicted operation, ∈ R 3× is a projection matrix.

The augmenter applies a reverse generator to perform the insert operation. Unlike other data augmentation methods, we allow the insertion of a subsequence with a maximum length of at the selected position, rather than just a single item. The currently generated inserted sequence is denoted

<span id="page-4-0"></span>![](_page_4_Figure_1.jpeg)

**Caption:** Figure 2 provides an overview of the LACLRec architecture, detailing its four main components: a shared encoder, a self-supervised sequence augmenter, a contrastive learning module, and a sequential recommender. The figure illustrates how the augmenter modifies input sequences to generate augmented data, which is then utilized in the contrastive learning tasks to improve recommendation accuracy through enhanced item correlation learning.

Figure 2. Overview of LACLRec. When training augmenter, we require it to restore the random modified sequences. The augmented sequence 1 is generated by the augmenter, and 2 is generated by random methods. Two contrastive learning tasks are used to provide supervised signals for item correlations learning. Finally, the recommender predicts the next item.

as < 1:−1 . The augmenter first indexes the embedding vector of each item in < 1:−1 , then stacks the hidden representation ℎ and the embedding vector of each item in < 1:−1 , while adding the position embedding:

$$
H_c^0 = \begin{bmatrix} h_t + p_1 \\ e_1 + p_2 \\ \dots \\ e_{n-1} + p_n \end{bmatrix},
$$
 (8)

where 0 denotes the initial representation matrix of reverse generator. We also adopt dropout to 0 .

We then updates 0 by Transformer to obtain its representation ∈ R × at the final layer, and calculate the probability distribution of the next inserted item :

$$
P\left(\hat{i}_n \mid S_{1:n-1}^{
$$

where ℎ ∈ R is the hidden representation of the last position of . In particular, the first inserted item <sup>1</sup> is generated based on 0 = [ℎ + 1], so the probability is expressed as ˆ<sup>1</sup> | .

We train the augmenter using a random modification and restoration task. Specifically, we randomly modify the raw sequence with probabilities of keep: , delete: , insert: , + + = 1, generating a randomly modified sequence . For the inserted items, the augmenter needs to delete them; for the deleted items, the augmenter not only needs to perform insert operation but also accurately predict all the deleted items. This process is repeated for each raw sequence, allowing the augmenter to be trained in a self-supervised manner, learning the ability to automatically delete noise

and insert strongly related new items. As shown in Eq. [10,](#page-4-1) the target loss function of the augmenter is to minimize the negative log-likelihood of the probability ( | ):

<span id="page-4-1"></span>
$$
L_{aug} = -\log P(S_u \mid S_m)
$$
  
=  $-\left(\log P(O \mid S_m) + \sum_{i \in I^{ins}} \log P(S^{  
=  $-\left(\sum_{t=1}^{|S_m|} \log P(\hat{o}_t = o_t \mid S_m) + \sum_{i \in I^{ins}} \sum_{n=1}^{|S^{(10)$$ 

 indicates the positions where items need to be inserted, < represents the ground truth of the inserted items.

## 4.4 Triplet Contrastive Learning

We first apply a coarse-grained contrastive loss to provide supervisory signals for model training. The optimization objective of the contrastive loss is to maximize the similarity between two augmented sequences derived from the same user interaction sequence, while minimizing the similarity between augmented sequences from different users. Assuming there are user sequences in a batch, we obtain selfsupervised augmented sequences <sup>h</sup> 1 1 , <sup>1</sup> 2 , . . . , <sup>1</sup> i and randomly augmented sequences <sup>h</sup> 2 1 , <sup>2</sup> 2 , . . . , <sup>2</sup> i . We treat ( 1 , <sup>2</sup> ) as the positive pair, while the other 2 −2 sequences serve as negative samples. The contrastive loss

can then be expressed as:

$$
L_{cl}\left(S_u^{aug1}, S_u^{aug2}\right) = -\log \frac{\exp\left(\sin\left(S_u^{aug1}, S_u^{aug2}\right)\right)}{\exp\left(\sin\left(S_u^{aug1}, S_u^{aug2}\right)\right) + \sum_{S^-} \exp\left(\sin\left(S_u^{aug1}, S^- \right)\right)},\tag{11}
$$

where <sup>−</sup> denotes the negative samples, and sim(·) is calculated by the dot product of the hidden representations of the sequences.

Next, we design a finer-grained contrastive loss function. Since the self-supervised augmenter demonstrates the ability to delete noisy interactions and insert highly relevant items during training, we believe that the sequence augmented by the augmenter contributes more to modeling item transition correlations compared to the randomly augmented sequence. Therefore, a triplet contrastive loss is used to amplify the supervisory signals from the augmenter. Specifically, for a user's triplet sequence <sup>h</sup> , <sup>1</sup> , <sup>2</sup> i , we directly maximize the similarity sim(, <sup>1</sup> ) between the raw sequence and the self-supervised augmented sequence:

$$
L_{tri}\left(S_u, S_u^{aug1}, S_u^{aug2}\right) = -\log \frac{\exp\left(\text{sim}\left(S_u, S_u^{aug1}\right)\right)}{\exp\left(\text{sim}\left(S_u, S_u^{aug1}\right)\right) + \exp\left(\text{sim}\left(S_u, S_u^{aug2}\right)\right)}.
$$
\n(12)

We jointly optimize and , achieving higher similarity between the two augmented sequences from the same user at a macro level. At a micro level, the augmenter provides additional supervisory signals and directly feeds the modified results back into the hidden representation of the raw sequence.

#### 4.5 Recommender and Joint learning

The recommender is used to predict the user's next interaction. In this study, we follow the baseline model CL4SRec by applying a unidirectional Transformer-based recommender.

Given the input sequence and its hidden representation matrix , we again update by a Transformer. The initial hidden representation matrix of recommender is denoted as 0 ∈ R | |× , and 0 = . 0 is updated following Eq. [13:](#page-5-0)

<span id="page-5-0"></span>
$$
H_r^l = \text{Trm}\left(H_r^{l-1}\right),\tag{13}
$$

where denotes the representation matrix at -th layer. We take the representation of the last layer and denote it as .

During training, we mask the last item | <sup>|</sup> in , and the recommender predicts its probability distribution:

$$
P\left(\hat{i}_t \mid S_u\right) = \text{softmax}\left(Eh_t\right),\tag{14}
$$

where denotes the shared item embedding matrix, ℎ ∈ R denotes the hidden representation of the masked item from , ˆ denotes the predicted item. When testing, we calculate | |+<sup>1</sup> | to predict the next item. The recommender is optimized by minimizing the negative log-likelihood of the probability ˆ | :

$$
L_{rec} = -\log P \left( \hat{i}_t \mid S_u \right)
$$
  
= 
$$
-\log P \left( \hat{i}_t = i_{|S_u|} \mid S_u \right).
$$
 (15)

In practical experiments, we first optimize the augmenter independently by minimizing . Then, the standard backpropagation algorithm is adopted to minimize the joint loss and optimize the parameters of recommender:

$$
L = L_{rec} + \alpha L_{cl} + \beta L_{tri}, \qquad (16)
$$

where and are weight hyperparameters used to control the contribution of the contrastive losses. We will discuss their impact on model performance in the experimental section.

## 5 EXPERIMENTAL SETUP

#### 5.1 Research Questions

We seek to answer the following research questions: (RQ1) Does LACLRec outperform other state-of-the-art sequential recommendation models? (RQ2) Do sequence augmenter and triplet contrast enhance recommendation accuracy? (RQ3) How robust is LACLRec in handling noisy interaction sequences? (RQ4) Is LACLRec sensitive to hyperparameter settings?

Table 1. Statistics of the datasets.

<span id="page-5-1"></span>

| Datasets    | Beauty  | Yelp    | Sports  |  |  |
|-------------|---------|---------|---------|--|--|
| Users       | 22,362  | 22,844  | 35,597  |  |  |
| Items       | 12,101  | 16,552  | 18,357  |  |  |
| Records     | 194,682 | 236,999 | 294,483 |  |  |
| Avg. length | 8.7     | 10.4    | 8.3     |  |  |
| Density     | 0.07%   | 0.06%   | 0.05%   |  |  |

#### 5.2 Datasets

We conduct experiments on three datasets: Beauty, Yelp, and Sports. Among them, Beauty and Sports are two product review datasets crawled from Amazon [\[19\]](#page-10-24). Yelp is a business recommendation dataset released by Yelp.com. Due to the large size of the Yelp dataset, we only use records from 2019.

We follow [\[16\]](#page-10-3) to preprocess the datasets. First, we filtered out users and items with fewer than 5 interaction records. Then, we sorted the interaction records of each user in chronological order to obtain the item sequences. For each item sequence, the last item is designated as the test item, the second to last item as the validation item, and the remaining items are used for training. The statistics of the preprocessed datasets are shown in Table [1:](#page-5-1)

## 5.3 Baselines

To verify the performance of LACLRec, we compare it with the following SOTA sequential recommendation baselines, which can be classified into three groups: (1) vanilla recommendation models; (2) contrastive learning-based models, and (3) sequence modification-based models.

- Vanilla recommendation models:
	- SASRec [\[12\]](#page-10-23) introduces the Transformer module to model the transition relationship between items.
	- BERT4Rec [\[27\]](#page-10-25) introduces BERT into sequential recommendation, using a bidirectional Transformer and trained by masked item prediction task.
- Contrastive learning-based models:
	- CL4SRec [\[34\]](#page-10-10) employs three random sequence augmentation methods to construct contrastive learning signals for sequential recommendation.
	- DuoRec [\[22\]](#page-10-22) employs an augmentation method based on dropout and a novel sampling strategy to construct contrastive self-supervised signals.
	- CoSeRec [\[17\]](#page-10-11) designs two SSL-based sequence augmentation methods and combines them with random methods.
	- ICSRec [\[21\]](#page-10-14) segments user intentions from the raw sequence and introduces intent contrastive learning.
- Sequence modification-based models:
	- STEAM [\[16\]](#page-10-3) designs a corrector to delete misclicked items and insert missed items, aiming to improve the recommendation accuracy.

#### 5.4 Evaluation Metrics and Implementation

We adopted three widely used TOP-K metrics to evaluate the performance of all the aforementioned recommendation models: HR@ (Hit Rate), MRR@ (Mean Reciprocal Rank), and NDCG@ (Normalized Discounted Cumulative Gain), where is set to 5, 10, or 20.

For all models, the experimental setup is determined by the original paper and the parameter tuning process. We initialize the model parameters using the Xavier method [\[14\]](#page-10-26) and train the model using the Adam optimizer, with a learning rate set to 0.001 and an embedding size set to 64. Like [\[16,](#page-10-3) [27\]](#page-10-25), we randomly select 99 uninteracted items as negative samples for each validation and test item to evaluate the recommendation performance. The number of heads in the Transformer is set to 1, the number of layers in the network is 1, and the dropout rate is 0.5. We limit the maximum length of the raw sequence to 50, and if the length exceeds 50, the 50 most recent records are kept. The augmenter can insert up to five consecutive items at each position of the sequence, and the maximum length of the augmented sequence is limited to 60. All experiments were performed using an RTX 4090 graphics card.

## 6 EXPERIMENTAL RESULTS

## 6.1 Overall Performance

To answer RQ1, we first compare the overall performance of LACLRec with seven baseline models, the experimental results are shown in Table [2.](#page-7-0) From the experimental results, we have the following observations.

First, LACLRec achieves the best scores across all nine evaluation metrics on the three datasets, demonstrating its superior recommendation performance. Specifically, the sum of metrics improves by up to 10.18% compared to the baseline contrastive learning model CL4SRec, and by up to 5.57% compared to the second-best model. Unlike other models, LACLRec utilizes a learnable sequence augmenter to perform insertion and deletion operations, generating new augmented sequences for the contrastive learning task. On one hand, the sequence augmenter provides a strong contrastive signal, with the generated augmented sequences alleviating issues of data sparsity and noisy interactions in the raw sequence. On the other hand, the triplet contrastive learning provides finer-grained self-supervision signals, enhancing the recommender's ability to capture item representations and item correlations.

Second, the contrastive learning models outperform the vanilla models on all datasets, with ICSRec achieving the second-best performance on most metrics. This indicates that contrastive learning tasks can extract additional supervisory signals from user interaction sequences, enhancing the performance of sequential recommendation. LACLRec surpasses these models by employing a learnable augmenter rather than random or manual methods, generating higherquality augmented sequences whose effectiveness is further amplified through triplet contrast.

Lastly, STEAM introduces the 'non-exposed' and 'misclicks' in real user interactions [\[16\]](#page-10-3), designing a corrector to automatically delete noisy interactions and insert new items. In comparison, STEAM lacks the stronger supervisory signals provided by contrastive learning, resulting in suboptimal performance comparable to ICSRec.

## 6.2 Ablation Study

To answer RQ2, we design several variant models and compared their performance. First, to validate the effectiveness of the augmenter and triplet contrast, we design two variant models:

- Base: The augmenter is removed, and both augmented sequences are generated randomly.
- / − : The augmenter is used to generate one augmented sequence, but triplet contrast is removed.

Next, we design three variant models to explore the optimal module combinations and training methods:

- DuoAug: We add random perturbations in the augmenter, and use it to generate both two augmented sequences.
- TestAug: When testing, the recommender directly predicts the next item based on augmented sequences generated by the augmenter.

<span id="page-7-0"></span>

| Table 2. Overall performance. The best performance and the second best performance are denoted in bold and underlined |  |  |  |
|-----------------------------------------------------------------------------------------------------------------------|--|--|--|
| fonts respectively.                                                                                                   |  |  |  |

| Dataset | Metrics | SASRec | BERT4Rec | CL4SRec | DuoRec | CoSeRec | ICSRec | STEAM  | LACLRec | improve v.s. |       |
|---------|---------|--------|----------|---------|--------|---------|--------|--------|---------|--------------|-------|
|         |         |        |          |         |        |         |        |        |         | CL4SRec      | All   |
|         | HR5     | 0.3721 | 0.3666   | 0.4067  | 0.4094 | 0.4124  | 0.4250 | 0.4284 | 0.4446  | 9.32%        | 3.78% |
|         | HR10    | 0.4639 | 0.4728   | 0.5056  | 0.5078 | 0.5187  | 0.5188 | 0.5256 | 0.5460  | 7.99%        | 3.88% |
|         | HR20    | 0.5804 | 0.6011   | 0.6199  | 0.6200 | 0.6356  | 0.6345 | 0.6486 | 0.6606  | 6.57%        | 1.85% |
|         | MRR5    | 0.2611 | 0.2337   | 0.2785  | 0.2884 | 0.2749  | 0.2963 | 0.2899 | 0.3161  | 13.5%        | 6.68% |
| Beauty  | MRR10   | 0.2732 | 0.2478   | 0.2916  | 0.3015 | 0.2890  | 0.3087 | 0.3028 | 0.3297  | 13.07%       | 6.8%  |
|         | MRR20   | 0.2812 | 0.2566   | 0.2994  | 0.3092 | 0.2971  | 0.3167 | 0.3112 | 0.3376  | 12.76%       | 6.6%  |
|         | NDCG5   | 0.2887 | 0.2570   | 0.3104  | 0.3194 | 0.3090  | 0.3284 | 0.3181 | 0.3482  | 12.18%       | 6.03% |
|         | NDCG10  | 0.3182 | 0.2907   | 0.3422  | 0.3494 | 0.3434  | 0.3586 | 0.3508 | 0.3810  | 11.34%       | 6.25% |
|         | NDCG20  | 0.3476 | 0.3227   | 0.3710  | 0.3774 | 0.3728  | 0.3878 | 0.3807 | 0.4099  | 10.49%       | 5.7%  |
|         | Sum     | 3.1868 | 3.049    | 3.4253  | 3.4825 | 3.4529  | 3.5748 | 3.5561 | 3.7740  | 10.18%       | 5.57% |
|         | HR5     | 0.5847 | 0.6118   | 0.6292  | 0.6400 | 0.6454  | 0.6618 | 0.6683 | 0.6833  | 8.6%         | 2.24% |
|         | HR10    | 0.7833 | 0.7972   | 0.8223  | 0.8263 | 0.8241  | 0.8337 | 0.8460 | 0.8569  | 4.21%        | 1.17% |
|         | HR20    | 0.9194 | 0.9235   | 0.9486  | 0.9564 | 0.9444  | 0.9531 | 0.9511 | 0.9554  | 0.72%        | 0.24% |
|         | MRR5    | 0.3543 | 0.3764   | 0.3991  | 0.4085 | 0.4140  | 0.4302 | 0.4293 | 0.4482  | 12.3%        | 4.18% |
| Yelp    | MRR10   | 0.3808 | 0.4013   | 0.4251  | 0.4334 | 0.4380  | 0.4533 | 0.4531 | 0.4716  | 10.94%       | 4.04% |
|         | MRR20   | 0.3907 | 0.4104   | 0.4343  | 0.4429 | 0.4467  | 0.4619 | 0.4607 | 0.4788  | 10.25%       | 3.66% |
|         | NDCG5   | 0.4113 | 0.4257   | 0.4662  | 0.4647 | 0.4714  | 0.4877 | 0.4895 | 0.5066  | 11.05%       | 3.49% |
|         | NDCG10  | 0.4756 | 0.4870   | 0.5188  | 0.5245 | 0.5293  | 0.5434 | 0.5461 | 0.5630  | 8.52%        | 3.09% |
|         | NDCG20  | 0.5105 | 0.5218   | 0.5513  | 0.5590 | 0.5602  | 0.5741 | 0.5735 | 0.5883  | 6.71%        | 2.47% |
|         | Sum     | 4.8109 | 4.9551   | 5.1849  | 5.2557 | 5.2734  | 5.3993 | 5.4176 | 5.5523  | 7.09%        | 2.49% |
|         | HR5     | 0.3450 | 0.3515   | 0.3935  | 0.3980 | 0.4074  | 0.4220 | 0.4190 | 0.4379  | 11.28%       | 3.77% |
|         | HR10    | 0.4597 | 0.4791   | 0.5152  | 0.5192 | 0.5305  | 0.5459 | 0.5496 | 0.5645  | 9.57%        | 2.71% |
|         | HR20    | 0.5942 | 0.6280   | 0.6562  | 0.6583 | 0.6650  | 0.6861 | 0.6916 | 0.7017  | 6.93%        | 1.46% |
|         | MRR5    | 0.2204 | 0.2154   | 0.2600  | 0.2597 | 0.2653  | 0.2741 | 0.2685 | 0.2896  | 11.38%       | 5.65% |
| Sports  | MRR10   | 0.2357 | 0.2323   | 0.2762  | 0.2758 | 0.2817  | 0.2906 | 0.2858 | 0.3064  | 10.93%       | 5.44% |
|         | MRR20   | 0.2449 | 0.2426   | 0.2859  | 0.2854 | 0.2910  | 0.3003 | 0.2956 | 0.3159  | 10.49%       | 5.19% |
|         | NDCG5   | 0.2513 | 0.2448   | 0.2931  | 0.2936 | 0.3005  | 0.3108 | 0.3058 | 0.3264  | 11.36%       | 5.02% |
|         | NDCG10  | 0.2883 | 0.2862   | 0.3324  | 0.3335 | 0.3403  | 0.3508 | 0.3479 | 0.3673  | 10.5%        | 4.7%  |
|         | NDCG20  | 0.3222 | 0.3236   | 0.3680  | 0.3686 | 0.3743  | 0.3862 | 0.3838 | 0.4020  | 9.24%        | 4.09% |
|         | Sum     | 2.9622 | 3.0035   | 0.3805  | 3.3921 | 3.4559  | 3.5668 | 3.5476 | 3.7122  | 9.81%        | 4.08% |

Table 3. Ablation Study. The best performance is denoted in bold fonts.

<span id="page-7-1"></span>

| Dataset | Model                                                            | HR5                                                      | HR10                                                     | HR20                                                     | MRR5                                                     | MRR10                                                    | MRR20                                                    | NDCG5                                                    | NDCG10                                                   | NDCG20                                                   | Sum                                                      |
|---------|------------------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|----------------------------------------------------------|
| Beauty  | LACLRec<br>Base<br>𝑤/𝑜<br>−𝑇 𝑟𝑖<br>DuoAug<br>TestAug<br>Co-Train | 0.4446<br>0.4066<br>0.4311<br>0.4097<br>0.4297<br>0.4381 | 0.5460<br>0.5067<br>0.5263<br>0.5032<br>0.5319<br>0.5332 | 0.6606<br>0.6202<br>0.6429<br>0.6173<br>0.6504<br>0.6529 | 0.3161<br>0.2806<br>0.3076<br>0.2943<br>0.2949<br>0.3102 | 0.3297<br>0.2939<br>0.3203<br>0.3067<br>0.3085<br>0.3229 | 0.3376<br>0.3017<br>0.3283<br>0.3145<br>0.3167<br>0.3311 | 0.3482<br>0.3119<br>0.3384<br>0.3230<br>0.3284<br>0.3421 | 0.3810<br>0.3442<br>0.3691<br>0.3531<br>0.3615<br>0.3728 | 0.4099<br>0.3729<br>0.3985<br>0.3818<br>0.3914<br>0.4029 | 3.7740<br>3.4391<br>3.6628<br>3.5041<br>3.6137<br>3.7066 |
| Yelp    | LACLRec<br>Base<br>𝑤/𝑜<br>−𝑇 𝑟𝑖<br>DuoAug<br>TestAug<br>Co-Train | 0.6833<br>0.6319<br>0.6661<br>0.6354<br>0.6649<br>0.6744 | 0.8569<br>0.8216<br>0.8378<br>0.8138<br>0.8396<br>0.8481 | 0.9554<br>0.9482<br>0.9436<br>0.9339<br>0.9443<br>0.9548 | 0.4482<br>0.4012<br>0.4355<br>0.4051<br>0.4308<br>0.4379 | 0.4716<br>0.4267<br>0.4586<br>0.4290<br>0.4543<br>0.4612 | 0.4788<br>0.4360<br>0.4663<br>0.4377<br>0.4620<br>0.4690 | 0.5066<br>0.4584<br>0.4927<br>0.4622<br>0.4889<br>0.4966 | 0.5630<br>0.5199<br>0.5485<br>0.5199<br>0.5456<br>0.5529 | 0.5883<br>0.5525<br>0.5757<br>0.5508<br>0.5726<br>0.5803 | 5.5523<br>5.1968<br>5.4252<br>5.1881<br>5.4035<br>5.4755 |
| Sports  | LACLRec<br>Base<br>𝑤/𝑜<br>−𝑇 𝑟𝑖<br>DuoAug<br>TestAug<br>Co-Train | 0.4379<br>0.3946<br>0.4157<br>0.3897<br>0.4182<br>0.4352 | 0.5645<br>0.5161<br>0.5403<br>0.5119<br>0.5470<br>0.5588 | 0.7017<br>0.6585<br>0.6751<br>0.6504<br>0.6860<br>0.6980 | 0.2896<br>0.2615<br>0.2766<br>0.2578<br>0.2719<br>0.2843 | 0.3064<br>0.2776<br>0.2932<br>0.2739<br>0.2890<br>0.3006 | 0.3159<br>0.2875<br>0.3025<br>0.2835<br>0.2986<br>0.3102 | 0.3264<br>0.2945<br>0.3112<br>0.2905<br>0.3083<br>0.3217 | 0.3673<br>0.3337<br>0.3514<br>0.3298<br>0.3498<br>0.3615 | 0.4020<br>0.3697<br>0.3854<br>0.3648<br>0.3849<br>0.3966 | 3.7122<br>3.3941<br>3.5519<br>3.3528<br>3.5542<br>3.6674 |

• Co-Train: The augmenter and recommender are jointly trained.

The experimental results are shown in Table [3,](#page-7-1) from which we have the following observations. Firstly, without the self-supervised augmenter, the Base actually degrades into CL4SRec, with a significant decrease in recommendation performance. The performance of / − also noticeably declines compared to LACLRec, indicating that triplet contrastive learning provides finer-grained supervisory signals that benefit next-item prediction tasks. Secondly, DuoAug performs poorly, due to the high similarity between the two augmented sequences generated by the augmenter from the same raw sequence, which fails to provide effective contrastive signals. TestAug predicts items based on augmented sequences, also shows inferior performance since

the augmented sequences do not directly participate in recommender training. If the next item is predicted based on the augmented sequence, it will reduce the efficiency of model training and inference [\[16\]](#page-10-3). Finally, co-training the augmenter and recommender also decreases performance. We attribute this to the early stages of training, where the untrained augmenter may generate low-quality augmented sequences, thereby misleading the contrastive learning task.

In conclusion, both the augmenter and triplet contrastive learning effectively improve the accuracy of sequential recommendations, and optimizing the model is best achieved by employing both modules while training the augmenter and recommender separately.

#### 6.3 Robustness analysis

Real-world user interaction records are often subject to noise interference due to privacy and other concerns, which may degrade the performance of trained recommendation models. To answer RQ3, we conduct several experiments on three simulated test sets to assess the robustness of LACLRec. Specifically, we apply 'keep', 'delete', and 'insert' operations in a 4:3:3 ratio to each item in the real test set (keeping the final item unchanged) to generate the simulated test sets. We then compare the recommendation performance of LACLRec against several strong baselines on these simulated test sets, which contain substantial noise.

The experimental results are presented in Table [4,](#page-9-8) where Sum denotes the total score of the evaluation metrics on the simulated test set, and Raw denotes the total score on the real test set. First, we find that all models have noticeable performance degradation on the simulated test set due to the massive destruction of data. Nonetheless, LACLRec continues to perform best on all three datasets, with only a slight drop in the HR20 metric on the Yelp dataset compared to IC-SRec, further proving the superior performance of LACLRec. Additionally, to further quantify the impact of noise on each model, we also visually show the disturbance of their total score on the simulated test set compared with the total score on the real test set, where = ( − )/. It is evident that LACLRec is the most robust, with the smallest decrease in total score across all three datasets. We attribute this robustness to the augmenter, which generates augmented sequences with higher diversity compared to traditional random augmentation methods, thereby conveying richer item correlations to the recommender. Consequently, LACLRec exhibits reduced sensitivity to noisy interactions. ICSRec, CoSeRec, and DuoRec also adopt optimized contrastive signal construction methods, which perform better overall than CL4SRec. Finally, STEAM corrects the input sequence for the recommender, which can effectively mitigate noise to some extent and showcase competitive performance ae well.

#### 6.4 Hyperparameter Study

LACLRec has two unique and critical hyperparameters: the proportion of random sequence modifications during augmenter training, and the weights of the contrastive loss during recommender training. To answer RQ4, we investigate whether LACLRec is sensitive to the settings of these hyperparameters.

First, we select three sets of [, , ], with results shown in Table [5,](#page-9-9) where 'Operation' represents the proportion of keep, delete, and insert operations when the trained augmenter generates augmented sequences. We observe that varying the random modification ratios can influence the augmenter's modification tendencies in practical applications. Specifically, increasing the rate of random deletions encourages the augmenter to insert items more frequently. From the results, we see that a higher insertion ratio can slightly improve LACLRec's performance, likely due to augmented sequences encompassing more diverse item transitions. However, LACLRec's recommendation performance does not display significant changes with variations in the 'Operation' ratio, indicating that the model is insensitive to the settings of [, , ].

Next, we examine the impact of the contrastive loss weights and on model performance, with results shown in Table [6.](#page-9-10) We observe similar performance variations on the three datasets, and present only the results on Beauty here. We find that as and increase, overall recommendation performance gradually declines. The model is particularly sensitive to the triplet contrastive loss weight . When increases to 0.05 or 0.1, LACLRec underperforms compared to some baseline models in Table [2.](#page-7-0) This is due to the fact that the scale of is larger than that of in our experiments, and jointly optimizing them requires a smaller weight to balance . This sensitivity to is a limitation of LACLRec, necessitating careful selection of the weight for .

## 7 CONCLUSION

This paper proposes LACLRec, which employs a learnable augmenter in place of traditional random methods to generate higher-quality augmented sequences for contrastive learning tasks, thereby mitigating issues of data sparsity and noisy interactions. Additionally, we design a triplet contrastive loss to provide finer-grained supervision signals for model training. Experiments on three public datasets demonstrate that LACLRec outperforms state-of-the-art baseline models in recommendation performance. Limitations of our work include the need to pre-collect data to train the augmenter and the additional hyperparameter tuning required.

## Acknowledgments

This research was supported by

<span id="page-9-8"></span>Table 4. Robustness analysis. The table shows the performance comparison of different models on the simulated test sets.

| Dataset | Model   | HR5    | HR10   | HR20   | MRR5   | MRR10  | MRR20  | NDCG5  | NDCG10 | NDCG20 | Sum    | Raw    | dist   |
|---------|---------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| Beauty  | LACLRec | 0.4306 | 0.5276 | 0.6424 | 0.3057 | 0.3186 | 0.3265 | 0.3368 | 0.3681 | 0.3971 | 3.6540 | 3.7740 | -3.17% |
|         | ICSRec  | 0.4045 | 0.5100 | 0.6278 | 0.2709 | 0.2849 | 0.2931 | 0.3041 | 0.3381 | 0.3679 | 3.4013 | 3.5748 | -4.85% |
|         | STEAM   | 0.4081 | 0.5080 | 0.6279 | 0.2718 | 0.2851 | 0.2933 | 0.3057 | 0.3379 | 0.3681 | 3.4062 | 3.5561 | -4.21% |
|         | CoSeRec | 0.3925 | 0.5020 | 0.6262 | 0.2567 | 0.2714 | 0.2799 | 0.2905 | 0.3259 | 0.3572 | 3.3022 | 3.4529 | -4.36% |
|         | CL4SRec | 0.3911 | 0.4882 | 0.6008 | 0.2690 | 0.2819 | 0.2896 | .2993  | 0.3307 | 0.3590 | 3.3100 | 3.4253 | -3.36% |
|         | DuoRec  | 0.3925 | 0.4928 | 0.6040 | 0.2705 | 0.2839 | 0.2915 | 0.3009 | 0.3333 | 0.3613 | 3.3311 | 3.4825 | -4.34% |
| Yelp    | LACLRec | 0.6536 | 0.8357 | 0.9514 | 0.4193 | 0.4437 | 0.4522 | 0.4774 | 0.5364 | 0.5662 | 5.3365 | 5.5523 | -3.88% |
|         | ICSRec  | 0.6183 | 0.8092 | 0.9551 | 0.3875 | 0.4129 | 0.4235 | 0.4447 | 0.5064 | 0.5438 | 5.1014 | 5.3993 | -5.51% |
|         | STEAM   | 0.6328 | 0.8160 | 0.9355 | 0.3991 | 0.4237 | 0.4324 | 0.4571 | 0.5165 | 0.5472 | 5.1606 | 5.4176 | -4.74% |
|         | CoSeRec | 0.6148 | 0.7966 | 0.9293 | 0.3853 | 0.4097 | 0.4192 | 0.4421 | 0.5011 | 0.5350 | 5.0331 | 5.2734 | -4.56% |
|         | CL4SRec | 0.6003 | 0.7910 | 0.9280 | 0.3721 | 0.3977 | 0.4077 | 0.4286 | 0.4905 | 0.5257 | 4.9419 | 5.1849 | -4.68% |
|         | DuoRec  | 0.6063 | 0.8011 | 0.9525 | 0.3757 | 0.4017 | 0.4128 | 0.4329 | 0.4959 | 0.5348 | 5.0141 | 5.2557 | -4.59% |
| Sports  | LACLRec | 0.4186 | 0.5440 | 0.6803 | 0.2740 | 0.2906 | 0.3000 | 0.3099 | 0.3503 | 0.3847 | 3.5527 | 3.7122 | -4.29% |
|         | ICSRec  | 0.3988 | 0.5246 | 0.6701 | 0.2552 | .2719  | 0.2820 | 0.2908 | 0.3314 | 0.3682 | 3.3931 | 3.5668 | -4.87% |
|         | STEAM   | 0.3929 | 0.5259 | 0.6724 | 0.2475 | 0.2652 | 0.2753 | 0.2836 | 0.3265 | 0.3635 | 3.3530 | 3.5476 | -5.48% |
|         | CoSeRec | 0.3813 | 0.5019 | 0.6377 | 0.2420 | 0.2580 | 0.2674 | 0.2765 | 0.3154 | 0.3497 | 3.2300 | 3.4559 | -6.53% |
|         | CL4SRec | 0.3648 | 0.4854 | 0.6251 | 0.2404 | 0.2563 | 0.2659 | 0.2712 | 0.3100 | 0.3452 | 3.1647 | 3.3805 | -6.38% |
|         | DuoRec  | 0.3746 | 0.4961 | 0.6362 | 0.2398 | 0.2558 | 0.2655 | 0.2732 | 0.3123 | 0.3477 | 3.2016 | 3.3921 | -5.62% |

Table 5. Hyperparameter Study. The table shows the effect of [, , ] when training the augmenter.

<span id="page-9-9"></span>

| Dataset | [𝑝𝑘<br>, 𝑝𝑑<br>, 𝑝𝑖] | HR5    | HR10   | HR20   | MRR5   | MRR10  | MRR20  | NDCG5  | NDCG10 | NDCG20 | Sum    | Operation      |
|---------|----------------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|----------------|
| Beauty  | [0.4, 0.5, 0.1]      | 0.4446 | 0.5460 | 0.6606 | 0.3161 | 0.3297 | 0.3376 | 0.3482 | 0.3810 | 0.4099 | 3.7740 | [53%, 1%, 46%] |
|         | [0.5, 0.4, 0.1]      | 0.4439 | 0.5470 | 0.6631 | 0.3137 | 0.3274 | 0.3354 | 0.3461 | 0.3795 | 0.4087 | 3.7652 | [58%, 1%, 41%] |
|         | [0.5, 0.3, 0.2]      | 0.4431 | 0.5450 | 0.6571 | 0.3147 | 0.3282 | 0.3359 | 0.3467 | 0.3796 | 0.4078 | 3.7587 | [74%, 1%, 25%] |
| Yelp    | [0.4, 0.5, 0.1]      | 0.6833 | 0.8569 | 0.9554 | 0.4482 | 0.4716 | 0.4788 | 0.5066 | 0.5630 | 0.5883 | 5.5523 | [50%, 2%, 48%] |
|         | [0.5, 0.4, 0.1]      | 0.6781 | 0.8505 | 0.9556 | 0.4444 | 0.4676 | 0.4753 | 0.5024 | 0.5584 | 0.5855 | 5.5180 | [72%, 1%, 27%] |
|         | [0.5, 0.3, 0.2]      | 0.6767 | 0.8511 | 0.9578 | 0.4406 | 0.4641 | 0.4719 | 0.4992 | 0.5558 | 0.5833 | 5.5008 | [83%, 4%, 13%] |
| Sports  | [0.4, 0.5, 0.1]      | 0.4336 | 0.5626 | 0.7016 | 0.2877 | 0.3049 | 0.3145 | 0.3240 | 0.3656 | 0.4007 | 3.6956 | [49%, 1%, 50%] |
|         | [0.5, 0.4, 0.1]      | 0.4379 | 0.5645 | 0.7017 | 0.2896 | 0.3064 | 0.3159 | 0.3264 | 0.3673 | 0.4020 | 3.7122 | [61%, 1%, 38%] |
|         | [0.5, 0.3, 0.2]      | 0.4355 | 0.5628 | 0.7005 | 0.2883 | 0.3052 | 0.3148 | 0.3248 | 0.3660 | 0.4008 | 3.6992 | [83%, 2%, 15%] |

Table 6. Hyperparameter Study. The table shows the effect of and when training the recommender.

<span id="page-9-10"></span>

| Dataset | 𝛼, 𝛽       | HR5    | HR10   | HR20   | MRR5   | MRR10  | MRR20  | NDCG5  | NDCG10 | NDCG20 | Sum    |
|---------|------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| Beauty  | 0.1, 0.005 | 0.4446 | 0.5460 | 0.6606 | 0.3161 | 0.3297 | 0.3376 | 0.3482 | 0.3810 | 0.4099 | 3.7740 |
|         | 0.1, 0.01  | 0.4466 | 0.5491 | 0.6608 | 0.3147 | 0.3283 | 0.3359 | 0.3476 | 0.3806 | 0.4087 | 3.7727 |
|         | 0.1, 0.05  | 0.4352 | 0.5349 | 0.6495 | 0.3048 | 0.3180 | 0.3259 | 0.3373 | 0.3694 | 0.3984 | 3.6738 |
|         | 0.1, 0.1   | 0.4181 | 0.5228 | 0.6340 | 0.2834 | 0.2973 | 0.3050 | 0.3170 | 0.3507 | 0.3788 | 3.5076 |
|         | 0.2, 0.005 | 0.4418 | 0.5426 | 0.6551 | 0.3124 | 0.3258 | 0.3336 | 0.3446 | 0.3772 | 0.4056 | 3.7390 |
|         | 0.5, 0.005 | 0.4410 | 0.5342 | 0.6477 | 0.3111 | 0.3235 | 0.3313 | 0.3435 | 0.3735 | 0.4022 | 3.7084 |
|         | 1.0, 0.005 | 0.4395 | 0.5349 | 0.6463 | 0.3112 | 0.3239 | 0.3315 | 0.3431 | 0.3739 | 0.4020 | 3.7066 |

# References

- <span id="page-9-3"></span>[1] Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, and Caiming Xiong. 2022. Intent Contrastive Learning for Sequential Recommendation. In Proceedings of the ACM Web Conference 2022 (Virtual Event, Lyon, France) (WWW '22). 2172–2182.
- <span id="page-9-2"></span>[2] Shitong Dai, Jiongnan Liu, Zhicheng Dou, Haonan Wang, Lin Liu, Bo Long, and Ji-Rong Wen. 2023. Contrastive Learning for User Sequence Representation in Personalized Product Search. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD '23). 380–389.
- <span id="page-9-1"></span>[3] Yizhou Dang, Enneng Yang, Guibing Guo, Linying Jiang, Xingwei Wang, Xiaoxiao Xu, Qinghui Sun, and Hong Liu. 2024. TiCoSeRec: Augmenting Data to Uniform Sequences by Time Intervals for Effective Recommendation. IEEE Transactions on Knowledge and Data Engineering 36, 6 (2024), 2686–2700.
- <span id="page-9-0"></span>[4] Hanwen Du, Huanhuan Yuan, Pengpeng Zhao, Fuzhen Zhuang, Guanfeng Liu, Lei Zhao, Yanchi Liu, and Victor S. Sheng. 2023. Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei,

Taiwan) (SIGIR '23). 58–67.

- <span id="page-9-7"></span>[5] Chenghua Duan, Wei Fan, Wei Zhou, Hu Liu, and Junhao Wen. 2023. CLSPRec: Contrastive Learning of Long and Short-term Preferences for Next POI Recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (Birmingham, United Kingdom) (CIKM '23). 473–482.
- <span id="page-9-4"></span>[6] Zirui Guo, Yanhua Yu, Yuling Wang, Kangkang Lu, Zixuan Yang, Liang Pang, and Tat-Seng Chua. 2024. Information-Controllable Graph Contrastive Learning for Recommendation. In Proceedings of the 18th ACM Conference on Recommender Systems (Bari, Italy) (RecSys '24). 528–537.
- <span id="page-9-6"></span>[7] Tianqi He, Kaiyuan Li, Shan Chen, Haitao Wang, Qiang Liu, Xingxing Wang, and Dong Wang. 2023. DMBIN: A Dual Multi-behavior Interest Network for Click-Through Rate Prediction via Contrastive Learning. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 1366–1375.
- <span id="page-9-5"></span>[8] Wei He, Guohao Sun, Jinhu Lu, and Xiu Susie Fang. 2023. Candidateaware Graph Contrastive Learning for Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23).

1670–1679.

- <span id="page-10-12"></span>[9] Chengkai Huang, Shoujin Wang, Xianzhi Wang, and Lina Yao. 2023. Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 99–109.
- <span id="page-10-7"></span>[10] Yangqin Jiang, Chao Huang, and Lianghao Huang. 2023. Adaptive Graph Contrastive Learning for Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD '23). 4252–4261.
- <span id="page-10-15"></span>[11] Yuezihan Jiang, Changyu Li, Gaode Chen, Peiyi Li, Qi Zhang, Jingjian Lin, Peng Jiang, Fei Sun, and Wentao Zhang. 2024. MMGCL: Meta Knowledge-Enhanced Multi-view Graph Contrastive Learning for Recommendations. In Proceedings of the 18th ACM Conference on Recommender Systems (Bari, Italy) (RecSys '24). 538–548.
- <span id="page-10-23"></span>[12] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM). IEEE, 197–206.
- <span id="page-10-18"></span>[13] Yantong Lai, Yijun Su, Lingwei Wei, Tianqi He, Haitao Wang, Gaode Chen, Daren Zha, Qiang Liu, and Xingxing Wang. 2024. Disentangled Contrastive Hypergraph Learning for Next POI Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (Washington DC, USA) (SI-GIR '24). 1452–1462.
- <span id="page-10-26"></span>[14] Jake Lever, Martin Krzywinski, and Naomi Altman. 2016. Points of significance: model selection and overfitting. Nature methods 13, 9 (2016), 703–705.
- <span id="page-10-13"></span>[15] Xuewei Li, Aitong Sun, Mankun Zhao, Jian Yu, Kun Zhu, Di Jin, Mei Yu, and Ruiguo Yu. 2023. Multi-Intention Oriented Contrastive Learning for Sequential Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore, Singapore) (WSDM '23). 411–419.
- <span id="page-10-3"></span>[16] Yujie Lin, Chenyang Wang, Zhumin Chen, Zhaochun Ren, Xin Xin, Qiang Yan, Maarten de Rijke, Xiuzhen Cheng, and Pengjie Ren. 2023. A Self-Correcting Sequential Recommender. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW '23). 1283–1293.
- <span id="page-10-11"></span>[17] Zhiwei Liu, Yongjun Chen, Jia Li, Philip S Yu, Julian McAuley, and Caiming Xiong. 2021. Contrastive self-supervised sequential recommendation with robust augmentation. arXiv preprint arXiv:2108.06479 (2021).
- <span id="page-10-4"></span>[18] Muyang Ma, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Huasheng Liang, Jun Ma, and Maarten De Rijke. 2023. Improving transformerbased sequential recommenders through preference editing. ACM Trans. Inf. Syst. 41, 3, Article 71 (apr 2023), 24 pages.
- <span id="page-10-24"></span>[19] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (Santiago, Chile) (SIGIR '15). 43–52.
- <span id="page-10-8"></span>[20] Xiuyuan Qin, Huanhuan Yuan, Pengpeng Zhao, Junhua Fang, Fuzhen Zhuang, Guanfeng Liu, Yanchi Liu, and Victor Sheng. 2023. Metaoptimized Contrastive Learning for Sequential Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 89–98.
- <span id="page-10-14"></span>[21] Xiuyuan Qin, Huanhuan Yuan, Pengpeng Zhao, Guanfeng Liu, Fuzhen Zhuang, and Victor S. Sheng. 2024. Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining (Merida, Mexico) (WSDM '24). 548–556.
- <span id="page-10-22"></span>[22] Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2022. Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (Virtual Event, AZ, USA)

(WSDM '22). 813–823.

- <span id="page-10-20"></span>[23] Dan Ni Ren, Leong Hou U, and Wei Liu. 2023. Dual-view Contrastive Learning for Auction Recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (Birmingham, United Kingdom) (CIKM '23). 2146–2155.
- <span id="page-10-16"></span>[24] Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, and Chao Huang. 2023. Disentangled Contrastive Collaborative Filtering. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 1137–1146.
- <span id="page-10-6"></span>[25] Zhaochun Ren, Na Huang, Yidan Wang, Pengjie Ren, Jun Ma, Jiahuan Lei, Xinlei Shi, Hengliang Luo, Joemon Jose, and Xin Xin. 2023. Contrastive State Augmentations for Reinforcement Learning-Based Recommender Systems. In Proceedings of the 46th International ACM SI-GIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 922–931.
- <span id="page-10-9"></span>[26] Jie Shuai, Kun Zhang, Le Wu, Peijie Sun, Richang Hong, Meng Wang, and Yong Li. 2022. A Review-aware Graph Contrastive Learning Framework for Recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22). 1283–1293.
- <span id="page-10-25"></span>[27] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (Beijing, China) (CIKM '19). 1441–1450.
- <span id="page-10-17"></span>[28] Jiakai Tang, Sunhao Dai, Zexu Sun, Xu Chen, Jun Xu, Wenhui Yu, Lantao Hu, Peng Jiang, and Han Li. 2024. Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Barcelona, Spain) (KDD '24). 2854–2865.
- <span id="page-10-0"></span>[29] Changxin Tian, Binbin Hu, Wayne Xin Zhao, Zhiqiang Zhang, and Jun Zhou. 2023. Periodicity May Be Emanative: Hierarchical Contrastive Learning for Sequential Recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (Birmingham, United Kingdom) (CIKM '23). 2442–2451.
- <span id="page-10-1"></span>[30] Ziyang Wang, Huoyu Liu, Wei Wei, Yue Hu, Xian-Ling Mao, Shaojian He, Rui Fang, and Dangyang Chen. 2022. Multi-level Contrastive Learning Framework for Sequential Recommendation. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management (Atlanta, GA, USA) (CIKM '22). 2098–2107.
- <span id="page-10-19"></span>[31] Zongwei Wang, Junliang Yu, Min Gao, Hongzhi Yin, Bin Cui, and Shazia Sadiq. 2024. Unveiling Vulnerabilities of Contrastive Recommender Systems to Poisoning Attacks. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Barcelona, Spain) (KDD '24). 3311–3322.
- <span id="page-10-21"></span>[32] Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022. Contrastive Meta Learning with Behavior Multiplicity for Recommendation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (Virtual Event, AZ, USA) (WSDM '22). 1120–1128.
- <span id="page-10-5"></span>[33] Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui, and Xiangliang Zhang. 2021. Self-supervised hypergraph convolutional networks for session-based recommendation. In Proceedings of the AAAI conference on artificial intelligence, Vol. 35. 4503–4511.
- <span id="page-10-10"></span>[34] Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Jiandong Zhang, Bolin Ding, and Bin Cui. 2022. Contrastive learning for sequential recommendation. In 2022 IEEE 38th international conference on data engineering (ICDE). IEEE, 1259–1273.
- <span id="page-10-2"></span>[35] Xiaolong Xu, Hongsheng Dong, Lianyong Qi, Xuyun Zhang, Haolong Xiang, Xiaoyu Xia, Yanwei Xu, and Wanchun Dou. 2024. CM-CLRec: Cross-modal Contrastive Learning for User Cold-start Sequential Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (Washington DC, USA) (SIGIR '24). 1589–1598.
- <span id="page-11-16"></span><span id="page-11-0"></span>[36] Hongrui Xuan, Yi Liu, Bohan Li, and Hongzhi Yin. 2023. Knowledge Enhancement for Contrastive Multi-Behavior Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore, Singapore) (WSDM '23). 195–203.
- <span id="page-11-7"></span>[37] Mengduo Yang, Yi Yuan, Jie Zhou, Meng Xi, Xiaohua Pan, Ying Li, Yangyang Wu, Jinshan Zhang, and Jianwei Yin. 2024. Adaptive Fusion of Multi-View for Graph Contrastive Recommendation. In Proceedings of the 18th ACM Conference on Recommender Systems (Bari, Italy) (RecSys '24). 228–237.
- <span id="page-11-1"></span>[38] Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang, Da Luo, and Kangyi Lin. 2023. Debiased Contrastive Learning for Sequential Recommendation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW '23). 1063–1073.
- <span id="page-11-12"></span>[39] Yuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li. 2022. Knowledge Graph Contrastive Learning for Recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22). 1434–1443.
- <span id="page-11-10"></span>[40] Yonghui Yang, Zhengwei Wu, Le Wu, Kun Zhang, Richang Hong, Zhiqiang Zhang, Jun Zhou, and Meng Wang. 2023. Generative-Contrastive Graph Learning for Recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 1117–1126.
- <span id="page-11-15"></span>[41] Xiaoxin Ye, Yun Li, and Lina Yao. 2023. DREAM: Decoupled Representation via Extraction Attention Module and Supervised Contrastive Learning for Cross-Domain Sequential Recommender. In Proceedings of the 17th ACM Conference on Recommender Systems (Singapore, Singapore) (RecSys '23). 479–490.
- <span id="page-11-11"></span>[42] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung Nguyen. 2022. Are Graph Augmentations Necessary? Simple Graph Contrastive Learning for Recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22). 1294–1303.
- <span id="page-11-2"></span>[43] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Jundong Li, and Zi Huang. 2023. Self-supervised learning for recommender systems: A survey. IEEE Transactions on Knowledge and Data Engineering (2023), 1–20.
- <span id="page-11-3"></span>[44] Dan Zhang, Yangliao Geng, Wenwen Gong, Zhongang Qi, Zhiyu Chen, Xing Tang, Ying Shan, Yuxiao Dong, and Jie Tang. 2024. RecDCL: Dual Contrastive Learning for Recommendation. In Proceedings of the ACM Web Conference 2024 (Singapore, Singapore) (WWW '24). 3655–3666.
- <span id="page-11-9"></span>[45] Yichi Zhang, Guisheng Yin, and Yuxin Dong. 2023. Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems (Singapore, Singapore) (RecSys '23). 141–150.
- <span id="page-11-14"></span>[46] Hongli Zhou, Zhihao Jia, Haiyang Zhu, and Zhizheng Zhang. 2024. CLLP: Contrastive Learning Framework Based on Latent Preferences for Next POI Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (Washington DC, USA) (SIGIR '24). 1473–1482.
- <span id="page-11-8"></span>[47] Peilin Zhou, Jingqi Gao, Yueqi Xie, Qichen Ye, Yining Hua, Jaeboum Kim, Shoujin Wang, and Sunghun Kim. 2023. Equivariant Contrastive Learning for Sequential Recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems (Singapore, Singapore) (Rec-Sys '23). 129–140.
- <span id="page-11-6"></span>[48] Peilin Zhou, You-Liang Huang, Yueqi Xie, Jingqi Gao, Shoujin Wang, Jae Boum Kim, and Sunghun Kim. 2024. Is Contrastive Learning Necessary? A Study of Data Augmentation vs Contrastive Learning in Sequential Recommendation. In Proceedings of the ACM Web Conference 2024 (Singapore, Singapore) (WWW '24). 3854–3863.
- <span id="page-11-4"></span>[49] Yuanhang Zhou, Kun Zhou, Wayne Xin Zhao, Cheng Wang, Peng Jiang, and He Hu. 2022. C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (Virtual

Event, AZ, USA) (WSDM '22). 1488–1496.

- <span id="page-11-5"></span>[50] Guanghui Zhu, Wang Lu, Chunfeng Yuan, and Yihua Huang. 2023. AdaMCL: Adaptive Fusion Multi-View Contrastive Learning for Collaborative Filtering. In Proceedings of the 46th International ACM SI-GIR Conference on Research and Development in Information Retrieval (Taipei, Taiwan) (SIGIR '23). 1076–1085.
- <span id="page-11-13"></span>[51] Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, and Xin Cao. 2022. Multi-level Cross-view Contrastive Learning for Knowledge-aware Recommender System. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22). 1358–1368.