# REWEIGHTING AUGMENTED SAMPLES BY MINIMIZ-ING THE MAXIMAL EXPECTED LOSS

Mingyang Yi1,2<sup>∗</sup> , Lu Hou<sup>3</sup> , Lifeng Shang<sup>3</sup> , Xin Jiang<sup>3</sup> , Qun Liu<sup>3</sup> , Zhi-Ming Ma1,<sup>2</sup>

<sup>1</sup>University of Chinese Academy of Sciences yimingyang17@mails.ucas.edu.cn

<sup>2</sup>Academy of Mathematics and Systems Science, Chinese Academy of Sciences mazm@amt.ac.cn <sup>3</sup>Huawei Noah's Ark Lab

{houlu3,shang.lifeng,Jiang.Xin,qun.liu}@huawei.com

## ABSTRACT

Data augmentation is an effective technique to improve the generalization of deep neural networks. However, previous data augmentation methods usually treat the augmented samples equally without considering their individual impacts on the model. To address this, for the augmented samples from the same training example, we propose to assign different weights to them. We construct the maximal expected loss which is the supremum over any reweighted loss on augmented samples. Inspired by adversarial training, we minimize this maximal expected loss (MMEL) and obtain a simple and interpretable closed-form solution: more attention should be paid to augmented samples with large loss values (i.e., harder examples). Minimizing this maximal expected loss enables the model to perform well under any reweighting strategy. The proposed method can generally be applied on top of any data augmentation methods. Experiments are conducted on both natural language understanding tasks with token-level data augmentation, and image classification tasks with commonly-used image augmentation techniques like random crop and horizontal flip. Empirical results show that the proposed method improves the generalization performance of the model.

## 1 INTRODUCTION

Deep neural networks have achieved state-of-the-art results in various tasks in natural language processing (NLP) tasks [\(Sutskever et al., 2014;](#page-10-0) [Vaswani et al., 2017;](#page-10-1) [Devlin et al., 2019\)](#page-8-0) and computer vision (CV) tasks [\(He et al., 2016;](#page-9-0) [Goodfellow et al., 2016\)](#page-8-1). One approach to improve the generalization performance of deep neural networks is data augmentation [\(Xie et al., 2019;](#page-10-2) [Jiao et al.,](#page-9-1) [2019;](#page-9-1) [Cheng et al., 2019;](#page-8-2) [2020\)](#page-8-3). However, there are some problems if we directly incorporate these augmented samples into the training set. Minimizing the average loss on all these samples means treating them equally, without considering their different implicit impacts on the loss.

To address this, we propose to minimize a reweighted loss on these augmented samples to make the model utilize them in a cleverer way. Example reweighting has previously been explored extensively in curriculum learning [\(Bengio et al., 2009;](#page-8-4) [Jiang et al., 2014\)](#page-9-2), boosting algorithms [\(Freund &](#page-8-5) [Schapire, 1999\)](#page-8-5), focal loss [\(Lin et al., 2017\)](#page-9-3) and importance sampling [\(Csiba & Richtárik, 2018\)](#page-8-6). However, none of them focus on the reweighting of augmented samples instead of the original training samples. A recent work [\(Jiang et al., 2020a\)](#page-9-4) also assigns different weights on augmented samples. But weights in their model are predicted by a mentor network while we obtain the weights from the closed-form solution by minimizing the maximal expected loss (MMEL). In addition, they focus on image samples with noisy labels, while our method can generally be applied to also textual data as well as image data. [Tran et al.](#page-10-3) [\(2017\)](#page-10-3) propose to minimize the loss on the augmented samples under the framework of Expectation-Maximization algorithm. But they mainly focus on the generation of augmented samples.

<sup>∗</sup>This work is done when Mingyang Yi is an intern at Huawei Noah's Ark Lab.

Unfortunately, in practise there is no way to directly access the optimal reweighting strategy. Thus, inspired by adversarial training [\(Madry et al., 2018\)](#page-9-5), we propose to minimize the maximal expected loss (MMEL) on augmented samples from the same training example. Since the maximal expected loss is the supremum over any possible reweighting strategy on augmented samples' losses, minimizing this supremum makes the model perform well under any reweighting strategy. More importantly, we derive a closed-form solution of the weights, where augmented samples with larger training losses have larger weights. Intuitively, MMEL allows the model to keep focusing on augmented samples that are harder to train.

The procedure of our method is summarized as follows. We first generate the augmented samples with commonly-used data augmentation technique, e.g., lexical substitution for textual input [\(Jiao](#page-9-1) [et al., 2019\)](#page-9-1), random crop and horizontal flip for image data [\(Krizhevsky et al., 2012\)](#page-9-6). Then we explicitly derive the closed-form solution of the weights on each of the augmented samples. After that, we update the model parameters with respect to the reweighted loss. The proposed method can generally be applied above any data augmentation methods in various domains like natural language processing and computer vision. Empirical results on both natural language understanding tasks and image classification tasks show that the proposed reweighting strategy consistently outperforms the counterpart of without using it, as well as other reweighting strategies like uniform reweighting.

## 2 RELATED WORK

Data augmentation. Data augmentation is proven to be an effective technique to improve the generalization ability of various tasks, e.g., natural language processing [\(Xie et al., 2019;](#page-10-2) [Zhu et al.,](#page-10-4) [2020;](#page-10-4) [Jiao et al., 2019\)](#page-9-1), computer vision [\(Krizhevsky et al., 2014\)](#page-9-7), and speech recognition [\(Park et al.,](#page-9-8) [2019\)](#page-9-8). For image data, baseline augmentation methods like random crop, flip, scaling, and color augmentation [\(Krizhevsky et al., 2012\)](#page-9-6) have been widely used. Other heuristic data augmentation techniques like Cutout [\(DeVries & Taylor, 2017\)](#page-8-7) which masks image patches and Mixup [\(Zhang](#page-10-5) [et al., 2018\)](#page-10-5) which combines pairs of examples and their labels, are later proposed. Automatically searching for augmentation policies [\(Cubuk et al., 2018;](#page-8-8) [Lim et al., 2019\)](#page-9-9) have recently proposed to improve the performance further. For textual data, [Zhang et al.](#page-10-6) [\(2015\)](#page-10-6); [Wei & Zou](#page-10-7) [\(2019\)](#page-10-7) and [Wang](#page-10-8) [\(2015\)](#page-10-8) respectively use lexical substitution based on the embedding space. [Jiao et al.](#page-9-1) [\(2019\)](#page-9-1); [Cheng et al.](#page-8-2) [\(2019\)](#page-8-2); [Kumar et al.](#page-9-10) [\(2020\)](#page-9-10) generate augmented samples with a pre-trained language model. Some other techniques like back translation [\(Xie et al., 2019\)](#page-10-2), random noise injection [\(Xie](#page-10-9) [et al., 2017\)](#page-10-9) and data mixup [\(Guo et al., 2019;](#page-8-9) [Cheng et al., 2020\)](#page-8-3) are also proven to be useful.

Adversarial training. Adversarial learning is used to enhance the robustness of model [\(Madry](#page-9-5) [et al., 2018\)](#page-9-5), which dynamically constructs the augmented adversarial samples by projected gradient descent across training. Although adversarial training hurts the generalization of model on the task of image classification [\(Raghunathan et al., 2019\)](#page-9-11), it is shown that adversarial training can be used as data augmentation to help generalization in neural machine translation [\(Cheng et al., 2019;](#page-8-2) [2020\)](#page-8-3) and natural language understanding [\(Zhu et al., 2020;](#page-10-4) [Jiang et al., 2020b\)](#page-9-12). Our proposed method differs from adversarial training in that we adversarially decide the weight on each augmented sample, while traditional adversarial training adversarially generates augmented input samples.

In [\(Behpour et al., 2019\)](#page-8-10), adversarial learning is used as data augmentation in object detection. The adversarial samples (i.e., bounding boxes that are maximally different from the ground truth) are reweighted to form the underlying annotation distribution. However, besides the difference in the model and task, their training objective and the resultant solution are also different from ours.

Sample reweighting. Minimizing a reweighted loss on training samples has been widely explored in literature. Curriculum learning [\(Bengio et al., 2009;](#page-8-4) [Jiang et al., 2014\)](#page-9-2) feeds first easier and then harder data into the model to accelerate training. [Zhao & Zhang](#page-10-10) [\(2014\)](#page-10-10); [Needell et al.](#page-9-13) [\(2014\)](#page-9-13); [Csiba & Richtárik](#page-8-6) [\(2018\)](#page-8-6); [Katharopoulos & Fleuret](#page-9-14) [\(2018\)](#page-9-14) use importance sampling to reduce the variance of stochastic gradients to achieve faster convergence rate. Boosting algorithms [\(Freund](#page-8-5) [& Schapire, 1999\)](#page-8-5) choose harder examples to train subsequent classifiers. Similarly, hard example mining [\(Malisiewicz et al., 2011\)](#page-9-15) downsamples the majority class and exploits the most difficult examples. Focal loss [\(Lin et al., 2017;](#page-9-3) [Goyal & He, 2018\)](#page-8-11) focuses on harder examples by reshaping the standard cross-entropy loss in object detection. [Ren et al.](#page-10-11) [\(2018\)](#page-10-11); [Jiang et al.](#page-9-16) [\(2018\)](#page-9-16); [Shu et al.](#page-10-12) [\(2019\)](#page-10-12) use meta-learning method to reweight examples to handle the noisy label problem. Unlike all

these existing methods, in this work, we reweight the augmented samples' losses instead of training samples.

## <span id="page-2-4"></span>3 MINIMIZE THE MAXIMAL EXPECTED LOSS

In this section, we derive our reweighting strategy on augmented samples from the perspective of maximal expected loss. We first give a derivation of the closed-form solution of the weights on augmented samples. Then we describe two kinds of loss under this formulation. Finally, we give the implementation details using the natural language understanding task as an example.

#### 3.1 WHY MAXIMAL EXPECTED LOSS

Consider a classification task with N training samples. For the i-th training sample x<sup>i</sup> , its label is denoted as yx<sup>i</sup> . Let fθ(·) be the model with parameter θ which outputs the classification probabilities. `(·, ·) denotes the loss function, e.g. the cross-entropy loss between outputs fθ(xi) and the groundtruth label yx<sup>i</sup> . Given an original training sample x<sup>i</sup> , the set of augmented samples generated by some method is B(xi). Without loss of generality, we assume x<sup>i</sup> ∈ B(xi). The conventional training objective is to minimize the loss on every augmented sample z in B(xi) as

<span id="page-2-0"></span>
$$
\min_{\theta} \frac{1}{N} \sum_{i=1}^{N} \left[ \frac{1}{|B(\boldsymbol{x}_{i})|} \sum_{(\boldsymbol{z}, y_{\boldsymbol{z}}) \in B(\boldsymbol{x}_{i})} \ell(f_{\theta}(\boldsymbol{z}), y_{\boldsymbol{z}}) \right],
$$
\n(1)

where y<sup>z</sup> is the label of z ∈ B(xi), and can be different with yx<sup>i</sup> . |B(xi)| is the number of augmented samples in B(xi), which is assumed to be finite.

In equation [\(1\)](#page-2-0), for each given x<sup>i</sup> , the weights on its augmented samples are the same (i.e., 1/|B(xi)|). However, different samples have different implicit impacts on the loss, and we can assign different weights on them to facilitate training. Note that computing the weighted sum of losses of each augmented sample in B(xi) can be viewed as taking expectation of loss on augmented samples z ∈ B(xi) under a certain distribution. When the augmented samples generated from the same training sample are drawn from a uniform distribution, the loss in equation [\(1\)](#page-2-0) can be rewritten as

$$
\min_{\theta} R_{\theta}(\mathbb{P}_U) = \min_{\theta} \frac{1}{N} \sum_{i=1}^N \left[ \mathbb{E}_{\mathbf{z} \sim \mathbb{P}_U(\cdot | \mathbf{x}_i)} \left[ \ell(f_{\theta}(\mathbf{z}), y_{\mathbf{z}}) \right] - \lambda_P \mathbf{KL}(\mathbb{P}_U(\cdot | \mathbf{x}_i) \parallel \mathbb{P}_U(\cdot | \mathbf{x}_i)) \right], \quad (2)
$$

where the Kullback–Leibler (KL) divergence KL(P<sup>U</sup> (· | xi) k P<sup>U</sup> (· | xi)) equals zero. Here P<sup>U</sup> (· | xi) denotes the uniform distribution on B(xi). When the augmented samples are drawn from a more general distribution PB(· | ·) [1](#page-2-1) instead of the uniform distribution, we can generalize P<sup>U</sup> (· | ·) here to some other conditional distribution PB.

<span id="page-2-2"></span>
$$
\min_{\theta} R_{\theta}(\mathbb{P}_{B}) = \min_{\theta} \frac{1}{N} \sum_{i=1}^{N} \left[ \mathbb{E}_{\mathbf{z} \sim \mathbb{P}_{B}(\cdot | \mathbf{x}_{i})} \left[ \ell(f_{\theta}(\mathbf{z}), y_{\mathbf{z}}) \right] - \lambda_{P} \mathbf{KL}(\mathbb{P}_{B}(\cdot | \mathbf{x}_{i}) \parallel \mathbb{P}_{U}(\cdot | \mathbf{x}_{i})) \right]. \tag{3}
$$

Remark 1. *When* PB(· | xi) *reduces to the uniform distribution* P<sup>U</sup> (· | xi) *for any* x<sup>i</sup> *, since* KL(P<sup>U</sup> (· | xi) k P<sup>U</sup> (· | xi)) = 0*, the objective in equation* [\(3\)](#page-2-2) *reduces to the one in equation* [\(1\)](#page-2-0)*.*

The KL divergence term in equation [\(3\)](#page-2-2) is used as a regularizer to encourage P<sup>B</sup> close to P<sup>U</sup> (see Remark [2\)](#page-3-0). From equation [\(3\)](#page-2-2), the conditional distribution P<sup>B</sup> determines the weights of each augmented sample in B(xi). There may exist an optimal formulation of P<sup>B</sup> in some regime, e.g. corresponding to the optimal generalization ability of model. Unfortunately, we can not explicitly characterize such an unknown optimal PB. To address this, we borrow the idea from adversarial training [\(Madry et al., 2018\)](#page-9-5) and minimize the maximal reweighted loss on augmented samples. Then, the model is guaranteed to perform well under any reweighting strategy, including the underlying optimal one. Specifically, let the conditional distribution P<sup>B</sup> be P ∗ <sup>θ</sup> = arg sup<sup>P</sup><sup>B</sup> <sup>R</sup>θ(PB). Our objective is to minimize the following reweighted loss

<span id="page-2-3"></span>
$$
\min_{\theta} R_{\theta}(\mathbb{P}_{\theta}^{*}) = \min_{\theta} \sup_{\mathbb{P}_{B}} R_{\theta}(\mathbb{P}_{B}).
$$
\n(4)

The following Remark [2](#page-3-0) discusses about the KL divergence term in equation [\(3\)](#page-2-2).

<span id="page-2-1"></span><sup>1</sup> In the following, we simplify PB(· | ·) as P<sup>B</sup> if there is no obfuscation.

<span id="page-3-0"></span>Remark 2. *Since we take a supremum over* P<sup>B</sup> *in equation* [\(4\)](#page-2-3)*, the regularizer* KL(P<sup>B</sup> k P<sup>U</sup> ) *encourages* P<sup>B</sup> *to be close to* P<sup>U</sup> *because it reaches the minimal value zero when* P<sup>B</sup> = P<sup>U</sup> *. Thus the regularizer controls the diversity among the augmented samples by constraining the discrepancy between* P<sup>B</sup> *and uniform distribution* P<sup>U</sup> *, e.g., a larger* λ<sup>P</sup> *promotes a larger diversity among the augmented samples.*

The following Theorem [1](#page-3-1) gives the explicit formulation of Rθ(P ∗ θ ).

<span id="page-3-1"></span>Theorem 1. *Let* Rθ(PB) *and* Rθ(P ∗ θ ) *be defined in equation* [\(1\)](#page-2-0) *and* [\(4\)](#page-2-3)*, then we have*

<span id="page-3-3"></span>
$$
R_{\theta}(\mathbb{P}_{\theta}^{*}) = \frac{1}{N} \sum_{i=1}^{N} \left[ \sum_{\mathbf{z} \in B(\mathbf{x}_{i})} \mathbb{P}_{\theta}^{*}(\mathbf{z} \mid \mathbf{x}_{i}) \ell(f_{\theta}(\mathbf{z}), y_{\mathbf{z}}) - \lambda_{P} \mathbb{P}_{\theta}^{*}(\mathbf{z} \mid \mathbf{x}_{i}) \log (|B(\mathbf{x}_{i})| \mathbb{P}_{\theta}^{*}(\mathbf{z} \mid \mathbf{x}_{i})) \right], \quad (5)
$$

*where*

<span id="page-3-2"></span>
$$
\mathbb{P}_{\theta}^{*}(z \mid x_{i}) = \frac{\exp\left(\frac{1}{\lambda_{P}}\ell(f_{\theta}(z), y_{z})\right)}{\sum_{z \in B(x_{i})} \exp\left(\frac{1}{\lambda_{P}}\ell(f_{\theta}(z), y_{z})\right)} = \text{Softmax}_{z} \left(\frac{1}{\lambda_{P}}\ell(f_{\theta}(B(x_{i})), y_{B(x_{i})})\right), \quad (6)
$$

*where* Softmaxz( 1 λ<sup>P</sup> `(fθ(B(xi)), yB(xi))) *represents the output probability of* z *for vector* ( 1 λ<sup>P</sup> `(fθ(z1), yz<sup>1</sup> ), · · · , 1 λ<sup>P</sup> `(fθ(z<sup>|</sup>B(xi)<sup>|</sup>), y<sup>|</sup>B(xi)<sup>|</sup>))*.*

Remark 3. *If we ignore the KL divergence term in equation* [\(3\)](#page-2-2)*, due to the equivalence of minimizing cross-entropy loss and MLE loss [\(Martens, 2019\)](#page-9-17), the proposed MMEL also falls into the generalized Expectation-Maximization (GEM) framework [\(Dempster et al., 1977\)](#page-8-12). Specifically, given a training example, the augmented samples of it can be viewed as latent variable, and any reweighting on these augmented samples corresponds to a specific conditional distribution of these augmented samples given the training sample. In the expectation step (E-step), we explicitly derive the closed-form solution of the weights on each of these augmented samples according to* [\(6\)](#page-3-2)*. In the maximization step, since there is no analytical solution for deep neural networks, following [\(Tran et al., 2017\)](#page-10-3), we update the model parameters with respect to the reweighted loss by one step of gradient descent.*

The proof of this theorem can be found in Appendix [A.](#page-11-0) From Theorem [1,](#page-3-1) the loss of it decides the weight on each augmented sample z ∈ Bx<sup>i</sup> , and the weight is normalized by Softmax over all augmented samples in Bx<sup>i</sup> . The reweighting strategy allows more attention paid to augmented samples with higher loss values. The strategy is similar to those in [\(Lin et al., 2017;](#page-9-3) [Zhao & Zhang,](#page-10-10) [2014\)](#page-10-10) but they apply it on training samples.

#### 3.2 TWO TYPES OF LOSS

For augmented sample z ∈ B(xi), instead of computing the discrepancy between the output probability fθ(z) and the hard label y<sup>z</sup> as in equation [\(5\)](#page-3-3), one can also compute the discrepancy between fθ(z) and the "soft" probability fθ(xi) in the absence of ground-truth label on augmented samples as in [\(Xie et al., 2019\)](#page-10-2). In the following, We use superscript "hard" for the loss in equation [\(5\)](#page-3-3) as

<span id="page-3-4"></span>
$$
R_{\theta}^{\text{hard}}(\mathbb{P}_{\theta}^*, \boldsymbol{x}_i) = \sum_{\boldsymbol{z} \in B(\boldsymbol{x}_i)} \mathbb{P}_{\theta}^*(\boldsymbol{z} \mid \boldsymbol{x}_i) \ell(f_{\theta}(\boldsymbol{z}), y_{\boldsymbol{z}})) - \lambda_P \mathbb{P}_{\theta}^*(\boldsymbol{z} \mid \boldsymbol{x}_i) \log(|B(\boldsymbol{x}_i)| \mathbb{P}_{\theta}^*(\boldsymbol{z} \mid \boldsymbol{x}_i)), \qquad (7)
$$

to distinguish with the following objective which uses the "soft probability":

$$
R_{\theta}^{\text{soft}}(\mathbb{P}_{\theta}^{*}, \boldsymbol{x}_{i}) = \ell(f_{\theta}(\boldsymbol{x}_{i}), y_{\boldsymbol{x}_{i}}) + \lambda_{T} \sum_{\boldsymbol{z} \in B(\boldsymbol{x}_{i}); \boldsymbol{z} \neq \boldsymbol{x}_{i}} (\mathbb{P}_{\theta}^{*}(\boldsymbol{z} \mid \boldsymbol{x}_{i}) \ell(f_{\theta}(\boldsymbol{z}), f_{\theta}(\boldsymbol{x}_{i})) - \lambda_{P} \mathbb{P}_{\theta}^{*}(\boldsymbol{z} \mid \boldsymbol{x}_{i}) \log (|B(\boldsymbol{x}_{i})| - 1) \mathbb{P}_{\theta}^{*}(\boldsymbol{z} \mid \boldsymbol{x}_{i})).
$$
\n(8)

The two terms in Rsoft θ (P ∗ θ , xi) respectively correspond to the loss on original training samples x<sup>i</sup> and the reweighted loss on the augmented samples. The reweighted loss promotes a small discrepancy between the augmented samples and the original training sample. λ<sup>T</sup> > 0 is the coefficient used to balance the two loss terms, and P ∗ θ (z | xi) is defined similar to [\(6\)](#page-3-2) as

<span id="page-3-6"></span><span id="page-3-5"></span>
$$
\mathbb{P}_{\theta}^{*}(z \mid x_{i}) = \frac{\exp\left(\frac{1}{\lambda_{P}}\ell(f_{\theta}(z), f_{\theta}(x_{i}))\right)}{\sum_{z \in B(x_{i}); z \neq x_{i}} \exp\left(\frac{1}{\lambda_{P}}\ell(f_{\theta}(z), f_{\theta}(x_{i}))\right)}.
$$
\n(9)

<span id="page-4-2"></span><span id="page-4-0"></span>![](_page_4_Figure_1.jpeg)

**Caption:** Figure 1 illustrates the performance of the proposed Maximal Expected Loss (MMEL) method using two types of losses: hard loss (1a) and soft loss (1b). The hard loss focuses on the discrepancy between model predictions and true labels, while the soft loss minimizes the difference between predictions of augmented samples and the original input. Both approaches demonstrate improved model accuracy across various tasks, highlighting the effectiveness of the reweighting strategy in enhancing generalization.

<span id="page-4-1"></span>Figure 1: MMEL with two types of losses. Figure [\(1a\)](#page-4-0) is the hard loss [\(7\)](#page-3-4) with probability computed using [\(6\)](#page-3-2) while Figure [\(1b\)](#page-4-1) is the soft loss [\(8\)](#page-3-5) with the probabilities computed using [\(9\)](#page-3-6).

<span id="page-4-3"></span>Algorithm 1 Minimize the Maximal Expected Loss (MMEL)

Input: Training set {(x1, yx<sup>1</sup> ), · · · ,(x<sup>N</sup> , yx<sup>N</sup> )}, batch size S, learning rate η, number of training iterations T, R<sup>θ</sup> equals Rhard θ or Rsoft θ .

1: for i in {1, 2, · · · , N} do . generate augmented samples 2: Generating B(xi) using some data augmentation method.

3: end for

4: **for** 
$$
t = 1, \dots, T
$$
 **do**  $\triangleright$  minimize the maximal expected loss

- 5: Randomly sample a mini-batch S = {(xi<sup>1</sup> , yxi<sup>1</sup> ), · · · ,(xi<sup>S</sup> , yxiS )} from training set.
- 6: Fetch the augmented samples B(xi<sup>1</sup> ), B(xi<sup>2</sup> ), · · · , B(xi<sup>S</sup> ).
- 7: Compute P ∗ θ according to [\(6\)](#page-3-2) or [\(9\)](#page-3-6).
- 8: Update model parameters θt+1 = θ<sup>t</sup> − η S P <sup>x</sup>∈S <sup>∇</sup>θRθ(<sup>P</sup> ∗ θ , x).

```
9: end for
```
The two losses are shown in Figure [1.](#page-4-2) Summing over all the training samples, we get the two kinds of reweighted training objectives.

Remark 4. *The proposed MMEL-S tries to reduce the discrepancy between* fθ(z) *and* fθ(xi) *for* z ∈ B(xi)*. However, if the prediction* fθ(xi) *is inaccurate, such misleading supervision for* z *may lead to the degraded performance of MMEL-S. More details are in Appendix [B.](#page-11-1)*

#### <span id="page-4-4"></span>3.3 EXAMPLE: MMEL IMPLEMENTATION ON NATURAL LANGUAGE UNDERSTANDING TASKS

In this section, we elaborate on implementing the proposed method using textual data in natural language understanding tasks as an example. Our method is separated into two phases. In the first phase, we generate augmented samples. Then in the second phase, with these augmented samples, we update the model parameters under these augmented samples with respect to the hard reweighted loss [\(7\)](#page-3-4) or the soft counterpart [\(8\)](#page-3-5). The generation and training procedure can be decoupled, and the augmented samples are offline generated in the first phase by only once. On the other hand, in the second phase, since we have the explicit solution of weights on augmented samples and the multiple forward and backward passes on these augmented samples can be computed in parallel, the whole training time is similar to the regular training counterpart for an appropriate number of augmented samples. The whole training process is shown in Algorithm [1.](#page-4-3)

Generation of Textual Augmented Data. Various methods have been proposed to generate augmented samples for textual data. Recently, large-scale pre-trained language models like BERT [\(Devlin](#page-8-0) [et al., 2019\)](#page-8-0) and GPT-2 [\(Radford et al., 2019\)](#page-9-18) learn contextualized representations and have been used widely in generating high-quality augmented sentences [\(Jiao et al., 2019;](#page-9-1) [Kumar et al., 2020\)](#page-9-10). In this paper, we use a pre-trained BERT trained from masked language modeling to generate augmented samples. For each original input sentence, we randomly mask k tokens. Then we do a forward propagation of the BERT to predict the tokens in those masked positions by greedy search. Details can be found in Algorithm [2](#page-12-0) in Appendix [C.](#page-12-1)

Mismatching Label. For Rhard θ in equation [\(7\)](#page-3-4), the loss term `(fθ(z), yz) on augmented sample z ∈ B(xi) for some x<sup>i</sup> relies on its label yz. Unlike image data, where conventional augmentation methods like random crop and horizontal flip of an image do not change its label, substituting even one word in a sentence can drastically change its meaning. For instance, suppose the original sentence is *"She is my daughter"*, and the word "She" is masked. The top 5 words predicted by the pre-trained BERT are "This, She, That, It, He". Apparently, for the task of linguistic acceptability task, replacing "She" with "He" can change the label from linguistically "acceptable" to "non-acceptable". Thus for textual input, for the term `(fθ(z), yz) in hard loss [\(7\)](#page-3-4), instead of directly setting y<sup>z</sup> as yx<sup>i</sup> [\(Zhu et al.,](#page-10-4) [2020\)](#page-10-4), we replace y<sup>z</sup> with the output probability of a trained teacher model. On the other hand, for the soft loss in equation [\(8\)](#page-3-5), if an augmented sample z ∈ B(xi) is predicted to a different class from x<sup>i</sup> by the teacher model, it is unreasonable to still minimize the discrepancy between fθ(z) and fθ(xi). In this case, we replace fθ(xi) in the loss term λ<sup>T</sup> P z∈B(xi);z6=x<sup>i</sup> P ∗ θ (z | xi)`(fθ(z), fθ(xi)) with the output probability from the teacher model.

## 4 EXPERIMENTS

In this section, we evaluate the efficacy of the proposed MMEL algorithm with both hard loss (MMEL-H) and soft loss (MMEL-S). Experiments are conducted on both the image classification tasks CIFAR-10 and CIFAR-100 [\(Krizhevsky et al., 2014\)](#page-9-7) with the ResNet Model [\(He et al.,](#page-9-0) [2016\)](#page-9-0), and the General Language Understanding Evaluation (GLUE) tasks [\(Wang et al., 2019\)](#page-10-13) with the BERT model [\(Devlin et al., 2019\)](#page-8-0).

#### <span id="page-5-0"></span>4.1 EXPERIMENTS ON IMAGE CLASSIFICATION TASKS.

Data. CIFAR [\(Krizhevsky et al., 2014\)](#page-9-7) is a benchmark dataset for image classification. We use both CIFAR-10 and CIFAR-100 in our experiments, which are colorful images with 50000 training samples and 10000 validation samples, but from 10 and 100 object classes, respectively.

Setup. The model we used is ResNet [\(He et al., 2016\)](#page-9-0) with different depths. We use random crop and horizontal flip [\(Krizhevsky et al., 2012\)](#page-9-6) to augment the original training images. Since these operations do not change the augmented sample label, we directly adopt the original training sample label for all its augmented samples. Following [\(He et al., 2016\)](#page-9-0), we use the SGD with momentum optimizer to train each model for 200 epochs. The learning rate starts from 0.1 and decays by a factor of 0.2 at epochs 60, 120 and 160. The batch size is 128, and weight decay is 5e-4. For each x<sup>i</sup> , |B(xi)| = 10. The λ<sup>P</sup> of the KL regularization coefficient is 1.0 for both MMEL-H and MMEL-S. The λ<sup>T</sup> in equation [\(8\)](#page-3-5) for MMEL-S is selected from {0.5, 1.0, 2.0}.

We compare our proposed MMEL with conventional training with data augmentation (abbreviated as "Baseline(DA)") under the same number of epochs. Though MMEL can be computed efficiently in parallel, the proposed MMEL encounters |B(xi)| = 10 times more training data. For fair comparison, we also compare with two other baselines that also use 10 times more data: (i) naive training with data augmentation but with 10 times more training epochs compared with MMEL (abbreviated as "Baseline(DA+Long)"). In this case, the learning rate accordingly decays at epochs 600, 1200 and 1600; (ii) training with data augmentation under the framework of MMEL but with uniform weights on the augmented samples (abbreviated as "Baseline(DA+UNI)").

Main Results. The results are shown in Table [1.](#page-6-0) As can be seen, for both CIFAR-10 and CIFAR-100, MMEL-H and MMEL-S significantly outperform the Baseline(DA), with over 0.5 points higher accuracy on all four architectures. Compared to Baseline(DA+Long), the proposed MMEL-H and MMEL-S also have comparable or better performance, while being much more efficient in training. This is because our backward pass only computes the gradient of the weighted loss instead of the separate loss of each example. Compared to Baseline(DA+UNI) which has the same computational cost as MMEL-H and MMEL-S, the proposed methods also have better performance. This indicates the efficacy of the proposed maximal expected loss based reweighting strategy.

We further evaluate the proposed method on larege-scale dataset ImageNet[\(Deng et al., 2009\)](#page-8-13). The detailed results are in Appendix [B.](#page-11-1)

| dataset   |       | Baseline(DA)          |      | Baseline(DA+Long) |       | Baseline(DA+UNI) |      | MMEL-H            |      | MMEL-S            |      |
|-----------|-------|-----------------------|------|-------------------|-------|------------------|------|-------------------|------|-------------------|------|
|           | Model | acc                   | time | acc               | time  | acc              | time | acc               | time | acc               | time |
|           |       | ResNet20 92.53(±0.10) |      | 0.7h 93.27        | 6.7h  | 93.00(±0.16)     |      | 2.9h 93.16(±0.03) |      | 2.9h 93.10(±0.18) | 2.9h |
| CIFAR-10  |       | ResNet32 93.46(±0.21) |      | 0.7h 94.43        | 7.2h  | 94.11(±0.33)     |      | 4.3h 94.31(±0.07) |      | 4.3h 93.93(±0.05) | 4.3h |
|           |       | ResNet44 93.92(±0.10) |      | 0.8h 94.11        | 8.3h  | 94.30(±0.18)     |      | 5.7h 94.70(±0.14) |      | 5.7h 94.48(±0.08) | 5.7h |
|           |       | ResNet56 93.96(±0.20) |      | 1.1h 94.12        | 10.6h | 94.62(±0.18)     |      | 7.0h 94.85(±0.15) |      | 7.0h 94.64(±0.03) | 7.0h |
|           |       | ResNet20 68.95(±0.56) |      | 0.7h 69.45        | 6.7h  | 68.89(±0.06)     |      | 2.9h 70.01(±0.07) |      | 2.9h 70.00(±0.07) | 2.9h |
|           |       | ResNet32 70.66(±0.16) |      | 0.7h 71.98        | 7.2h  | 71.59(±0.10)     |      | 4.3h 72.51(±0.07) |      | 4.3h 72.57(±0.20) | 4.3h |
| CIFAR-100 |       | ResNet44 71.43(±0.30) |      | 0.8h 72.83        | 8.3h  | 72.30(±0.38)     |      | 5.7h 73.18(±0.31) |      | 5.7h 72.89(±0.16) | 5.7h |
|           |       | ResNet56 72.22(±0.26) |      | 1.1h 73.09        | 10.6h | 73.44(±0.13)     |      | 7.0h 74.20(±0.24) |      | 7.0h 73.89(±0.15) | 7.0h |

<span id="page-6-0"></span>Table 1: Performance of ResNet on CIFAR-10 and CIFAR-100. The time is the training time measured on a single NVIDIA V100 GPU. The results of five independent runs with "mean (±std)" are reported, expected for "Baseline(DA + Long)" which is slow in training.

Varying the Number of Augmented Samples. One hyperparameter of the proposed method is the number of augmented samples |B(xi)|. In Table [2,](#page-6-1) we evaluate the effect of |B(xi)| on the CIFAR dataset. We vary |B(xi)| in {2, 5, 10, 20} for both MMEL-H and MMEL-S with other settings unchanged. As can be seen, the performance of MMEL improves with more augmented samples for small |B(xi)|. However, the performance gain begins to saturate when |B(xi)| reaches 5 or 10 for some cases. Since a larger |B(xi)| also brings more training cost, we should choose a proper number of augmented samples rather than continually increasing it.

<span id="page-6-1"></span>Table 2: Performance of MMEL on CIFAR-10 and CIFAR-100 with ResNet with varying |Bx<sup>i</sup> |. Here "MMEL-\*-k" means training with MMEL-\* loss with |B(xi)| = k. The results are averaged over five independent runs with "mean(±std)" reported.

|           |       |                                    | MMEL-*-2 |   | MMEL-*-5                  |   |                           | MMEL-*-10                                           | MMEL-*-20                              |              |
|-----------|-------|------------------------------------|----------|---|---------------------------|---|---------------------------|-----------------------------------------------------|----------------------------------------|--------------|
| dataset   | Model | Baseline(DA)                       | H        | S | H                         | S | H                         | S                                                   | H                                      | S            |
|           |       | ResNet20 92.53(±0.10) 92.77(±0.01) |          |   | 92.91(±0.21) 93.11(±0.13) |   | 92.89(±0.05) 93.16(±0.03) |                                                     | 93.10(±0.18) 93.57(±0.04)              | 93.18(±0.08) |
| CIFAR-10  |       | ResNet32 93.46(±0.21) 93.85(±0.16) |          |   | 93.88(±0.18) 94.20(±0.18) |   | 93.88(±0.14) 94.31(±0.07) |                                                     | 93.93(±0.05) 94.39(±0.09)              | 93.89(±0.17) |
|           |       | ResNet44 93.92(±0.10) 94.18(±0.12) |          |   | 93.87(±0.13) 94.51(±0.13) |   | 94.35(±0.07) 94.70(±0.14) |                                                     | 94.48(±0.08) 94.70(±0.20)              | 94.39(±0.11) |
|           |       | ResNet56 93.96(±0.20) 94.29(±0.08) |          |   | 94.43(±0.05) 94.78(±0.09) |   | 94.56(±0.15) 94.85(±0.15) |                                                     | 94.64(±0.03) 95.01(±0.12)              | 94.62(±0.12) |
|           |       | ResNet20 68.95(±0.56) 69.46(±0.24) |          |   | 70.00(±0.36) 69.73(±0.21) |   | 69.88(±0.18) 70.01(±0.07) |                                                     | 70.00(±0.07) 69.89(±0.09) 70.05(±0.23) |              |
|           |       | ResNet32 70.66(±0.16) 71.50(±0.09) |          |   | 71.37(±0.30) 72.41(±0.18) |   |                           | 71.73(±0.16) 72.51(±0.07) 72.57(±0.20) 72.25(±0.12) |                                        | 72.00(±0.12) |
| CIFAR-100 |       | ResNet44 71.43(±0.30) 72.58(±0.08) |          |   | 72.42(±0.24) 73.38(±0.07) |   | 72.92(±0.15) 73.18(±0.31) |                                                     | 72.89(±0.16) 73.23(±0.18)              | 72.77(±0.15) |
|           |       | ResNet56 72.22(±0.26) 73.11(±0.36) |          |   | 73.33(±0.30) 73.95(±0.04) |   | 73.47(±0.14) 74.20(±0.24) |                                                     | 73.89(±0.15) 74.10(±0.05)              | 73.53(±0.12) |

#### <span id="page-6-2"></span>4.2 RESULTS ON NATURAL LANGUAGE UNDERSTANDING TASKS

Data. GLUE is a benchmark containing various natural language understanding tasks, including textual entailment (RTE and MNLI), question answering (QNLI), similarity and paraphrase (MRPC, QQP, STS-B), sentiment analysis (SST-2) and linguistic acceptability (CoLA). Among them, STS-B is a regression task, CoLA and SST-2 are single sentence classification tasks, while the rest are sentence-pair classification tasks. Following [\(Devlin et al., 2019\)](#page-8-0), for the development set, we report Spearman correlation for STS-B, Matthews correlation for CoLA and accuracy for the other tasks. For the test set for QQP and MRPC, we report "F1".

Setup. The backbone model is BERTBASE [\(Devlin et al., 2019\)](#page-8-0). We use the method in Section [3.3](#page-4-4) to generate augmented samples. For the problem of mismatching label as described in Section [3.3,](#page-4-4) we use a BERTBASE model fine-tuned on the downstream task as teacher model to predict the label of each generated sample z in B(xi). For each x<sup>i</sup> , |B(xi)| = 5. The fraction of masked tokens for each sentence is 0.4. The λ<sup>P</sup> of the KL regularization coefficient is 1.0 for both MMEL-H and MMEL-S. The λ<sup>T</sup> in equation [\(8\)](#page-3-5) for MMEL-S is 1.0. The other detailed hyperparameters in training can be found in Appendix [D.](#page-12-2)

The derivation of MMEL in Section [3](#page-2-4) is based on the classification task, while STS-B is a regression task. Hence, we generalize our loss function accordingly for regression tasks as follows. For the hard loss in equation [\(7\)](#page-3-4), we directly replace y<sup>z</sup> ∈ R with the prediction of teacher model on z. For the soft loss [\(8\)](#page-3-5), for each entry of fθ(xi) in loss term λ<sup>T</sup> P z∈B(xi);z6=x<sup>i</sup> P ∗ θ (z | xi)MSE(fθ(z), fθ(xi)), we replace it with the prediction of teacher model if the difference between them is larger than 0.5.

Similar to Section [4.1,](#page-5-0) We compare with three baselines. However, we change the first baseline to naive training without data augmentation (abbreviated as "Baseline") since data augmentation is not used by default in NLP tasks. The other two baselines are similar to those in Section [4.1:](#page-5-0) (i) "Baseline(DA+Long)" which fine-tunes BERT with data augmentation with the same batch size; and

<span id="page-7-1"></span>![](_page_7_Figure_1.jpeg)

**Caption:** Figure 2 presents the development set results for the BERTBASE model utilizing different loss functions, including MMEL-H and MMEL-S. The accuracy trends indicate that both MMEL variants outperform baseline methods, particularly in tasks with smaller datasets. The figure emphasizes the faster convergence and superior performance of the proposed methods, showcasing their potential in natural language understanding tasks.

Figure 2: Development set results on BERTBASE model with different loss functions.

(ii)"Baseline(DA+UNI)" which fine-tunes BERT with augmented samples by using average loss. We also compare with another recent data augmentation technique SMART [\(Jiang et al., 2020b\)](#page-9-12).

<span id="page-7-0"></span>Table 3: Development and test sets results on the BERTBASE model. The training time is measured on a single NVIDIA V100 GPU. The results of Baseline, Baseline(DA+UNI), MMEL-H and MMEL-S are obtained by five independent runs with "mean(±std)" reported.

|      | Method            | CoLA<br>8.5k | SST-2<br>67k            | MRPC<br>3.7k                                                | STS-B<br>7k                         | QQP<br>364k             | MNLI-m/mm<br>393k                   | QNLI<br>108k | RTE<br>2.5k             | Avg                     | Time   |
|------|-------------------|--------------|-------------------------|-------------------------------------------------------------|-------------------------------------|-------------------------|-------------------------------------|--------------|-------------------------|-------------------------|--------|
|      | Baseline          | 59.7(±0.61)  | 93.1(±0.38)             | 87.0(±0.56)                                                 | 89.7(±0.34)                         | 91.1(±0.12)             | 84.6(±0.28)/85.0(±0.37)             | 91.7(±0.17)  | 69.7(±2.3)              | 83.5(±0.27)             | 21.5h  |
|      | Baseline(DA+Long) | 61.5         | 93.3                    | 88.0                                                        | 89.8                                | 91.1                    | 84.8/85.3                           | 92.0         | 73.3                    | 84.3                    | 107.5h |
|      | Baseline(DA+UNI)  | 61.1(±0.75)  | 93.1(±0.17)             | 87.9(±0.63)                                                 | 90.0(±0.14)                         | 91.1(±0.03)             | 84.8(±0.36)/85.1(±0.26)             | 91.9(±0.16)  | 71.8(±1.02)             | 84.1(±0.14)             | 31.6h  |
| Dev  | SMART             | 59.1         | 93.0                    | 87.7                                                        | 90.0                                | 91.5                    | 85.6/86.0                           | 91.7         | 71.2                    | 84.0                    | -      |
|      | MMEL-H            | 62.1(±0.55)  | 93.1(±0.14)             |                                                             | 87.7(±0.20) 90.4(±0.14) 91.5(±0.07) |                         | 85.3(±0.06)/85.5(±0.06)             | 92.2(±0.10)  | 72.3(±0.85)             | 84.5(±0.11)             | 31.8h  |
|      | MMEL-S            |              |                         | 62.1(±0.55) 93.5(±0.23) 88.4(±0.73) 90.4(±0.14) 91.5(±0.04) |                                     |                         | 85.2(±0.05)/85.6(±0.02) 92.4(±0.12) |              |                         | 71.9(±0.24) 84.6(±0.11) | 32.4h  |
|      | Baseline          | 51.6(±0.73)  | 93.3(±0.21)             | 88.0(±0.59)                                                 | 85.8(±0.88)                         | 71.3(±0.32)             | 84.6(±0.19)/83.8(±0.30)             | 91.1(±0.35)  | 67.4(±1.30)             | 79.6(±0.09)             | 21.5h  |
|      | Baseline(DA+Long) | 52.0         | 93.3                    | 88.8                                                        | 86.7                                | 71.3                    | 84.4/83.9                           | 90.9         | 69.6                    | 80.1                    | 107.5h |
| Test | Baseline(DA+UNI)  | 52.4(±1.50)  | 92.3(±0.52)             | 87.7(±0.72)                                                 | 85.8(±0.70)                         | 71.5(±0.44)             | 84.6(±0.31)/83.6(±0.46)             | 90.6(±0.43)  | 68.8(±1.76)             | 79.7(±0.50)             | 31.6h  |
|      | MMEL-H            | 53.6(±0.90)  | 93.4(±0.05)             | 88.3(±0.21)                                                 |                                     | 86.6(±0.45) 72.4(±0.05) | 84.9(±0.19)/84.5(±0.15) 91.5(±0.11) |              |                         | 69.8(±0.52) 80.5(±0.17) | 31.8h  |
|      | MMEL-S            |              | 52.5(±0.43) 93.5(±0.16) | 88.3(±0.15)                                                 | 86.1(±0.07)                         |                         | 72.1(±0.10) 85.0(±0.23)/84.2(±0.15) |              | 91.4(±0.31) 69.9(±0.54) | 80.3(±0.10)             | 32.4h  |

Main Results. The development and test set results on the GLUE benchmark are shown in Table [3.](#page-7-0) The development set results for the BERT baseline are from our re-implementation, which is comparable or better than the reported results in the original paper [\(Devlin et al., 2019\)](#page-8-0). The results for SMART are taken from [\(Jiang et al., 2020b\)](#page-9-12), and there are no test set results in [\(Jiang et al.,](#page-9-12) [2020b\)](#page-9-12). As can be seen, data augmentation significantly improves the generalization of GLUE tasks. Compared to the baseline without data augmentation (Baseline), MMEL-H or MMEL-S consistently achieves better performance, especially on small datasets like CoLA and RTE. Similar to the observation in the image classification task in Section [4.1,](#page-5-0) the proposed MMEL-H and MMEL-S are more efficient and have better performance than Baseline(DA+Long). MMEL-H and MMEL-S also outperform Baseline(DA+UNI), indicating the superiority of using the proposed reweighting strategy. In addition, our proposed method also beats SMART in both accuracy and efficiency because they use PGD-k [\(Madry et al., 2018\)](#page-9-5) to construct adversarial augmented samples which requires nearly k times more training cost. Figure [2](#page-7-1) shows the development set accuracy across over the training procedure. As can be seen, training with MMEL-H or MMEL-S converges faster and has better accuracy except SST-2 and RTE where the performance is similar.

Effect of Predicted Labels. For the augmented samples from same origin, we use a fine-tuned task-specific BERTBASE teacher model to predict their labels as mentioned in Section [3.3](#page-4-4) to handle the problem of mismatching label. In Table [4,](#page-8-14) we show the comparison between using the label of the original sample and using predicted labels. As can be seen, using the predicted label significantly improves the performance. By comparing with the results in Table [3,](#page-7-0) using the label of the original sample even hurts the performance.

<span id="page-8-14"></span>

| Method | Label     | CoLA | SST-2 | MRPC | STS-B | QQP  | MNLI-m/mm | QNLI | RTE  | Avg  |
|--------|-----------|------|-------|------|-------|------|-----------|------|------|------|
| MMEL-H | Original  | 48.8 | 91.5  | 79.2 | 80.3  | 88.6 | 80.4/79.8 | 88.8 | 65.3 | 78.1 |
| MMEL-H | Predicted | 62.8 | 93.3  | 87.5 | 90.4  | 91.6 | 85.4/85.6 | 92.1 | 72.2 | 84.5 |
| MMEL-S | Original  | 56.6 | 91.7  | 85.8 | 81.6  | 90.0 | 81.9/81.3 | 89.9 | 61.0 | 80.0 |
| MMEL-S | Predicted | 61.7 | 93.8  | 89.2 | 90.2  | 91.6 | 85.0/85.5 | 92.5 | 73.3 | 84.7 |

Table 4: Effect of using the predicted label. Development set results are reported.

## 5 CONCLUSION

In this work, we propose to minimize a reweighted loss over the augmented samples which directly considers their implicit impacts on the loss. Since we can not access the optimal reweighting strategy, we propose to minimize the supremum of the loss under all reweighting strategies, and give a closedform solution of the optimal weights. Our method can be applied on top of any data augmentation methods. Experiments on both image classification tasks and natural language understanding tasks show that the proposed method improves the generalization performance of the model, while being efficient in training.

## REFERENCES

- <span id="page-8-10"></span>S. Behpour, K. Kitani, and B. Ziebart. Ada: Adversarial data augmentation for object detection. In *IEEE Winter Conference on Applications of Computer Vision*, 2019.
- <span id="page-8-4"></span>Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In *International Conference on Machine Learning*, 2009.
- <span id="page-8-2"></span>Y. Cheng, L. Jiang, and W. Macherey. Robust neural machine translation with doubly adversarial inputs. In *Annual Meeting of the Association for Computational Linguistics*, 2019.
- <span id="page-8-3"></span>Y. Cheng, L. Jiang, W. Macherey, and J. Eisenstein. Advaug: Robust adversarial augmentation for neural machine translation. In *Annual Conference of the Association for Computational Linguistics*, 2020.
- <span id="page-8-6"></span>D. Csiba and P. Richtárik. Importance sampling for minibatches. *The Journal of Machine Learning Research*, 19(1):962–982, 2018.
- <span id="page-8-8"></span>E. D. Cubuk, B. Zoph, D. Mane, V. Vasudevan, and Q. V. Le. Autoaugment: Learning augmentation policies from data. Preprint arXiv:1805.09501, 2018.
- <span id="page-8-12"></span>A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. *Journal of the Royal Statistical Society: Series B (Methodological)*, 39(1):1–22, 1977.
- <span id="page-8-13"></span>J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In *2009 IEEE Conference on Computer Vision and Pattern Recognition*, 2009.
- <span id="page-8-0"></span>J. Devlin, M. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In *North American Chapter of the Association for Computational Linguistics*, 2019.
- <span id="page-8-7"></span>T. DeVries and G. W. Taylor. Improved regularization of convolutional neural networks with cutout. Preprint arXiv:1708.04552, 2017.
- <span id="page-8-5"></span>Y. Freund and R. Schapire. A short introduction to boosting. *Journal-Japanese Society For Artificial Intelligence*, 14(771-780):1612, 1999.
- <span id="page-8-1"></span>I. Goodfellow, Y. Bengio, and A. Courville. *Deep learning*, volume 1. 2016.
- <span id="page-8-11"></span>P. Goyal and K. He. Focal loss for dense object detection. *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 39:2999–3007, 2018.
- <span id="page-8-9"></span>H. Guo, Y. Mao, and R. Zhang. Augmenting data with mixup for sentence classification: An empirical study. Preprint arXiv:1905.08941, 2019.
- <span id="page-9-0"></span>K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In *IEEE Conference on Computer Vision and Pattern Recognition*, 2016.
- <span id="page-9-2"></span>L. Jiang, D. Meng, S. Yu, Z. Lan, S. Shan, and A. Hauptmann. Self-paced learning with diversity. In *Advances in Neural Information Processing Systems*, 2014.
- <span id="page-9-16"></span>L. Jiang, Z. Zhou, T. Leung, L. Li, and F. Li. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In *International Conference on Machine Learning*, 2018.
- <span id="page-9-4"></span>L. Jiang, D. Huang, M. Liu, and W. Yang. Beyond synthetic noise: Deep learning on controlled noisy labels. In *International Conference on Machine Learning*, 2020a.
- <span id="page-9-12"></span>P. Jiang, H.and He, W. Chen, X. Liu, J. Gao, and T. Zhao. Smart: Robust and efficient fine-tuning for pre-trained natural language models through principled regularized optimization. In *Annual Conference of the Association for Computational Linguistics*, 2020b.
- <span id="page-9-1"></span>X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, and Q. Liu. Tinybert: Distilling bert for natural language understanding. Preprint arXiv:1909.10351, 2019.
- <span id="page-9-14"></span>A. Katharopoulos and F. Fleuret. Not all samples are created equal: Deep learning with importance sampling. In *International Conference on Machine Learning*, 2018.
- <span id="page-9-6"></span>A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In *Advances in neural information processing systems*, 2012.
- <span id="page-9-7"></span>A. Krizhevsky, V. Nair, and G. Hinton. The cifar-10 dataset. *online: http://www. cs. toronto. edu/kriz/cifar. html*, 55, 2014.
- <span id="page-9-10"></span>V. Kumar, A. Choudhary, and E. Cho. Data augmentation using pre-trained transformer models. Preprint arXiv:2003.02245, 2020.
- J. Li, B. Ziebart, and B. Berger-Wolf. A game-theoretic adversarial approach to dynamic network prediction. In *Pacific-Asia Conference on Knowledge Discovery and Data Mining*, pp. 677–688. Springer, 2018.
- <span id="page-9-9"></span>S. Lim, I. Kim, T. Kim, C. Kim, and S. Kim. Fast autoaugment. In *Advances in Neural Information Processing Systems*, 2019.
- <span id="page-9-3"></span>T. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár. Focal loss for dense object detection. In *IEEE International Conference on Computer Vision*, 2017.
- <span id="page-9-19"></span>I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In *International Conference on Learning Representations*, 2018.
- <span id="page-9-5"></span>A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. In *International Conference on Learning Representations*, 2018.
- <span id="page-9-15"></span>T. Malisiewicz, A. Gupta, and A. A. Efros. Ensemble of exemplar-svms for object detection and beyond. In *International Conference on Computer Vision*, 2011.
- <span id="page-9-17"></span>J. Martens. New insights and perspectives on the natural gradient method. Preprint arXiv:1412.1193, 2019.
- <span id="page-9-13"></span>D. Needell, R. Ward, and N. Srebro. Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm. In *Advances in Neural Information Processing Systems*, 2014.
- <span id="page-9-8"></span>D. S. Park, W. Chan, Y. Zhang, C. Chiu, B. Zoph, E. D. Cubuk, and Q. V. Le. Specaugment: A simple data augmentation method for automatic speech recognition. In *Interspeech*, 2019.
- <span id="page-9-18"></span>A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised multitask learners. *OpenAI Blog*, 1(8):9, 2019.
- <span id="page-9-11"></span>A. Raghunathan, S. M. Xie, F. Yang, J. C Duchi, and P. Liang. Adversarial training can hurt generalization. Preprint arXiv:1906.06032, 2019.
- <span id="page-10-11"></span>M. Ren, W. Zeng, B. Yang, and R. Urtasun. Learning to reweight examples for robust deep learning. In *International Conference on Machine Learning*, 2018.
- <span id="page-10-12"></span>J. Shu, Q. Xie, L. Yi, Q. Zhao, S. Zhou, Z. Xu, and D. Meng. Meta-weight-net: Learning an explicit mapping for sample weighting. In *Advances in Neural Information Processing Systems*, 2019.
- <span id="page-10-0"></span>I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In *Advances in Neural Information Processing Systems*, 2014.
- <span id="page-10-3"></span>T. Tran, T. Pham, G. Carneiro, L. Palmer, and I. Reid. A bayesian data augmentation approach for learning deep models. In *Advances in Neural Information Processing Systems*, 2017.
- <span id="page-10-1"></span>A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N Gomez, Ł. Kaiser, and I. Polosukhin. Attention is all you need. In *Advances in Neural Information Processing Systems*, 2017.
- <span id="page-10-13"></span>A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. In *International Conference on Learning Representations*, 2019.
- <span id="page-10-8"></span>D. Wang, W. Y.and Yang. That's so annoying!!!: A lexical and frame-semantic embedding based data augmentation approach to automatic categorization of annoying behaviors using# petpeeve tweets. In *Conference on Empirical Methods in Natural Language Processing*, 2015.
- <span id="page-10-7"></span>J. Wei and K. Zou. Eda: Easy data augmentation techniques for boosting performance on text classification tasks. In *Conference on Empirical Methods in Natural Language Processing*, 2019.
- <span id="page-10-2"></span>Q. Xie, Z. Dai, E. Hovy, M. Luong, and Q. V. Le. Unsupervised data augmentation for consistency training. Preprint arXiv:1904.12848, 2019.
- <span id="page-10-9"></span>Z. Xie, S. I. Wang, J. Li, D. Lévy, A. Nie, D. Jurafsky, and A. Y. Ng. Data noising as smoothing in neural network language models. In *International Conference on Learning Representations*, 2017.
- <span id="page-10-14"></span>Y. Yang, L. Huang, and M. Ma. Breaking the beam search curse: A study of (re-) scoring methods and stopping criteria for neural machine translation. In *Conference on Empirical Methods in Natural Language Processing*, 2018.
- <span id="page-10-5"></span>H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz. mixup: Beyond empirical risk minimization. In *International Conference on Learning Representations*, 2018.
- <span id="page-10-6"></span>X. Zhang, J. Zhao, and Y. LeCun. Character-level convolutional networks for text classification. In *Advances in Neural Information Processing Systems*, 2015.
- <span id="page-10-10"></span>P. Zhao and T. Zhang. Accelerating minibatch stochastic gradient descent using stratified sampling. preprint arXiv:1405.3080, 2014.
- <span id="page-10-4"></span>C. Zhu, Y. Cheng, Z. Gan, S. Sun, T. Goldstein, and J. Liu. Freelb: Enhanced adversarial training for natural language understanding. In *International Conference on Learning Representations*, 2020.

## <span id="page-11-0"></span>A PROOF OF THEOREM [1](#page-3-1)

*Proof.* For any given x<sup>i</sup> and B(xi), we aim to find Pθ(· | xi) on B(xi) such that

$$
\max_{\mathbb{P}_{\theta}(\cdot|\boldsymbol{x}_{i})} \sum_{\boldsymbol{z}\in B(\boldsymbol{x}_{i})} \mathbb{P}_{\theta}(\boldsymbol{z} \mid \boldsymbol{x}_{i}) \ell(f_{\theta}(\boldsymbol{z}), y_{\boldsymbol{z}})) - \lambda_{P} \mathbb{P}_{\theta}(\boldsymbol{z} \mid \boldsymbol{x}_{i}) \log (|B(\boldsymbol{x}_{i})| \mathbb{P}_{\theta}(\boldsymbol{z} \mid \boldsymbol{x}_{i}))
$$
\n
$$
\text{s.t.} \sum_{\boldsymbol{z}\in B(\boldsymbol{x}_{i})} \mathbb{P}_{\theta}(\boldsymbol{z} \mid \boldsymbol{x}_{i}) = 1.
$$
\n(10)

Since the objective is convex, by Lagrange multiplier method, let

$$
\mathcal{L}(\mathbb{P}_{\theta}, \lambda) = \sum_{\mathbf{z} \in B(\mathbf{x}_i)} \mathbb{P}_{\theta}(\mathbf{z} \mid \mathbf{x}_i) \ell(f_{\theta}(\mathbf{z}), y_{\mathbf{z}})) - \lambda_P \mathbb{P}_{\theta}(\mathbf{z} \mid \mathbf{x}_i) \log (|B(\mathbf{x}_i)| \mathbb{P}_{\theta}(\mathbf{z} \mid \mathbf{x}_i)) + \lambda \left( \sum_{\mathbf{z} \in B(\mathbf{x}_i)} \mathbb{P}_{\theta}(\mathbf{z} \mid \mathbf{x}_i) - 1 \right).
$$
\n(11)

From ∇<sup>P</sup>θL(Pθ, λ) = ∇λL(Pθ, λ) = 0, for any pairs of zu, z<sup>v</sup> ∈ B(xi), we have

$$
\ell(f_{\theta}(\mathbf{z}_u), y_{\mathbf{z}_u}) - \lambda_P(\log |B(\mathbf{x}_i)| + 1 + \log \mathbb{P}_{\theta}(\mathbf{z}_u | \mathbf{x}_i))
$$
  
= 
$$
\ell(f_{\theta}(\mathbf{z}_v), y_{\mathbf{z}_v}) - \lambda_P(\log |B(\mathbf{x}_i)| + 1 + \log \mathbb{P}_{\theta}(\mathbf{z}_v | \mathbf{x}_i)).
$$
 (12)

Hence we have

$$
\mathbb{P}_{\theta}(\mathbf{z}_{v} \mid \mathbf{x}_{i}) = \mathbb{P}_{\theta}(\mathbf{z}_{u} \mid \mathbf{x}_{i}) \exp \left(\frac{\ell(f_{\theta}(\mathbf{z}_{v}), y_{\mathbf{z}_{v}}) - \ell(f_{\theta}(\mathbf{z}_{u}), y_{\mathbf{z}_{u}})}{\lambda_{P}}\right).
$$
(13)

Summing over z<sup>v</sup> ∈ B(xi), we have

$$
\mathbb{P}_{\theta}(z_u \mid \boldsymbol{x}_i) \sum_{\boldsymbol{z}_v \in B(\boldsymbol{x}_i)} \exp\left(\frac{\ell(f_{\theta}(\boldsymbol{z}_v), y_{\boldsymbol{z}_u}) - \ell(f_{\theta}(\boldsymbol{z}_u), y_{\boldsymbol{z}_u})}{\lambda_P}\right) = 1.
$$
 (14)

The proof completes.

## <span id="page-11-1"></span>B MMEL ON LARGE-SCALE DATASET

In this section, we evaluate the proposed method MMEL on large-scale image classification task ImageNet[\(Deng et al., 2009\)](#page-8-13).

Data. ImageNet is a benchmark dataset which contains colorful images with over 1 million training samples and 50000 validation samples from 1000 categories.

Setup. The model we used is ResNet for ImageNet with three different depths [\(He et al., 2016\)](#page-9-0). All these experiments are conducted for 100 epochs, and the learning rate decays at epochs 30, 60, and 90. We set batch size as 256, and |B(xi)| = 10 for each x<sup>i</sup> . The other experimental settings follow Section [4.1,](#page-5-0) expect for the following hyperparameters. We compare the proposed method with "Baseline(DA)".

Main Results. The results are shown in Table [5.](#page-12-3) From the results, the proposed MMEL-H improves the performance of the model for all three depths. However, the proposed MMEL-S is beaten by the baseline method. We speculate this is due to the relatively larger proportion of inaccurate prediction of original training samples on the large-scale dataset. More specifically, as in equation [\(8\)](#page-3-5), for each augmented sample z ∈ B(xi), the proposed MMEL-S encourages the model to fit the output of original training sample fθ(xi). However, the accuracy of the original training samples in the ImageNet dataset can not reach 100% e.g., about 80% for ResNet50 on ImageNet. The inaccurate prediction fθ(xi) can be a misleading supervision for augmented sample z ∈ B(xi), leading to degraded performance of the proposed MMEL-S. Thus, we suggest using the MMEL-H if the accuracy of the original training samples is relative low.

<span id="page-12-3"></span>

| dataset  | Model    | Baseline(DA) | MMEL-H       | MMEL-S       |
|----------|----------|--------------|--------------|--------------|
| ImageNet | ResNet18 | 69.76        | 70.48(+0.72) | 68.52(-1.24) |
|          | ResNet34 | 73.30        | 74.38(+1.08) | 72.33(-0.97) |
|          | ResNet50 | 76.15        | 76.53(+0.38) | 74.82(-1.33) |

Table 5: Performance of ResNet on ImageNet.

## <span id="page-12-1"></span>C GENERATING AUGMENTED SAMPLES FOR TEXTUAL SAMPLES

In this section, we elaborate the procedure of generating augmented sentences using greedy-based and beam-based method for a sequence. For each original input sentence, we randomly mask k tokens (which is obtained by rounding the product of masking ratio and length of the sequence to the nearest number) and then we do a forward propagation of the BERT to predict the tokens in those masked positions using greedy search. The detailed procedure is shown in Algorithm [2.](#page-12-0) We also use beam search [\(Yang et al., 2018\)](#page-10-14) to generate augmented data. The details of beam search can be referred to [\(Yang et al., 2018\)](#page-10-14). For sentence-pair tasks, we treat the two sentences separately and generate augmented samples for each of them.

<span id="page-12-0"></span>Algorithm 2 Augmented Sample Generation by Greedy Search

Input: Pre-trained language model BertModel, original sentence x, number of augmented samples |B(x)| − 1, number of masked tokens k. Output: Augmented samples B(x) = {z1, z2, · · · , z<sup>|</sup>B(x)|−1}. 1: Randomly sample k positions {p1, · · · , pk} and get xmask. 2: for i = 1, 2, · · · |B(x)| − 1 do . Generate the i-th augmented sample 3: z<sup>i</sup> ← xmask. 4: z<sup>i</sup> [p1] ← the ith most likely word predicted by BertModel(z<sup>i</sup> [p1]|zi). 5: for j in {2, 3. · · · , k} do 6: z<sup>i</sup> [p<sup>j</sup> ] ← the most likely word predicted by BertModel(z<sup>i</sup> [p<sup>j</sup> ]|zi). 7: end for 8: end for

In the following, we vary the factors that may affect the quality of the generated augmented samples. These factors include

- 1. The number of masked tokens, which equals the replacement proportion multiplied with the sentence length. This affects the diversity of augmented samples, i.e., replacing a large proportion of tokens makes the augmented sample less similar to the original one.
- 2. Treating the two sentences separately in sentence-pair tasks when generating augmented examples, or concatenate them as a single sentence;
- 3. Different generation methods like greedy search (Algorithm [2\)](#page-12-0) and beam search.

The results are shown in Table [6.](#page-13-0) As can be seen, compared with Baseline without data augmentation, MMEL-H and MMEL-S under all hyperparameter configurations have higher accuracy, showing the efficacy of data augmentation and the proposed reweighting strategy. There is no significant difference in using greedy search or beam search to generate the augmented samples. In this natural understanding task, training with augmented samples generated with proper larger replacement proportion (i.e., larger diversity) has slightly better performance. For sentence-pair tasks, treating the two sentences separately and generate augmented samples for each of them has slightly better performance. In the experiments in Section [4.2,](#page-6-2) we use Greedy search, masking proportion 0.4, and generate augmented sentence for each sentence in sentence-pair tasks.

## <span id="page-12-2"></span>D HYPERPARAMETERS FOR THE EXPERIMENT ON THE GLUE BENCHMARK.

The optimizer we used is AdamW [\(Loshchilov & Hutter, 2018\)](#page-9-19). The hyperparameters of BERTBASE model are listed in Table [7.](#page-13-1)

|        |        | Separate      | Replacement | CoLA | SST-2 | MRPC | STS-B | QQP  | MNLI-m/mm | QNLI | RTE  | Avg  |
|--------|--------|---------------|-------------|------|-------|------|-------|------|-----------|------|------|------|
|        | Method | sentence-pair | proportion  |      |       |      |       |      |           |      |      |      |
|        |        | Baseline      |             | 59.0 | 93.3  | 87.5 | 89.8  | 91.3 | 84.6/85.0 | 91.4 | 71.1 | 83.7 |
|        | Greedy | True          | 0.2         | 60.2 | 93.1  | 87.7 | 90.0  | 91.5 | 85.4/85.6 | 92.4 | 71.5 | 84.1 |
|        | Greedy | True          | 0.4         | 62.8 | 93.3  | 87.5 | 90.4  | 91.6 | 85.4/85.6 | 92.1 | 72.2 | 84.5 |
|        | Greedy | False         | 0.2         | 60.2 | 93.6  | 87.0 | 89.8  | 91.5 | 85.4/85.7 | 92.5 | 69.3 | 84.0 |
| MMEL-H | Greedy | False         | 0.4         | 61.8 | 92.7  | 88.0 | 90.0  | 91.5 | 85.3/85.5 | 92.2 | 72.2 | 84.4 |
|        | Beam   | True          | 0.2         | 60.0 | 93.2  | 87.0 | 90.0  | 91.4 | 85.5/85.5 | 92.4 | 71.1 | 84.0 |
|        | Beam   | True          | 0.4         | 60.8 | 93.1  | 88.0 | 90.3  | 91.3 | 85.3/85.5 | 92.3 | 70.3 | 84.5 |
|        | Beam   | False         | 0.2         | 60.0 | 93.5  | 86.7 | 89.8  | 91.5 | 85.6/85.7 | 92.3 | 70.4 | 83.9 |
|        | Beam   | False         | 0.4         | 60.8 | 93.1  | 88.0 | 90.0  | 91.4 | 85.3/85.5 | 92.3 | 70.4 | 84.1 |
|        | Greedy | True          | 0.2         | 61.0 | 93.1  | 87.0 | 89.5  | 91.6 | 85.5/85.8 | 92.1 | 71.8 | 84.2 |
|        | Greedy | True          | 0.4         | 61.7 | 93.8  | 89.2 | 90.2  | 91.6 | 85.0/85.5 | 92.5 | 73.3 | 84.7 |
|        | Greedy | False         | 0.2         | 61.0 | 93.6  | 86.5 | 89.9  | 91.6 | 85.6/86.2 | 92.5 | 69.3 | 84.0 |
|        | Greedy | False         | 0.4         | 61.8 | 93.0  | 87.7 | 90.0  | 91.6 | 85.1/85.6 | 92.5 | 72.2 | 84.4 |
| MMEL-S | Beam   | True          | 0.2         | 62.0 | 92.9  | 86.7 | 89.9  | 91.5 | 85.4/85.9 | 92.5 | 71.8 | 84.2 |
|        | Beam   | True          | 0.4         | 61.0 | 93.0  | 87.7 | 90.2  | 91.4 | 85.2/85.5 | 92.2 | 73.6 | 84.0 |
|        | Beam   | False         | 0.2         | 62.0 | 93.3  | 86.7 | 89.7  | 91.6 | 85.3/85.9 | 92.4 | 70.0 | 84.1 |
|        | Beam   | False         | 0.4         | 61.0 | 93.1  | 88.2 | 89.7  | 91.4 | 85.2/85.7 | 92.2 | 72.2 | 84.3 |

<span id="page-13-0"></span>Table 6: Ablation study on generating augmented samples on the GLUE benchmark. Development set results are reported.

Table 7: Hyperparameters of the BERTBASE model.

<span id="page-13-1"></span>

| Hyperparam                         | MMEL-H   | MMEL-S   |
|------------------------------------|----------|----------|
| Learning Rate                      | 3e-5     | 3e-5     |
| Batch Size                         | 32       | 32       |
| Weight Decay                       | 0        | 0        |
| Hidden Layer Dropout Rate          | {0, 0.1} | {0, 0.1} |
| Attention Probability Dropout Rate | {0, 0.1} | {0, 0.1} |
| Max Epochs (MNLI, QQP)             | 3        | 3        |
| Max Epochs (Others)                | 10       | 10       |
| Learning Rate Decay                | Linearly | Linearly |
| Warmup Ratio                       | 0        | 0        |
| λT                                 | 1.0      | 1.0      |
| λP                                 | 1.0      | 1.0      |
| Number of Candidates ( B(xi) )     | 5        | 5        |