# Dynamic Data Augmentation via Monte-Carlo Tree Search for Prostate MRI Segmentation

Xinyue Xu 1 ⋆ , Yuhan Hsi 2 ⋆ , Haonan Wang 3 , and Xiaomeng Li1( )

<sup>1</sup> The Hong Kong University of Science and Technology, Hong Kong xxucb@connect.ust.hk, eexmli@ust.hk

<sup>2</sup> The Pennsylvania State University, State College PA, USA ybh5084@psu.edu <sup>3</sup> The University of Hong Kong, Hong Kong

haonanw@connect.hku.hk

Abstract. Medical image data are often limited due to the expensive acquisition and annotation process. Hence, training a deep-learning model with only raw data can easily lead to overfitting. One solution to this problem is to augment the raw data with various transformations, improving the model's ability to generalize to new data. However, manually configuring a generic augmentation combination and parameters for different datasets is non-trivial due to inconsistent acquisition approaches and data distributions. Therefore, automatic data augmentation is proposed to learn favorable augmentation strategies for different datasets while incurring large GPU overhead. To this end, we present a novel method, called Dynamic Data Augmentation (DDAug), which is efficient and has negligible computation cost. Our DDAug develops a hierarchical tree structure to represent various augmentations and utilizes an efficient Monte-Carlo tree searching algorithm to update, prune, and sample the tree. As a result, the augmentation pipeline can be optimized for each dataset automatically. Experiments on multiple Prostate MRI datasets show that our method outperforms the current state-of-the-art data augmentation strategies.

Keywords: Prostate MRI Segmentation · Data Augmentation · Auto ML

# 1 Introduction

The prostate is an important reproductive organ for men. The three most prevalent forms of prostate disease are inflammation, benign prostate enlargement, and prostate cancer. A person may experience one or more of these symptoms. Accurate MRI segmentation is crucial for the pathological diagnosis and prognosis of prostate diseases [\[17\]](#page-10-0). Manual prostate segmentation is a time-consuming task that is subject to inter and intra-observer variability [ [6\]](#page-9-0). The development of deep learning has led to significant advancements in many fields, including

<sup>⋆</sup> Both authors contributed equally to this work.

computer-assisted intervention. With the advancement of technology, clinical applications of deep learning techniques have increased. There are multiple deep learning networks [\[10,](#page-10-1)[18,](#page-10-2)[28\]](#page-11-0) designed to enhance the accuracy of automatic prostatic segmentation. Different neural network structures, such as Vnet [\[18\]](#page-10-2), U-Net [\[21\]](#page-10-3) and its variant nnUNet [\[9\]](#page-10-4), can all be utilized for prostate segmentation. These methods are all from the perspective of modifying the model structure to improve the segmentation accuracy. However, in medical image segmentation tasks, carefully designed network structure is prone to overfitting due to limited data. To alleviate the data shortage, data augmentation is an effective means of enhancing segmentation performance and model generalizability simultaneously on small datasets.

Data augmentation aims to generate more data from the raw samples via pre-defined transformations, which helps to diversify the original dataset [\[22\]](#page-10-5). Typical data augmentation techniques include affine transformations (e.g., rotation, flipping, and scaling), pixel-level transformation (e.g., gaussian nosie and contrast adjustment), and elastic distortion. For prostate MRI data, affine transformation or GAN-based methods are frequently used [\[5\]](#page-9-1). However, the augment selection and combination process that utilizes these aforementioned transformations are predominantly hand-crafted. It is difficult to identify which operations are actually useful for the prostate segmentation task, thus often resulting in sub-optimal combinations, or even degrading network performance. Automatic data augmentation, with its ability to design different combinations, its flexibility to remove useless augment operations, and its utilization of quantifiable metrics, is a crucial technology that can solve this problem. Approaches to automatic data augmentation need to strike a balance between simplicity, cost, and performance [\[19\]](#page-10-6). In the field of natural image, early automatic augmentation techniques [\[2,](#page-9-2) [8,](#page-9-3) [13,](#page-10-7) [25\]](#page-11-1) were GPU-intensive. Subsequently, RandAugment [\[3\]](#page-9-4), UniformAugment [\[14\]](#page-10-8), and TrivialAugment [\[19\]](#page-10-6) substantially decreased the search cost while maintaining performance. Due to the variation between medical (spatial context information and different morphologies of lesions and tissues) and natural images, directly applying these approaches is either ineffective or unsuitable. The earliest work [\[27\]](#page-11-2) utilized reinforcement learning (RL) for automatic medical data augmentation, but it required a significant amount of computing resources. The state-of-the-art automatic data augmentation framework (ASNG) algorithm [\[26\]](#page-11-3) formulated the automatic data augmentation problem as bi-level optimization and applied the approximation algorithm to solve it. Although it is more efficient than reinforcement learning, the time required to find a reasonable strategy can still be highly demanding. Furthermore, using only rudimentary spatial transforms can limit performance, and some state-of-the-art methods involve searching the probability of operation, which can make the training process inefficient.

To this end, we propose a novel automatic augmentation strategy Dynamic Data Augmentation (DDAug) for MRI segmentation. Automatic data augmentation problem is formulated into the Monte-Carlo tree search problem for the first time. The augmentation pipeline is represented as a tree structure, which is iteratively refined through updating, pruning, and sampling. In contrast to the previous method, our approach expands the search space by including more spatial augmentations and allows the tree structure to determine the optimal sequence of augmentations while removing redundant ones. Moreover, our method's flexibility in selecting operations without having to search for the probability significantly enhances its search efficiency. Our method adopts a novel approach by using only a few augmentation operations at a time, yet achieving an effect similar to that of manually combining multiple operations. Our DDAug method achieves an optimal balance between simplicity, cost, and performance when compared to previous approaches. Code and documentation are available at [https://github.com/xmed-lab/DDAug.](https://github.com/xmed-lab/DDAug)

# 2 Methodology

Automatic augmentation search spaces and Monte-Carlo tree search constitute our method. We meticulously selected a number of dependable operations on medical images to compose our search space for the tree's construction. The search space consists of pixel-level and spatial-level transformations, as well as the left and right ranges of their respective magnitudes. After the tree is constructed, a path is chosen for each training epoch, which is updated by the validation loss, and nodes and their children in the chosen path that degrade model performance are pruned. Finally, the path of the subsequent epoch is chosen by random or Upper Confidence Bounds applied to Trees (UCT) [\[1\]](#page-9-5) sampling for different layers, and the cycle continues until training is complete. Fig. [1](#page-2-0) illustrates the procedure of the complete tree and the whole training process can be summarized in Algorithm [1.](#page-4-0) We will elaborate on each section below.

<span id="page-2-0"></span>![](_page_2_Figure_4.jpeg)

**Caption:** Figure 1 illustrates the four stages of the Monte-Carlo Tree Search (MCTS) used in the Dynamic Data Augmentation (DDAug) method. The hierarchical tree structure represents various augmentation operations, which are updated and pruned based on validation loss to optimize the augmentation pipeline for prostate MRI segmentation tasks.

Fig. 1: Four Stages of Monte-Carlo Tree Search.

### 2.1 Search Space

The design of our search space is crucial to the performance of the final network. To compensate for the absence of spatial-level augmentation operations, optical distortion, elastic transformation, and grid distortion are added. Table [1](#page-3-0) displays the complete search space. To better assess the efficacy of various operations in relation to their magnitude, we divide the magnitude into left-range and right-range whenever possible. Operations like brightness transform exhibit left-range (decrease brightness) or right-range (increase brightness). The random crop operation will pad the data by first padding it with a stochastically selected percentage, then randomly crop the padded data to its original size. Unlike brightness transform, random crop only has one magnitude range. This division allows for more precise control over the magnitude range without significantly increasing tree size. The operations of the root type pertain to the subsequent construct tree. These are necessary augmentation operations for each path and are not involved in the search. We forego the search for augmentation probability for two reasons. First, it would significantly increase the size of the tree, making search inefficient. Second, if a particular operation and magnitude range combination increases validation performance, it will be sampled more frequently. And if the combination is prone to degrade network performance, it will be swiftly removed.

| Operations             | LR        | RR       | Type                   |  |
|------------------------|-----------|----------|------------------------|--|
| Mirror                 | -         | -        | root                   |  |
| Random Crop            | (0%, 33%) | -        | root                   |  |
| Contrast Adjustment    | (0.5, 1)  | (1, 1.5) | pixel-level            |  |
| Gamma Transform        | (0.5, 1)  | (1, 1.5) | pixel-level            |  |
| Brightness Transform   | (0.5, 1)  | (1, 1.5) | pixel-level            |  |
| Gaussian Noise         | (0, 0.1)  | -        | pixel-level            |  |
| Gaussian Blur          | (0.5, 1)  | (1, 1.5) | pixel-level            |  |
| Simulate low-res image | (0.5, 1)  | -        | pixel-level            |  |
| Scale                  | (0.5, 1)  |          | (1, 1.5) spatial-level |  |
| Optical Distortion     | (0, 0.05) | -        | spatial-level          |  |
| Elastic Transform      | (0, 50)   | -        | spatial-level          |  |
| Grid Distortion        | (0, 0.3)  | -        | spatial-level          |  |

<span id="page-3-0"></span>Table 1: Augmentation Search Space. The root type refers to must-do operations at the beginning of path selection. '-' denotes range not applicable.

## 2.2 Tree Construction

Similar to tree nodes, different augmentation operations can be connected to create various augmentation combinations. Additionally, we must consider their order when using a sequence of augmentations. This resembles the structure of a tree very closely. For efficient search purposes, we encode the automatic data augmentation as a tree structure. To construct our tree using the specified search space, we begin by generating a root node with mirror and random crop operations. These operations serve as a set of foundational augmentations and are always applied prior to the augmentation path chosen by tree search for each epoch. The remaining augmentation operations will participate in the search, and we use a three-layer tree structure to load the search space. Each node in the first layer is an augmentation operation, and their child nodes are the augmentation operations that do not include their parent. There are no duplicate operations on a single path, and no two paths have the same order of operations. The first augment path is initialized as the leftmost path of the tree.

### <span id="page-4-0"></span>Algorithm 1 Training Process of DDAug

|     | 1: Initialize the augmentation tree.                   |
|-----|--------------------------------------------------------|
|     | 2: Set the leftmost path as the first augment path.    |
|     | 3: for each epoch do                                   |
| 4:  | Train the model and calculate the validation loss.     |
| 5:  | for each node in previously selected path do           |
| 6:  | Update node Q-value (Eq. 2) using moving average loss. |
| 7:  | Record validation loss change Lnode.                   |
| 8:  | if Past P5<br>n=1 Lnode<br>> 0 then                    |
| 9:  | Delete the current node and subtree of this node.      |
| 10: | Break;                                                 |
| 11: | end if                                                 |
| 12: | end for                                                |
| 13: | while not at leaf node do                              |
| 14: | if mean visited times < kuct<br>then                   |
| 15: | Sample node using Random sampling.                     |
| 16: | else                                                   |
| 17: | Sample node using UCT sampling (Eq. 4).                |
| 18: | end if                                                 |
| 19: | end while                                              |
| 20: | Finish sampling path for next epoch.                   |
|     | 21: end for                                            |
|     | 22: Inference and report testing data performance.     |

### 2.3 Tree Updating and Pruning

With the initialized path during tree construction, we train the model for one epoch per path and calculate the validation loss Lval. The validation loss is computed utilizing the original nnUNet CE + DICE loss. The validation loss is then employed to update the tree by calculating the moving average loss Lma using the following formula:

$$
L_{ma} = \beta \cdot L_{val}^{t-1} + (1 - \beta) \cdot L_{val}^t \tag{1}
$$

where β ∈ [0, 1] controls the ratio of current validation loss. L t−1 val is the validation loss of the previous epoch, while L t val represents the validation loss of the current epoch. We then update the Q-value of all nodes in the previously selected path with:

<span id="page-5-0"></span>
$$
Q = \frac{L_{ma}}{L_{val}^t} \tag{2}
$$

A record of validation loss change Lnode = L t val −L t−1 val is kept for all nodes to evaluate their overall impact on network performance. As we traverse the path to update the Q-value, if the sum of the previous five Lnode scores is greater than 0, the node is deemed to have a negative impact on the network's performance and is pruned from the tree.

### 2.4 Tree Sampling

After the pruning process, a new path needs to be chosen for the subsequent epoch. Because the nodes have not yet been visited, we use random sampling rather than Monte-Carlo UCT sampling at the beginning of the network training process. We compare the kuct threshold to the average visited times of the current layer to determine when to switch to UCT sampling. The value of kuct is set to 3, 1, and 1 times, for the first, second, and third layers of the tree, respectively. The number of tree layers is expandable, but increasing the number of layers will lead to the exponential growth of search space, which is not conducive to search efficiency. At the same time, if the tree has less than three layers, the amount of nodes and paths is extremely limited, thus decreasing the diversity introduced via data augmentation.

Inspired by [\[24\]](#page-10-9), we introduce a node communication term S to better evaluate the current node's efficacy using nodes' Q-value of nodes from the same layer that has the same augment operation and magnitude range as the current node.

$$
S(v_i^l) = (1 - \lambda) \cdot Q(v_i^l) + \lambda \cdot \sum_{j=0}^n \frac{Q(v_j^l)}{n}
$$
 (3)

where v l i is the i-th child node in the l-th layer, v l j is the other nodes that have the same operation and magnitude range as v<sup>i</sup> in the l-th layer, and n denotes the total number of v l j . λ controls the effect of the node communication term.

When the averaged visited times of all children of the current node exceeds kuct, we employ the following equation to calculate the UCT [\[11,](#page-10-10)[24\]](#page-10-9) score for all children of the current node:

<span id="page-5-1"></span>
$$
UCT(v_i^l) = \frac{Q(v_i^l)}{n_i^l} + C_1 \sqrt{\frac{\log(n_p^{(l-1)})}{n_i^l}} + C_2 \cdot S(v_i^l)
$$
\n(4)

where n l i is the number of visited times of v l i , and n (l−1) <sup>p</sup> is the visited times of its parent node in the (l − 1)-th layer.

A temperature term τ [\[20\]](#page-10-11) is utilized to promote greater discrimination between candidates by amplifying score differences, thus the sampling probability can be calculated as

$$
P(v_i^l) = \frac{\exp(\frac{UCT(v_i^l)}{\tau})}{\sum_j^n \exp(\frac{UCT(v_j^l)}{\tau})}
$$
\n
$$
(5)
$$

where v l i are children of the current node. We sample a node from the current group of children using the probabilities calculated, then continue the sampling process until a leaf node is reached. Reaching a leaf node signifies the termination of the sampling process for the current epoch, and the selected path will be adopted in the next epoch. This cycle repeats at the end of every epoch until maximum the training epochs are reached.

# 3 Implementation and Experiments

### 3.1 Datasets and Implementation Details

Datasets. We conduct our experiments on several 3d Prostate MRI datasets: subset 1 and 2 are from NCI-ISBI 2013 challenge [\[4\]](#page-9-6), subset 3 is from I2CVB benchmarking [\[12\]](#page-10-12), subset 4, 5, 6 are from PROMISE12 [\[15\]](#page-10-13), and subset 7 is the Task 005 prostate dataset from Medical Segmentation Decathlon [\[23\]](#page-10-14). Subsets 1 through 6 are acquired from and have been resized by [\[16\]](#page-10-15). All datasets are then resampled and normalized to zero mean and unit variance as described in nnUNet [\[9\]](#page-10-4).

Implementation Details. For a fair comparison, we base our implementation on the original nnUNet repository. We only inserted additional code for the implementation of DDAug while keeping model architecture and self-configuration process intact. To conduct 5-fold cross-validation, we utilized stochastic gradient descent with Nesterov momentum and set the learning rate of 0.01. Each fold trains for 200 epochs, and each epoch has 250 batches with a batch size of 2. The runtime comparison can be found in Table [2.](#page-6-0) The utilization of Reinforcement Learning and ASNG method demand substantial GPU resources. In contrast, our approach performs at an equivalent efficiency to the original nnUnet data augmentation.

<span id="page-6-0"></span>Table 2: Comparison of GPU costs with different augmentation methods.

| Method       |     |     | RL [27] ASNG [7, 26] DDAug (Ours) nnUNet [9] |    |
|--------------|-----|-----|----------------------------------------------|----|
| Cost (hours) | 768 | 100 | 40                                           | 40 |

Compared Methods. Since ASNG [\[26\]](#page-11-3) requires ten days of GPU processing time and our objective is to create an effective and efficient automated search method, we only compare our implementations on nnUNet that has the same GPU runtime requirements. Limited by the size of each subset, we conduct all of our experiments using 5-fold cross-validation and report the mean validation DICE score inferred with weights from the last epoch. Our baselines are established via training nnUNet using no augmentations (NoDA) and using default augmentations (moreDA). The 'moreDA' is a set of sequential augmentations including scaling, rotating, adding gaussian noise, adding gaussian blur, transforming with multiplicative brightness, transforming with contrast augmentation, simulating low resolution, performing gamma transform, and mirroring axis.

Ablation Study. In our ablation study, we start by replacing the sequential augment operations in moreDA with the uniform sampling mechanism described TrivialAugment [\[19\]](#page-10-6). This allows us to assess the viability of using the natural image SOTA approach on medical image. To evaluate the effectiveness of the proposed search space, we extend moreDA's operation search space with additional spatial augmentations (Spatial SS). Finally, we replace moreDA with DDAug to examine the advantage of using the expanded search space inconjunction with Monte-Carlo Tree Search (MCTS).

### 3.2 Experimental Results

<span id="page-7-0"></span>Table 3: Augmentation performance of different Prostate datasets on Dice (%). Subsets represent different prostate datasets and the backbone is nnUNet. NoDA: No augmentation; moreDA: sequential augmentation; Spatial SS: our designed search space; TrivialAugment: natural image SOTA method; DDAug: MCTS + our search space (proposed method). red, blue denote the highest and second highest score.

| Method            |       |       |       |       |       |       | Subset 1 Subset 2 Subset 3 Subset 4 Subset 5 Subset 6 Subset 7 Average |       |
|-------------------|-------|-------|-------|-------|-------|-------|------------------------------------------------------------------------|-------|
| NoDA              | 79.12 | 80.82 | 84.57 | 82.02 | 78.10 | 82.77 | 72.36                                                                  | 79.97 |
| moreDA            | 79.64 | 81.66 | 87.60 | 81.38 | 83.74 | 87.12 | 71.23                                                                  | 81.77 |
| TrivialAugment    | 80.39 | 82.21 | 88.42 | 82.60 | 86.36 | 86.60 | 72.58                                                                  | 82.74 |
| Spatial SS (Ours) | 79.96 | 82.18 | 87.68 | 83.74 | 85.69 | 86.99 | 72.90                                                                  | 82.73 |
| DDAug (Ours)      | 80.27 | 82.72 | 87.46 | 88.59 | 86.40 | 87.17 | 73.20                                                                  | 83.69 |

The five-fold average Dice similarity coefficients of different methods are shown in Table [3.](#page-7-0) As we can see, in general, adding augmentation to the prostate MRI dataset is better than no augmentation. moreDA demonstrates some improvement from NoDA on most of the datasets, and additional performance increase are observed when expanding the search space by adding spatial-level augmentations. When comparing the performance of Spatial SS and TrivialAugment, the improvement prove to be inconclusive, as three out of seven dataset exhibits degradation. This is likely due to the fact that TrivialAugment uses uniform sampling over the search space, and unlike our DDAug, does not consider the efficacy of different operations. We are able to further improve the results by utilizing DDAug's full search space and its tree search method. It is important to note that moreDA contains 9 sequential augmentations while DDAug only uses 5. This indicates that simply piling on more augmentations sequentially is not the optimal solution. Though using only a few operations per epoch, DDAug still achieves the highest average DICE when looking at all 7 subsets with near-zero computing consumption.

The performance difference can translate to visual discrepancy between different methods. When inspecting validation segmentation results, we noticed that DDAug is significantly more robust when segmenting validation cases as shown in Fig. [2.](#page-8-0) DDAug demonstrates enhanced generalizability against its counterparts. Augmenting data sequentially, on the other hand, was not able to handle difficult validation cases.

<span id="page-8-0"></span>![](_page_8_Figure_3.jpeg)

**Caption:** Figure 2 compares inference results from models trained with different augmentation techniques on prostate MRI datasets. The top row shows validation images and ground truth, while subsequent rows display results from models using no augmentation, moreDA, Spatial SS, and DDAug, highlighting DDAug's superior robustness in segmentation performance.

Fig. 2: Comparison of inference results using different augmentation techniques during training. The top row is validation images and their corresponding ground truth. The subsequent rows are inference results using models trained with no augmentation, moreDA augmentation, our designed search space, and DDAug, respectively.

# 4 Conclusion

We propose an efficient and zero GPU overhead automatic data augmentation algorithm for prostate MRI segmentation. Comparing previous approaches, we include additional spatial transformations into the search space, and adopt a Monte-Carlo tree structure to store various augmentation operations. An optimal augmentation strategy can be obtained by updating, pruning, and sampling the tree. Our method outperforms the state-of-the-art manual and natural image automatic augmentation methods on several prostate datasets. We show the feasibility of utilizing automatic data augmentation without increasing GPU consumption. In future work, we will further investigate the generalizability of tree search on other medical segmentation datasets, e.g., liver cancer segmentation, brain tumor segmentation and abdominal multi-organ segmentation.

# 5 Acknowledgement

This work was supported by the Hong Kong Innovation and Technology Fund under Project ITS/030/21, as well as by Foshan HKUST Projects under Grants FSUST21-HKUST10E and FSUST21- HKUST11E.

# References

- <span id="page-9-5"></span>1. Auer, P., Cesa-Bianchi, N., Fischer, P.: Finite-time analysis of the multiarmed bandit problem. Machine learning 47, 235–256 (2002)
- <span id="page-9-2"></span>2. Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: Autoaugment: Learning augmentation strategies from data. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 113–123 (2019)
- <span id="page-9-4"></span>3. Cubuk, E.D., Zoph, B., Shlens, J., Le, Q.V.: Randaugment: Practical automated data augmentation with a reduced search space. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops. pp. 702–703 (2020)
- <span id="page-9-6"></span>4. Farahani K., KirbyJ., M.A., Huisman H., E.A.: Nci-isbi 2013 challenge - automated segmentation of prostate structures (2015)
- <span id="page-9-1"></span>5. Garcea, F., Serra, A., Lamberti, F., Morra, L.: Data augmentation for medical imaging: A systematic literature review. Computers in Biology and Medicine p. 106391 (2022)
- <span id="page-9-0"></span>6. Gardner, S.J., Wen, N., Kim, J., Liu, C., Pradhan, D., Aref, I., Cattaneo, R., Vance, S., Movsas, B., Chetty, I.J., et al.: Contouring variability of human-and deformablegenerated contours in radiotherapy for prostate cancer. Physics in Medicine & Biology 60(11), 4429 (2015)
- <span id="page-9-7"></span>7. He, W., Liu, M., Tang, Y., Liu, Q., Wang, Y.: Differentiable automatic data augmentation by proximal update for medical image segmentation. IEEE/CAA Journal of Automatica Sinica 9(7), 1315–1318 (2022)
- <span id="page-9-3"></span>8. Ho, D., Liang, E., Chen, X., Stoica, I., Abbeel, P.: Population based augmentation: Efficient learning of augmentation policy schedules. In: International Conference on Machine Learning. pp. 2731–2741. PMLR (2019)

Dynamic Data Augmentation via MCTS for Prostate MRI Segmentation 11

- <span id="page-10-4"></span>9. Isensee, F., Jaeger, P.F., Kohl, S.A., Petersen, J., Maier-Hein, K.H.: nnu-net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods 18(2), 203–211 (2021)
- <span id="page-10-1"></span>10. Jia, H., Song, Y., Huang, H., Cai, W., Xia, Y.: Hd-net: hybrid discriminative network for prostate segmentation in mr images. In: Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part II 22. pp. 110–118. Springer (2019)
- <span id="page-10-10"></span>11. Kocsis, L., Szepesv´ari, C.: Bandit based monte-carlo planning. In: Machine Learning: ECML 2006: 17th European Conference on Machine Learning Berlin, Germany, September 18-22, 2006 Proceedings 17. pp. 282–293. Springer (2006)
- <span id="page-10-12"></span>12. Lemaˆıtre, G., Mart´ı, R., Freixenet, J., Vilanova, J.C., Walker, P.M., Meriaudeau, F.: Computer-aided detection and diagnosis for prostate cancer based on mono and multi-parametric mri: A review. Computers in Biology and Medicine 60, 8–31 (2015)
- <span id="page-10-7"></span>13. Lin, C., Guo, M., Li, C., Yuan, X., Wu, W., Yan, J., Lin, D., Ouyang, W.: Online hyper-parameter learning for auto-augmentation strategy. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 6579–6588 (2019)
- <span id="page-10-8"></span>14. LingChen, T.C., Khonsari, A., Lashkari, A., Nazari, M.R., Sambee, J.S., Nascimento, M.A.: Uniformaugment: A search-free probabilistic data augmentation approach. arXiv preprint arXiv:2003.14348 (2020)
- <span id="page-10-13"></span>15. Litjens G., Toth R., V.W., Hoeks C., Ginneken B., K.S.: Miccai grand challenge: Prostate mr image segmentation 2012 (2012)
- <span id="page-10-15"></span>16. Liu, Q., Dou, Q., Yu, L., Heng, P.A.: Ms-net: Multi-site network for improving prostate segmentation with heterogeneous mri data. IEEE Transactions on Medical Imaging (2020)
- <span id="page-10-0"></span>17. Mahapatra, D., Buhmann, J.M.: Prostate mri segmentation using learned semantic knowledge and graph cuts. IEEE Transactions on Biomedical Engineering 61(3), 756–764 (2013)
- <span id="page-10-2"></span>18. Milletari, F., Navab, N., Ahmadi, S.A.: V-net: Fully convolutional neural networks for volumetric medical image segmentation. In: 2016 fourth international conference on 3D vision (3DV). pp. 565–571. Ieee (2016)
- <span id="page-10-6"></span>19. M¨uller, S.G., Hutter, F.: Trivialaugment: Tuning-free yet state-of-the-art data augmentation. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 774–782 (2021)
- <span id="page-10-11"></span>20. Neumann, L., Zisserman, A., Vedaldi, A.: Relaxed softmax: Efficient confidence auto-calibration for safe pedestrian detection (2018)
- <span id="page-10-3"></span>21. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. pp. 234–241. Springer (2015)
- <span id="page-10-5"></span>22. Shorten, C., Khoshgoftaar, T.M.: A survey on image data augmentation for deep learning. Journal of big data 6(1), 1–48 (2019)
- <span id="page-10-14"></span>23. Simpson, A.L., Antonelli, M., Bakas, S., Bilello, M., Farahani, K., Van Ginneken, B., Kopp-Schneider, A., Landman, B.A., Litjens, G., Menze, B., et al.: A large annotated medical image dataset for the development and evaluation of segmentation algorithms. arXiv preprint arXiv:1902.09063 (2019)
- <span id="page-10-9"></span>24. Su, X., Huang, T., Li, Y., You, S., Wang, F., Qian, C., Zhang, C., Xu, C.: Prioritized architecture sampling with monto-carlo tree search. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10968– 10977 (2021)
- 12 X. Xu et al.
- <span id="page-11-1"></span>25. Tian, K., Lin, C., Sun, M., Zhou, L., Yan, J., Ouyang, W.: Improving auto-augment via augmentation-wise weight sharing. Advances in Neural Information Processing Systems 33, 19088–19098 (2020)
- <span id="page-11-3"></span>26. Xu, J., Li, M., Zhu, Z.: Automatic data augmentation for 3d medical image segmentation. In: Medical Image Computing and Computer Assisted Intervention– MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part I 23. pp. 378–387. Springer (2020)
- <span id="page-11-2"></span>27. Yang, D., Roth, H., Xu, Z., Milletari, F., Zhang, L., Xu, D.: Searching learning strategy with reinforcement learning for 3d medical image segmentation. In: Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part II 22. pp. 3–11. Springer (2019)
- <span id="page-11-0"></span>28. Yu, L., Yang, X., Chen, H., Qin, J., Heng, P.A.: Volumetric convnets with mixed residual connections for automated prostate segmentation from 3d mr images. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 31 (2017)