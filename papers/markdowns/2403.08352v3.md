# Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods

Alhassan Mumuni1<sup>∗</sup> and Fuseini Mumuni<sup>2</sup>

#### **Abstract**—

Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models. It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties. Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually. State-of-the-art approaches are increasingly relying on automated machine learning (AutoML) principles. This work presents a comprehensive survey of AutoMLbased data augmentation techniques. We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques. The focus of this work is on image data augmentation methods. Nonetheless, we cover other data modalities, especially in cases where the specific data augmentations techniques being discussed are more suitable for these other modalities. For instance, since automated data integration methods are more suitable for tabular data, we cover tabular data in the discussion of data integration methods. The work also presents extensive discussion of techniques for accomplishing each of the major subtasks of the image data augmentation process: search space design, hyperparameter optimization and model evaluation. Finally, we carried out an extensive comparison and analysis of the performance of automated data augmentation techniques and state-of-the-art methods based on classical augmentation approaches. The results show that AutoML methods for data augmentation currently outperform state-of-the-art techniques based on conventional approaches.

**Index Terms**—Data augmentation, AutoML, automated machine learning, machine learning, data preparation, image augmentation. ✦

## **1 INTRODUCTION**

#### **1.1 Background**

Practical implementations of machine learning systems require large data samples to produce satisfactory results. Since data is often not available in sufficient quantities, regularization techniques are critical for achieving good performance. These techniques commonly entail tweaking the machine learning model configuration or applying data augmentation—a range of methods for extending the available data by applying appropriate transformations. The basic idea is to modify training datasets by applying suitable transformations in ways that increase the quantity, representation quality and variability of the original data.

The most commonly used data augmentation techniques include geometric transformations – particularly, rotation, flipping, shearing and scaling–and photometric transformations such as color jittering, solarizaion, brightness, contrast adjustment, noise addition, denoising, and color space conversion. Data augmentation can also involve creating completely new data from scratch [\[1\]](#page-23-0), [\[2\]](#page-23-1). This approach can be useful when the training data for the target application

*Ghana. E-mail: fmumuni@umat.edu.gh*

is inaccessible [\[3\]](#page-23-2). Methods for synthetic data generation

#### **1.2 Limitations of classical data augmentation approaches**

While classical data augmentation methods can significantly improve the predictive performance of machine learning models, they are typically characterized by laborious manual work. The process of generating and finding the best augmentations for a particular dataset or task is a combinatorial problem, which requires infinitely large number of permutations of different settings to be tested for a suitable method to be found. However, for a given dataset, the

<sup>•</sup> <sup>1</sup>*Alhassan Mumuni: Department of Electrical and Electronics Engineering, Cape Coast Technical University, Cape Coast, Ghana.* <sup>∗</sup>*Corresponding author, E-mail: alhassan.mumuni@cctu.edu.gh*

<sup>•</sup> <sup>2</sup>*Fuseini Mumuni: University of Mines and Technology, UMaT, Tarkwa,*

include explicitly creating samples with desired data distribution using computer graphics tools ( [\[2\]](#page-23-1)) or algorithmically generating artificial data with the aid of special deep learning models (e.g., with techniques such as differential neural rendering [\[4\]](#page-23-3), [\[5\]](#page-23-4). Neural style transfer [\[6\]](#page-23-5), generative modeling techniques such as variational autoencoders (VAEs) [\[7\]](#page-23-6) and generative adversarial networks (GANs) [\[8\]](#page-23-7) have also been extensively used to generate synthetic data for training deep learning models. Another way to augment training data is by integrating existing data from several sources (e.g., see [\[9\]](#page-23-8), [\[10\]](#page-23-9), [\[11\]](#page-23-10)). This is a useful and a more natural way to augment training data since the approach can leverage the large quantities of data available in various forms on the internet and other sources.

number of unique augmentations that can be obtained with manual effort is generally limited. Moreover, it is known that different types of augmentations work well for different machine learning tasks, and determining a suitable augmentation methods for a particular task is a nontrivial problem.

Moreover, approaches that improve generalization on one dataset may fail to transfer to other datasets. For instance, Lopes et al. [\[12\]](#page-23-11) demonstrated that CutOut [\[13\]](#page-23-12) improves performance on CIFAR-10 but not on ImageNet dataset. Also, Raileanu et al. [\[14\]](#page-23-13) argue that classical data augmentation approaches do not readily work well for reinforcement learning (RL) tasks. Generative modeling techniques such as VAEs and GANs have shown promise in generating synthetic data to alleviate data shortage problems but they also suffer from overfitting when trained on insufficient data.

Approaches based on GANs are also not guaranteed to produce good results even in cases where sufficiently large and rich datasets are available [\[15\]](#page-23-14). Moreover, since generative modeling-based approaches constrain the distribution of generated samples in some way (e.g., by requiring some form of similarity of the target domain and generated samples), many potentially useful augmentations that do not satisfy these constrains may be missed. AutoML approaches avoid this limitation by solving the problem in a similarityindependent manner.

The foregoing discussion shows that it is extremely challenging to achieve optimal augmentation results using traditional data augmentation methods. Even in situations where restrictions on the range of augmentations achievable do not exist, it is still difficult to obtain good results without excessive trial and error work. Recently, automated algorithmic solutions have been proposed as a means of simplifying the cumbersome data augmentation process. For example, transferable AutoMl (Tr-AutoML) [\[16\]](#page-23-15) is specifically designed to allow learned features to be transferable to novel task domains. The approach combines meta-learning and architecture search for feature extraction from multiple but related datasets. Cubuk et al. [\[17\]](#page-23-16) show that AutoML-based augmentations are also transferable to new datasets. This could potentially provide a means for automatically learning useful augmentations that are independent of datasets for different machine learning tasks.

#### **1.3 Automated machine learning and data augmentation**

Developing a machine learning model involves a series of tedious and repetitive tasks: data preparation, hyperparameter seclection, model selection, hyperparameter optimization, model tuining and evaluation of the resulting outcome. For a single machine learning tasks, all these steps are usually performed repeatedly until satisfactory results are achieved. This requires human experts to manually perform each of the subtasks (Figure [1](#page-2-0) A). The task is inherently a combinatorial problem, as different types of hyperparameter settings would need to be configured and tested. Consequently, with the manual method it is often impractical to find an optimal solution due to the enormous variety of settings involved.

Automated machine learning (AutoML) [\[18\]](#page-23-17) is an approach to automate all the processes of designing, training, deploying and monitoring machine learning solutions. AutoML frameworks can, for example, carry out data augmentation, perform additional processing and feature engineering, and construct the network structure of the machine learning model. The general idea of automated data augmentation is to create different types of basic transformations functions (e.g., rotations, flipping, color jittering, solarizaion, scaling, etc.) and then, using AutoML techniques, algorithmically apply various combinations of operations on the data and select the most effective set of data augmentation operations. Typically, black-box optimization techniques are used to find the best augmentation strategies. The search operation needs to find not only relevant transformations but also the optimal levels of transformations. For image augmentation these levels may be rotation angles, translation offsets and saturation values. Thus, automated data augmentation is mainly a task of combinatorial optimization of primitive data transformation operations. All these processes are carried out without the intervention of a human developer (see Figure [1](#page-2-0) B). Given a task, dataset and performance objective, automated data augmentation produces optimal data augmentation policies that are applied on the dataset and trained in an end-to-end manner (i.e., from input data to final stage).

#### **1.4 Motivation for this survey**

The concept of automated machine learning (AutoML) has received enormous attention in recent years. One of its most important applications is in data preparation, which includes data pre-processing and data augmentation. Despite there being many surveys on data augmentation methods [\[19\]](#page-23-18), [\[20\]](#page-23-19), [\[21\]](#page-24-0), very few works have discussed automated data augmentation in sufficient detail. Among the many surveys on AutoML techniques, only a few (e.g., [\[22\]](#page-24-1), [\[23\]](#page-24-2), [\[24\]](#page-24-3), [\[25\]](#page-24-4), [\[26\]](#page-24-5)) have discussed the application of AutoML to solve data augmentation problems. Unfortunately, the coverage of automated data augmentation in theses works is very limited in scope and depth. To the best of our knowledge, only Yang et al. [\[27\]](#page-24-6) and Cheung [\[28\]](#page-24-7) have presented surveys that are specifically dedicated to automated data augmentation methods. However, these works do not cover many important aspects of AutoML approaches in data augmentation settings, including automated data integration and synthetic data generation methods. Moreover, approaches for the composition of augmentation functions as well as hyperparameter optimization strategies are not given sufficient attention. In addition, to the best of our knowledge, no work has conducted a detailed comparison of the predictive performance of AutoML-based data augmenation approaches and classical methods. This work has been motivated by the emerging importance of AutoML for data augmentation tasks and, as discussed above, the acute lack of coverage of many important issues in the literature.

#### **1.5 Main contributions**

The main contributions of this survey are that:

• We discuss AutoML techniques for performing various data augmentation tasks, including data manipulation, data integration and data synthesis. The

![](_page_2_Figure_0.jpeg)

**Caption:** Figure 1 illustrates the contrast between classical deep learning and AutoML approaches. In classical deep learning (A), all stages, including data preparation, hyperparameter tuning, and model evaluation, are performed manually. Conversely, AutoML (B) automates these processes, optimizing parameters and hyperparameters to enhance efficiency and performance.

<span id="page-2-0"></span>Figure 1. Classical deep learning versus AutoML: In classical deep learning (A), all stages of the machine learning task—data preparation, hyperparameter selection and tuning, model selection and tweaking as well as the evaluation and validation of outcomes– are performed manually. In contrast, AutoML (B) incorporates an automatic tuning mechanism to learn the best parameters and hyperparameters for all these tasks.

last two classes of tasks have not been covered in previous surveys.

- We present the main techniques for designing and composing transformation basic operations for automating data augmentation. We exhaustively describe the main characteristics, challenges and workarounds of the various approaches.
- We extensively discuss a wide variety of search methods for finding optimal augmentation policies. The important concepts, properties as well as strengths and limitations of common black-box optimization methods are presented. In addition, we discuss alternative methods for obtaining effective augmentation policies without using these black-box optimization techniques.
- In addition, we present quantitative performance results of automated data augmentation approaches based on AutoML techniques. We additionally provide a comprehensive comparison of the predictive performance of automated data augmentation methods and classical approaches.
- Finally, we discuss pertinent issues pertaining to the automation of data augmentation, and provide an overview of future research prospects.

# **1.6 Outline of survey**

The rest of the survey is organized as follows. Section 2 presents the basic concepts of AutoML and an overview of data augmentation in AutoML pipelines. We divide automated data augmentation tasks into three main subtasks: search space construction, optimization of augmentation policies and evaluation of learned strategies. Section 3 presents a detailed discussion on three broad ways of achieving data augmentation, and discusses techniques for their realization in AutoML frameworks. Various techniques for construction of the search space are covered in Section 4. Here we discuss common methods for creating the set of data transformation operations or implicit parameters or neural models that can be used to augment data. The hyperparameter optimization subtask is discussed in Section 5. In Section 6, we present quantitative performance results that demonstrate the effectiveness of automated data augmentation techniques. We also compare the performance of these techniques with those of state-of-the-art classical data augmentation methods. Section 7 discusses pertinent issues, unsolved problems and future research directions. Section 7 concludes the survey.

# **2 OVERVIEW AND GENERAL PRINCIPLE OF AUTOML-BASED DATA AUGMENTATION**

The task of AutoML-based data augmentation is to automatically generate the best augmentation for the given dataset and task. This is typically achieved by composing and applying a wide range of basic transformation operations on the given training data and then using various optimization techniques and heuristic search algorithms to find the most useful combination of augmentations.

# **2.1 General structure of AutoML-based data augmentation pipelines**

Automated data augmentation schemes typically utilize a bi-level optimization scheme ( see Figure [2\)](#page-3-0) in which an inner loop optimizes parameters of a deep neural network on training data while an outer loop optimizes the augmentation parameters based on the set of transformation operations and their associated constraints defined in the search space. For instance, the Automated augmentation scheme, proposed by Hataya et al. [\[29\]](#page-24-8), simultaneously optimizes augmentation and image classification model parameters. With the proposed architecture, CNN parameters are optimized by minimizing the training loss while the tunable hyperparameters of the augmentation – transformation magnitude and the probability of application of the augmentation operations – are optimized by minimizing the validation loss.

## **2.2 General procedure for AutoML-based data augmentation**

The first step in the AutoML-based data augmentation process is to define the relevant augmentations to incorporate. A good AutoML data augmentor should incorporate diverse operations that can generate a rich set of data to

![](_page_3_Figure_0.jpeg)

**Caption:** Figure 2 depicts the bi-level optimization scheme utilized in AutoML-based data augmentation. The inner loop focuses on optimizing model parameters using training data, while the outer loop optimizes augmentation hyperparameters, ensuring effective data transformation for improved model performance.

<span id="page-3-0"></span>Figure 2. Bi-level optimization scheme and basic principle of operation of AutoML-based data augmentation methods. The general approach is to jointly optimize two machine learning loops – an outer loop involving augmentation hyperparameter search, and an inner loop that optimizes model parameters.

account for diverse real-world situations. The specification of the types and nature of augmentations typically involves defining different types of primitive data processing operations that transform data in desired ways (e.g., noise perturbation, rotation, scaling, blurring, contrast adjustment, etc.). In addition to the specific transformations, hyperparameters such as the degree or magnitudes of these transformations (e.g., the range of scale factors, rotation angels, etc.) are also specified. Another aspect of the augmentation problem is to specify how to combine these basic augmentations to compose more complex augmentations, known as augmentation policies. An augmentation policy is generally understood as a set of ordered transformation operations parameterized by selection probabilities and intensity values (see Figure [3\)](#page-5-0). Optimization techniques and heuristic search algorithms are used to find the best augmentation policy. The best augmentation strategy is selected by evaluating the performance of candidate augmentations on the target or a proxy task according to a prior defined performance criterion. This task is generally formulated as a joint optimization problem, where performance on the end task is maximized by jointly optimizing model parameters, augmentation operations and their associated hyperparameters. The most important factors in the choice of search strategy are the accuracy of the resulting policy, the search time and the cost in terms of computational resources.

Thus, the automated data augmentation tasks can generally be decomposed into three sub-problems:

1) *Search space composition*— This involves defining basic transformation operations and hyperparameters to be used for data augmentation. The types of augmentation operations depend on the data type and target task. For computer vision tasks, for example,

these primitive augmentation operations are typically image transformation operations (e.g., affine and photometric transformations such as scaling, rotation, flipping, shearing, color jittering, brightness adjustment and noise addition).

- 2) *Augmentation policy search*—This task, also known as augmentation policy optimization, is the task of formulating and applying search strategies to find the best combination of transformations and the associated hyperparameters in the search space that yield effective augmentations.
- 3) *Evaluation of performance of augmentation policies*—The final step in the automated data augmentation process is to evaluate the performance of all candidate policies and select the best. This is typically achieved by validating the performance of the resulting model on a proxy task or on the target task. It is common to solve tasks 2 and 3 as a single optimization problem.

The different approaches for accomplishing each of these subtasks are thoroughly discussed in Sections 4 through 6. We present search space composition techniquesapproaches for designing the set of data transformation operations or implicit parameters capable of learning transformations on data. Tunable hyperparameters that make it flexible to generate augmentations of varying magnitudes and with different attributes are also discussed. Heuristic search algorithms for finding the most effective transformations and their associated hyperparameters are covered in Section 5. Because in most implementations the evaluation strategies are realized as part of the optimization step, we only briefly cover this subtask (in Section 6).

## **3 APPROACHES FOR DATA AUGMENTATION**

## **3.1 Data manipulation approaches**

The easiest and most common way to extend training data is to manipulate existing data by applying appropriate transformations. With this method, typically, a large set of transformation operations, together with possible magnitudes and application probabilities are defined (see Figure [3\)](#page-5-0). There are many ways to generate these basic transformation functions. They can be explicitly specified (e.g., [\[17\]](#page-23-16), [\[30\]](#page-24-9), [\[31\]](#page-24-10) or learned (e.g., [\[32\]](#page-24-11), [\[33\]](#page-24-12)). In essence, this approach consists in designing a set of data transformation operations or implicit parameters or neural models capable of learning transformations on data.

## *3.1.1 Image data manipulation*

For automated image augmentation (e.g., [\[34\]](#page-24-13), [\[35\]](#page-24-14), [\[36\]](#page-24-15)) the search space typically consists of a combination of spatial image transformation operations such as rotation, sheer, vertical and horizontal flipping, cropping and scaling, as well as photometric transformations like smoothing, solarization, sharpening, blurring brightness and contrast adjustment, noise addition, and color space conversion operations. Input data samples are augmented by different policies selected according to specific search criteria. In most cases, a policy in turn consists of sub-policies or proxy policies each of which applies a set of transformation operations on the training data in a sequential fashion.

While this approach is widely successful, care must always be exercised in its application; the technique is aimed at changing the very nature of the training data. In particular, the performance of models trained on the resulting data is sensitive to not only the type of transformation operations, but also to the parameters of transformation functions. Consequently, incorrectly specified transformations or aggressive application of operations will often lead to unintended distortions that harm performance. This problem has been reported in several studies, including in the semial works AutoAugment [\[17\]](#page-23-16) and Population-Based Augmentation [\[37\]](#page-24-16). Because AutoML-based data augmentation methods based on data manipulation techniques have been extensively covered by other surveys (e.g., [\[27\]](#page-24-6), [\[28\]](#page-24-7), [\[38\]](#page-24-17)), we rather focus on AutoML-based data augmentation strategies that have not received much attention. The most prominent of these approaches are dataset integration and data synthesis methods. These are covered in the next subsections.

## *3.1.2 Text data manipulation*

Manipulation-based text augmentation creates variations in the original text while still maintaining the meaning and grammatical structure. Approaches for manipulating textual data include rephrasing, randomly deleting or inserting words, replacing words by their corresponding synonyms, rearranging sentences in long texts, and introducing noise in the form of typographical errors. Natural language processing techniques [\[39\]](#page-24-18) are typically used to apply these manipulation methods in AutoML pipelines. Instead of explicitly performing transformations in the AutoML pipeline using basic NLP algorithms, approaches such as Text AutoAugment [\[40\]](#page-24-19) relies on learning text manipulation polices from input data. More recently, large language models have been seen as a vital tool for automated text augmentation [\[41\]](#page-24-20), [\[42\]](#page-24-21). Besides manipulating text, they can also perform a number of high-level functions such as model configuration or serving as an interface for interaction with the underlying AutoML framework (see [\[43\]](#page-24-22)).

# *3.1.3 Tabular data manipulation*

Similar to image and text modalities, data manipulation operations can be applied on tables to directly transform existing elements. Common methods include feature jittering [\[44\]](#page-24-23), cell completion [\[45\]](#page-24-24), table decomposition and reconstruction [\[46\]](#page-24-25), and random row-wise permutation. Feature jittering techniques generally aim to learn embeddings of the target tabular data and perform suitable manipulations in the embedding space. Cell completion involves populating empty cells, supplying additional entities or missing attribute in the target tables. With decomposition and reconstruction techniques, entire tables are disentangled, simplified and recomposed into new tables. The relative positions of rows can also be altered in various ways to provide additional variation of the tabular data.

# **3.2 Data integration**

Another common approach to data augmentation is to combine several complementary datasets in order to obtain richer and expanded training data. The first step in the integration process is data discovery, where relevant datasets per the given machine learning problem and objective are identified and designated as candidate datasets. The second step of the process consists in selecting suitable data points from the discovered datasets for use. This involves collecting data or extracting relevant data elements from different sources, applying necessary transformations and additional processing to make them homogeneous and compatible. The third step is to then reconstitute them into a new target dataset. This process is shown in Figure [4.](#page-5-1)

# *3.2.1 Image data integration*

Research (e.g., [\[48\]](#page-24-26), [\[49\]](#page-24-27), [\[50\]](#page-24-28)) has shown the effectiveness of mixing different image datasets to overcome the limitations of smaller datasets. Despite the attractiveness of this method, it is particularly challenging to integrate image data from different sources as these data often suffer from problems of inconsistent, incomplete, or noisy (i.e., inaccurate) annotations, rendering the effectiveness of automated data integration methods for image modality low. Moreover, data cleaning methods are ill-suited for image modalities. Because of these difficulties, only a few works have attempted using automated machine learning methods to integrate image data from varied sources. Some researchers (e.g., Kim et al. [\[51\]](#page-24-29), [\[52\]](#page-24-30)) have proposed to address this challenge by employing dedicated label correction or filtering algorithms in the integration framework.

Instead of attempting to clean noisy image data or to correct erroneous labels, an alternative class of approaches [\[49\]](#page-24-27), [\[50\]](#page-24-28), [\[53\]](#page-24-31), [\[54\]](#page-24-32), [\[55\]](#page-24-33) aims to modify the training process in such a way that makes the resulting model more robust to the impact of noisy image labels. For instance, Gao et al. [\[49\]](#page-24-27) propose a so-called Automated Robust Loss (ARL)

![](_page_5_Figure_0.jpeg)

**Caption:** Figure 3 outlines the general process of data manipulation-based augmentation in AutoML pipelines. It shows how a learned sampler selects a subset of input data for transformation through various candidate augmentation policies, producing diverse augmentation outcomes based on the application probabilities of transformation functions.

<span id="page-5-0"></span>Figure 3. General process of data manipulation-based augmentation using AutoML pipelines. With this approach, a subset of the input data is sampled by a learned sampler for transformation by different candidate augmentation policies. Different augmentation outcomes are produced by varying the ordering and application probabilities of the transformation functions OP1, OP2, .. OPn.

![](_page_5_Figure_2.jpeg)

**Caption:** Figure 4 illustrates ARDA, a data acquisition technique that integrates data from multiple sources. It not only performs feature engineering but also optimizes hyperparameters to enhance the integration of related datasets, thereby improving the overall quality of the training data.

<span id="page-5-1"></span>Figure 4. ARDA [\[47\]](#page-24-34), an example of a data acquisition technique that relies on integrating data from multiple sources. In addition to performing feature engineering operations, the technique searches for optimal hyperparameters to integrate data from related tables.

framework, an AutoML-based meta-learning method, that learns loss functions that are robust to noisy labels. Yao et al. [\[52\]](#page-24-30) employ a function approximation method based on a modified Newton algorithm within an AutoML framework to filter out inconsistent and noisy labels by selectively sampling only images with clean labels.

# *3.2.2 Tabular data integration*

Techniques for the integration of tabular data [\[9\]](#page-23-8), [\[10\]](#page-23-9), [\[11\]](#page-23-10), [\[47\]](#page-24-34), [\[56\]](#page-24-35), [\[57\]](#page-24-36), [\[58\]](#page-24-37), [\[59\]](#page-24-38) generally aim to automatically discover, select and aggregate related data in order to extend a given dataset. Tabular data is typically characterized by problems such as missing values, large discrepancy in data representation, inconsistency of keys, and the presence of a wide variety of variables. This makes the problem of integrating this type of data an extremely challenging but useful task. Chepurko et al. [\[47\]](#page-24-34) presented an AutoMLbased data acquisition strategy aimed at integrating different but related tabular data into a single dataset to provide effective training of machine learning models. Given a set of database tables and corresponding keys, the proposed model automatically searches for, and joins the most related tables in an optimal way. Bai et al. [\[10\]](#page-23-9) propose neural architecture search (NAS) [\[60\]](#page-24-39) method to find the best network topology and connections that provide the most effective integration. Kumar et al. [\[61\]](#page-24-40) demonstrate that integrating relational data from multiple sources does not always lead to performance improvements; it requires a rigorous and careful implementation to achieve improvements. It is the task of the AutoML framework to find integration strategies that provide optimal performance.

# *3.2.3 Integrating text and multimodal data*

Approaches have been devised to allow automated machine learning models to seamlessly integrate text [\[62\]](#page-24-41), [\[63\]](#page-25-0) as well as heterogeneous and multimodal data [\[64\]](#page-25-1), [\[65\]](#page-25-2). Owing to the differences in construction of the different datasets, it often requires enormous preprocessing to achieve good integration. Automated machine learning techniques are able to handle all the needed processing tasks for integrating multi-modal data. For instance, Shi et al. [\[64\]](#page-25-1) propose to employ specialized transformer models as multimodal data processing units to allow automated learning on multimodal data – specifically, text and tabular information in different formats. The Transformer units rely on natural language processing (NLP) to obtain useful features from text datasets. In the processing stage, these feature sets are then aggregated, transformed and combined with tabular data, where AutoGluon-Tabular [\[66\]](#page-25-3), an AutoML framework for learning on tabular data, is then used to seamlessly processed the aggregated information from multiple data sources and formats.

Another challenge is that data from different sources may exhibit different statistical distributions [\[67\]](#page-25-4), [\[68\]](#page-25-5). Moreover, in situations where the collected data is from sources created by diverse players with different levels of expertise or conflicting interests and goals, data quality and bias become important issues and need to be handled in the integration process [\[67\]](#page-25-4). This is currently achieved using automated cleaning methods [\[69\]](#page-25-6).

#### **3.3 Data synthesis with AutoML**

Data synthesis methods effectively generate new data samples from "scratch". The use of synthetic data [\[70\]](#page-25-7), [\[71\]](#page-25-8), [\[72\]](#page-25-9), [\[73\]](#page-25-10) for training machine learning models has emerged as an important approach to address data scarcity issues in many domains. The generation of synthetic data is currently a tedious and time consuming process. Data synthesis for medical image analysis [\[70\]](#page-25-7), [\[74\]](#page-25-11) and other computer vision tasks [\[75\]](#page-25-12), for example, typically involve mundane processes of creating and manually manipulating representation primitives such as basic geometric shapes and simulation parameters to produce realistic data.

Unlike classical data acquisition methods that perform synthesis separately as a distinct subproblem, approaches based on automated machine learning principles typically treat the synthesis task and the target application as a unified problem, where optimal simulation parameters can be jointly learned for the downstream task. This distinction is shown in Figure [5.](#page-7-0) The workflow of a typical data synthesis method, Task2Sim [\[76\]](#page-25-13), is shown in Figure [6.](#page-7-1) Figure [7](#page-7-2) shows samples of image data generated by the technique. The approach contrasts sharply with traditional approaches such as A3D [\[77\]](#page-25-14) that do not make use of feedback signals from the performance on the downstream task to optimize simulation parameters. The synthesis process in the latter case, thus, involves extensive manual tuning.

#### *3.3.1 Image data synthesis*

AutoML approaches aimed at automating synthetic image data generation pipelines include [\[51\]](#page-24-29), [\[78\]](#page-25-15), [\[79\]](#page-25-16), [\[80\]](#page-25-17). For example, Kim et al. [\[51\]](#page-24-29) propose a deep neural network that aims to collect real world data by means of adaptive sampling. Their model, LADA, is both a data integration and synthesis method as it learns to acquire informative samples and at the same time generates synthetic instances from the acquired samples using AutoML-based data synthesis principles. In order to generate new samples, they train a policy to maximize the acquisition score based on feedback of the training loss from a classification network. To guarantee the informativeness of the synthetic samples, the authors propose a so-called look-ahead data acquisition technique that speculates about (i.e., predicts) the quality of plausible candidate data in advance. Also, they employ an *oracle* to annotate the unlabeled real-world data acquired.

In computer vision domains (e.g., [\[76\]](#page-25-13), [\[82\]](#page-25-18), [\[83\]](#page-25-19), [\[84\]](#page-25-20), [\[85\]](#page-25-21), [\[86\]](#page-25-22)), the task is usually to synthesize visual scenes or images. The search space in this case consists of mathematical operations describing geometry primitives and other scene parameters such as textures, color, lighting, pose and camera properties. The synthesis process involves the conversion of these elementary information into realistic 2D or 3D data. The role of automation in the synthesis process is to jointly optimize the rendering parameters and the machine learning model conditioned on the performance of the synthetic data on the target task. Ruiz et al. [\[83\]](#page-25-19) utilize AutoML technique with reinforcement learning-based optimization to control the quality of synthetic data generated using computer graphics modeling method. Their approach aims to automatically find scene parameters for the simulation process that maximize the accuracy of trained model. More modern techniques such as NeuralSim [\[87\]](#page-25-23) (Figure [8\)](#page-8-0) employ neural radiance fields as implicit representations of simulation primitives instead of relying on explicitly modeled geometric primitives. The method has been designed to synthesize data for object detection tasks. It employs a bi-level optimization strategy to jointly optimize model parameters of the object detector and rendering parameters of the synthetic data (e.g., illumination, texture, object pose, material, color and appearance).

Another area where automated data synthesis has been particularly successful is in tasks such as depth estimation, optical flow and stereo vision. Since these tasks do not require photorealistic data, the synthesis process is less resource-intensive from the computational perspective. Consequently, models pre-trained on synthetic datasets consistently outperformed those trained on real data alone. Because of this success, techniques to automate the synthesis of data [\[85\]](#page-25-21), [\[86\]](#page-25-22), [\[88\]](#page-25-24) in these domains are currently receiving serious attention. Sun et al. [\[85\]](#page-25-21), for example, propose a technique, called AutoFlow, to automatically render synthetic 2D data for optical flow tasks by learning model hyperparameters to optimize the appearance, shape and motion of the generated data. The synthetic data generated by AutoFlow is designed to be used to pre-train optical flow models before fine-tuning on real data. Unlike classical approaches (e.g., [\[76\]](#page-25-13), [\[89\]](#page-25-25), [\[90\]](#page-25-26)) that tackle the pre-training task as an independent process, Sun et al. [\[85\]](#page-25-21) framed the data synthesis and pre-training performance (i.e., performance on target data) as a joint optimization problem. They demonstrate that the approach achieves better performance than conventionally rendered synthetic 3D datasets such as FlyingThings3D [\[91\]](#page-25-27) and Flying Chairs [\[92\]](#page-25-28). Moreover, their approach has proven to be significantly more data-efficient in pre-training optical flow models on MPI-Sintel [\[93\]](#page-25-29) and KITTI [\[94\]](#page-25-30) datasets than traditional approaches.

#### *3.3.2 Tabular data synthesis*

Some of the most popular traditional methods for generating synthetic tabular data involve random oversampling. This approach is particularly useful for balancing imbalanced data, where minority classes are typically sampled and interpolated to create new datapoints. SMOTE [\[95\]](#page-25-31), a seminal work among this class of approaches, is commonly used to generate synthetic data to populate tables by means of k-Nearest Neighbor algorithm which interpolates

![](_page_7_Figure_0.jpeg)

**Caption:** Figure 5 compares classical and automated data synthesis approaches. Classical methods involve distinct steps for creating data elements, training models, and evaluating results, while AutoML approaches streamline the entire process into a single end-to-end optimization framework, enhancing efficiency.

<span id="page-7-0"></span>Figure 5. A comparison of classical and automated data synthesis approaches. Classical methods of data synthesis involve three distinct steps (A): (1) creation of primitive data elements (e.g., geometric models), (2) model training, and (3) evaluation of results and fine-tuning. With AutoML approaches,however, th entire data synthesis process is carried out end-to-end in a single process. Like in many AutoML procedures, the process typically utilizes a bi-lel optimization scheme to optimize hyperparameters for both synthesis primitives (outer loop) and model hyperparameters (inner loop).

![](_page_7_Figure_2.jpeg)

**Caption:** Figure 6 showcases the Task2Sim model, which generates synthetic data from primitive elements using reinforcement learning-based gradient approximation. This model learns to map input images to optimal simulation primitives, enabling effective data generation for various tasks.

<span id="page-7-1"></span>Figure 6. Task2Sim [\[76\]](#page-25-13) generates synthetic data from primitive elements and utilizes reinforcement learning-based gradient approximation method known as REINFORCE algorithm [\[81\]](#page-25-32) to estimate the gradients of the performance on the downstream task with respect to the data simulation and model parameters. The model first learns to map input images to the best set of simulation primitives. It is then trained to generate synthetic image samples for specified tasks in a pretraining phase. The aim is to transfer this ability to unseen tasks.

![](_page_7_Figure_4.jpeg)

**Caption:** Figure 7 presents sample synthetic images generated by the Task2Sim model. The top images in each column illustrate the model's ability to create diverse views from a given exemplar image, demonstrating its effectiveness in generating realistic synthetic data for unseen tasks.

<span id="page-7-2"></span>Figure 7. Sample synthetic image data generated by Task2Sim model proposed by Mishra et al. [\[76\]](#page-25-13)—top images in each column. After pretraining, the model is able to generate new samples for unseen tasks. Here, given an exemplar image, different views are generated by pretrained Task2Sim model and two other methods, domain randomization and ImageNet pretraining.

between existing data points to create new samples. These oversampling methods can be incorporated within larger neural frameworks to automate the data synthesis process . For instance, Wang and Pai [\[96\]](#page-25-33) propose an approach that employs SMOTE together with a GAN model to generate novel tabular clinical data. Similarly, DeepSMOTE [\[97\]](#page-25-34)

![](_page_8_Figure_1.jpeg)

**Caption:** Figure 8 depicts the architecture of the NeuralSim model, which employs a bi-level optimization scheme to fine-tune model hyperparameters. This approach utilizes multiple feedback signals to enhance the quality of synthetic data generation, showcasing the integration of AutoML principles in data synthesis.

<span id="page-8-0"></span>Figure 8. Basic architecture of NeuralSim model [\[87\]](#page-25-23). The approach is a typical AutoML-based data synthesis models that employ a bi-level optimization scheme to fintune model hypeparameters with the help of multiple feedback signals. The outer loop optimizes hyperparameters for rendering primitives while the inner loop the machine learning parameters.

combines SMOTE with an encoder-decoder sub-model for synthetic data generation. Aragao et al. [\[98\]](#page-25-35) propose a selfbalancing, synthetic tabular data generation pipeline that utilizes both undersampling and oversampling techniques within an AutoML framework to generate new data. Some new approaches bypass the step of modeling data analytically and instead learn the generation process end-toend from data. Rashidi et al. [\[99\]](#page-25-36), for example, devise a so-called Synthetic Tabular Neural Generator (STNG) that trains a dedicated neural network within a larger AutoML framework to specifically generate rich tabular data.

# *3.3.3 Text data synthesis*

In the past, models struggled to generate meaningful text automatically. Approaches often utilize shemantic parsers together with dedicated templates to simplify the process. AutoQA [\[100\]](#page-25-37), for example, employs an end-to-end neural paraphrasing model to generate answers (i.e., text) to different questions using template-based parsing technique. Large language models have recently revolutionized text generation in NLP domains [\[101\]](#page-25-38), [\[102\]](#page-25-39). Consequently, they have been increasingly used to generate text for AutoML pipelines [\[103\]](#page-25-40). Large language models are extremely powerful and flexible for this use case. They are adept at producing semantically meaningful text on many different contexts and tasks. Generally, in this process, the LLM framework serves asan interface for not only text generation but also for performing additional functions, including model configuration (see [\[43\]](#page-24-22), [\[103\]](#page-25-40)). mposed in many different ways. We discuss the most common classes of techniques next. These are grouped into three main approaches: (1) methods based on fixed or predefined data augmentation operations, (2) deeply learned data transformation operations, and (3) methods based on neural architecture search [\[104\]](#page-26-0), [\[105\]](#page-26-1), [\[106\]](#page-26-2) – i.e., learning the best neural architectures for the given data.

# **4 COMPOSITION OF SEARCH SPACE**

The search space can be composed in many different ways. We discuss the most common classes of techniques next. These are grouped into three main approaches: (1) methods based on manual or pre-defined data augmentation operations, (2) deeply learned data transformation operations, and (3) those based on neural architecture search (NAS) – i.e., learning the best neural architectures for the given data.

## **4.1 Fixed augmentation operations**

Many AutoML techniques (e.g., [\[17\]](#page-23-16), [\[30\]](#page-24-9), [\[31\]](#page-24-10), [\[34\]](#page-24-13), [\[36\]](#page-24-15), [\[107\]](#page-26-3), [\[108\]](#page-26-4), [\[109\]](#page-26-5)) employ a fixed set of pre-defined transformation operations to perform data augmnetation. In these works, the transformation operations themselves are fixed and can only be varied by learning tunable parameters that control hyperparameters such as augmentation intensities and application probabilities. Thus, the task of the AutoML process in this case is reduced to simply learning the most useful combination of these fixed augmentations along with the optimal settings for these hyperparameters. In the procedure, the choice of specific transformation operations and their corresponding magnitudes to include in the search space is based on domain knowledge and intuition. Fig. 9 shows the common methods typically employed by approaches that utilize pre-defined transformation operations to perform data augmentation.

| Augmentation                  | Implemented                                                                                                                                              | Augmentation                                                                     |
|-------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|
| operations                    | operations                                                                                                                                               | magnitude                                                                        |
| Geometric<br>transformation   | Shearing along x<br>Shearing along y<br>Translation along x<br>Translation along y<br>Rotation<br>Flipping                                               | Continuous<br>Continuous<br>Continuous<br>Continuous<br>Continuous<br>None       |
| Photometric<br>transformation | Solarization<br>Posterization<br>Color invertion<br>Contrast adjustment<br>Brightness adjustment<br>Sharpness variation<br>Auto-contrast<br>Equalization | Discrete<br>Discrete<br>None<br>Continuous<br>Continuous<br>None<br>None<br>None |
| Other                         | CutOut                                                                                                                                                   | Discrete                                                                         |
| transformations               | SamplePairing                                                                                                                                            | Continuous                                                                       |

Figure 9. Composition of fixed augmetation operations. Many works–including AA [\[17\]](#page-23-16), FastAA [\[108\]](#page-26-4), FasterAA [\[30\]](#page-24-9), PAA [\[36\]](#page-24-15), DADA [\[31\]](#page-24-10) and BDA [\[109\]](#page-26-5)–employ this or similar search space construction.

The process of composing predefined augmentation operations is typically sub-divided into three main subproblems: (1) composition of transformation operations to be used for augmentation, (2) a specification of (mostly) discrete probabilities with which the transformation operations would be applied on the input data, and (3) a specification of the applicable transformation magnitudes (i.e., augmentation intensities). Again, for simplicity, transformation magnitudes are often discrete values. The original work, AutoAugment (AA) [\[17\]](#page-23-16), for example, uses a set of 16 common image transformation operations to augment image data for classification tasks. It trains a deep CNN model on each set of transformation operations to learn optimal parameters for effective image augmentations using validation data. Many subsequent works (e.g., [\[30\]](#page-24-9), [\[31\]](#page-24-10), [\[35\]](#page-24-14), [\[108\]](#page-26-4), [\[110\]](#page-26-6)) adopt a similar formulation of augmentation operations in the search space as in AA [\[17\]](#page-23-16) but utilize more efficient optimization methods and additional mechanisms to reduce computational requirements. For instance, AdvAA [\[110\]](#page-26-6) maintained the search space specification in AA [\[17\]](#page-23-16) but, instead of optimizing the augmentation policy hyperparameters and network parameters separately, jointly optimizes both tasks through adversarial training. Also, instead of RL, a gradient approximation method is used for the policy search. The visual results of applying fixed transformation operations with different magnitudes on image data are shown in Fig. 10. The sample results indicated are specifically for augmentation policies of FasterAA [\[30\]](#page-24-9).

![](_page_9_Figure_1.jpeg)

**Caption:** Figure 10 illustrates the augmentation policies of FasterAA and their application on sample images from CIFAR-10 and SVHN datasets. The results demonstrate the effectiveness of these policies in enhancing image classification performance through diverse augmentation techniques.

Figure 10. Augmentation policies of FasterAA [\[30\]](#page-24-9) and the result of applying these policies on sample images of the CIFAR-10 [\[111\]](#page-26-7) and SVHN [\[112\]](#page-26-8) datasets.

While approaches such as AutoAugment [\[17\]](#page-23-16), FastAA [\[108\]](#page-26-4), FasterAA [\[30\]](#page-24-9) and [\[113\]](#page-26-9) associate magnitudes to each operation as transformation-dependent attributes, Direct Differentiable Augmentation Search (DDAS) [\[107\]](#page-26-3) treats different transformation magnitudes as unique augmentations. This representation simplifies the search space and greatly reduces the computational demand for performing subsequent search operations to optimize model parameters. Many recent approaches [\[34\]](#page-24-13), [\[114\]](#page-26-10) follow this philosophy of designing more simplified search space that facilitate efficient optimization.

The task of creating effective augmentation policies based on manually-designed, fixed transformation operations has a number of significant drawbacks. First, the process is tedious, time-consuming and is highly dependent on domain expertise. Second, the approach constrains the degree of automation that can be achieved. More significantly, given the large space of possible augmentations, it is not practical to manually incorporate all potentially useful augmentation operations, thereby further limiting the benefits that can be derived from automation. In view of the limitations of composing a search space consisting solely of fixed, manually-designed transformation operations, some new approaches have proposed learning more useful augmentations from data.

## **4.2 Learned augmentation operations**

As already noted, transformation operations used in most current automated data augmentation pipelines are designed manually. This constrains their scope to the range of intuitive and discrete transformation routines that can be constructed analytically. To further extend the capabilities of automated machine learning-based data augmentation methods, more recent works [\[32\]](#page-24-11), [\[33\]](#page-24-12), [\[115\]](#page-26-11), [\[116\]](#page-26-12) attempt to automatically learn useful augmentation operations directly from the training data. The design of these types of operations requires less domain expertise to compose task-specific augmentation policies. These approaches have already demonstrated very competitive results. In many cases, the performance of models designed using learned augmentations are superior to those employing fixed augmentation operations.

## *4.2.1 Fully learned augmentations*

An alternative to learning to dynamically modify primitive transformation operations is to deeply learn the transformation functions from data. Techniques such as spatial transformer networks (STN) [\[117\]](#page-26-13), Deformable Convolutional Networks (DCN) [\[118\]](#page-26-14) and [\[116\]](#page-26-12) have demonstrated the effectiveness of learning effective data transformation operations using deep learning models. Zhao et al. [\[116\]](#page-26-12) formulate the data augmentation problem as a composite transformation function consisting of spatial transformation defined by voxel displacement and an appearance transformation defined by pixel intensity transformations. Chu et al. [\[119\]](#page-26-15) propose a natural language processing (NLP) model consisting of three sub-models—an encoder, a custom augmentation network and a document classification model—and then find the best augmentation strategies by employing a reinforcement learning technique to jointly optimize all sub-models.

The STN, in particular, has recently been widely used within automated machine learning models (e.g., [\[32\]](#page-24-11), [\[33\]](#page-24-12), [\[51\]](#page-24-29), [\[120\]](#page-26-16)) as a means of generating the basic transformation operations that can be used to form data augmentation policies. For example, Mounsaveng et al. [\[32\]](#page-24-11) employ STNbased augmenter networks to learn effective transformations from data and use a bi-level optimization scheme to search for model and augmentation parameters. Similarly, Miao and Rahman [\[33\]](#page-24-12) incorporate a Spatial Transformer in a network structure based on AutoAugment [\[121\]](#page-26-17) to learn generic affine transformations in a traffic sign classification task. Kim et al. [\[51\]](#page-24-29) employ an STN-based model known as InfoSTN together with InfoMixup, an adaptive form of MixUp [\[122\]](#page-26-18), for automated data acquisition and further augmentation.

![](_page_10_Figure_0.jpeg)

**Caption:** Figure 11 presents the Sample-Adaptive Policy for Augmentation (SapAugment), which utilizes basic transformation operations and adapts their parameters based on the specific input dataset. This approach aims to optimize data transformation according to training loss, enhancing model performance.

![](_page_10_Figure_1.jpeg)

**Caption:** Figure 12 shows the architecture of the SapAugment model, highlighting its mechanism for adapting learnable parameters of basic operations to specific datasets. This dynamic adjustment aims to improve the effectiveness of data augmentation strategies during training.

<span id="page-10-0"></span>Figure 11. Sample-Adaptive Policy for Augmentation (SapAugment) [\[123\]](#page-26-19) uses basic transformation operations and simple data augmentation methods such as SamplePairing [\[124\]](#page-26-20) and CutMix [\[125\]](#page-26-21) to transformation input data (A). The approach additionall implement a mechanism to adapt the learnable parameters of these basic operations to the specific input dataset according to the training loss (B).

A large number of learned augmentation methods (e.g., [\[110\]](#page-26-6), [\[115\]](#page-26-11), [\[116\]](#page-26-12), [\[120\]](#page-26-16), [\[126\]](#page-26-22), [\[127\]](#page-26-23)) utilize generative modeling techniques to automatically generate augmentations instead of relying on manual image transformation operations. Techniques based on generative adversarial networks and variational autoencoders are particularly useful in this regard. They are able to synthesize realistic data with rich appearance variations. Augmentation policies are then learned to select the most effective augmentations based on training and evaluating on the large synthetic set generated. For instance, Gao et al. [\[115\]](#page-26-11) propose a fully automated data augmentation pipeline that employs three separate GAN sub-models to perform different image transformations in order to generate augmented data– an appearance perturbation sub-model, as well as global and local affine transformation units. They then use a game theoretic formulation based on two min-max [\[128\]](#page-26-24) optimization scheme to learn effective augmentations. Similarly, Chinbat and Bae [\[126\]](#page-26-22) constituted a learned search space of synthetic data using a GAN model as a policy network. Another interesting implementation of learned augmentations based on generative modeling can be found in works such as [\[120\]](#page-26-16). Instead of directly specifying the augmentation operations, a complex deep learning model was used to learn appropriate transformations from data. Here, the authors employed a socalled Augmentation STN (A-STN) that was a modification of the original STN model, proposed by Jaderberg et al. [\[117\]](#page-26-13), to learn affine transformations. They also incorporated a complementary model based on variational Autoencoder architecture [20]– known as Deformation VAE (or D-VAE) –that performs local deformations on input samples or feature maps. A third model, known as perturbation VAE (or P-VAE) was used to learn photometric augmentations such as brightness and contrast adjustment, color jittering and noise addition. These three augmentation networks were jointly trained with the target task to learn effective augmentation strategies.

One of the most important advantages of methods based on deeply learned transformation operations is their universality – ability to generalize well in a large variety of scenarios without prior knowledge about the target tasks. Yet in some practical situations, it is more effective and beneficial to leverage domain knowledge to encode important attributes for specific tasks [\[129\]](#page-26-25), [\[130\]](#page-26-26).

## *4.2.2 Learning dynamic augmentations from basic transformation operations*

An alternative to automatically learning data transformation operations directly from data (e.g., see [\[116\]](#page-26-12), [\[120\]](#page-26-16), [\[126\]](#page-26-22)) is to compose simple and flexible transformation functions whose properties can be modified in the process of training. In contrast to approaches such as AA [\[17\]](#page-23-16), FastAA [\[108\]](#page-26-4) and FasterAA [\[30\]](#page-24-9) that compose a search space consisting of fixed augmentations and evaluate different combinations of these to obtain effective policies, many recent approaches (e.g., [\[37\]](#page-24-16), [\[123\]](#page-26-19), [\[131\]](#page-26-27), [\[132\]](#page-26-28)) propose to learn augmentation policies in a more flexible and dynamic way. They design the search space as a composition of loosely-specified primitive data transformation operations that can be modified in the course of training to generate better augmentations. This flexibility allows the model to adapt the augmentation policies to the specific task, dataset and, in some cases (e.g., see [\[37\]](#page-24-16)), specific input instances. Population Based Augmentation (PBA) [\[37\]](#page-24-16), for example, utilizes an evolutionary algorithm technique that allows augmentation policies to generate child policies which evolve over time in the course of training. Also, in SaPAugment [\[123\]](#page-26-19), Hu et al. propose a so-called sample-adaptive policy that dynamically adapts transformation parameters according to the training loss (see Figure [11\)](#page-10-0). Even though the search space (i.e., the set of primitive augmentation operations) is fixed like in AutoAugment [\[17\]](#page-23-16), FastAA [\[108\]](#page-26-4) and FasterAA [\[30\]](#page-24-9), SapAugment (SAPA) [\[123\]](#page-26-19) is able to adaptively learn and apply different transformation parameters to different datasets in a context dependent manner. Chen et al. [\[133\]](#page-26-29) proposed an automated augmentation method for object detection tasks based on learning dynamic augmentations that are robust to scale variations. Deep AutoAugment (DeepAA) [\[131\]](#page-26-27) eliminates the need for manually constructed default augmentation policies in the search space by replacing them with sequentially stacked augmentation layers which can be trained to generate more nuanced augmentation policies. Adversarial AutoAugment (AdvAA) [\[110\]](#page-26-6) is aimed at generating dynamic augmentation policies through adversarial training.

## *4.2.3 Instance-adaptive dynamic search space*

Instead of employing a single augmentation strategy, many recent works such as MetaAugment [\[134\]](#page-26-30), AdaAug [\[135\]](#page-26-31), InstaAug [\[136\]](#page-26-32) and [\[119\]](#page-26-15) have proposed learning adaptive, instant-dependent data augmentation policies from data. These methods are based on the observation that certain transformations may only produce useful augmentations for specific input types but can be harmful when applied globally. For example, whereas the interpretation of the digit "8" is unaffected by flippng, a vertical flipping of the latin symbol "R" may change it to the Cyrillic letter "Я", thereby corrupting its semantic interpretation. Similarly, a 180<sup>o</sup> rotation of the Arabic numeral "6" may change its semantic label to "9" whereas the letter "O" is generally agnostic to such a transformation. Therefore, instead of applying the same set of transformation operations on all input samples, instance-adaptive methods [\[119\]](#page-26-15), [\[134\]](#page-26-30), [\[135\]](#page-26-31), [\[136\]](#page-26-32) learn input specific transformations according to the dataset and task.

These approaches focus on realizing more fine-grained transformation parameterizations that provide flexible augmentations which can be applied to individual instances instead of using coarse transformations that satisfy all samples of the entire dataset. In this formulation, the instancelevel augmentations correspond to specific configurations of transformation hyperparameters. MetaAugment [\[134\]](#page-26-30) utilizes an auxiliary model within an AutoML framework which re-weights input samples in order to learn the application probabilities of different transformation operations for specific input instances. Thus, by learning the probability of applying transformations for different instances, the sub-model essentially predicts useful augmentations that may be specific to the underlying instance. Based on a similar philosophy, the developers of AdaAug [\[135\]](#page-26-31) propose an adaptive data augmentation technique that, like [\[137\]](#page-26-33), learns effective augmentation policies in a category (e.g., [\[137\]](#page-26-33))- and sample (e.g., [\[135\]](#page-26-31))-dependent way. Their model re-uses extracted features from the input data to map samples to useful transformations, thus adapting the augmentation operations for each instance. The technique is specifically aimed at enhancing the generalization ability of models trained with this augmentation method. The authors claim that data augmentation policies learned by AdaAug can perform well on new datasets without further fine-tuning. Using a slightly different approach, InstaAug [\[136\]](#page-26-32) learns instance-adaptive augmentation strategies by mapping instances to distributions of transformation operations instead of single transformations, which are relatively coarse. The authors [\[136\]](#page-26-32) propose to map input samples to transformation distribution parameters in order to learn instance-specific data augmentations policies from training data. Similar to MetaAugment, InstaAug [\[136\]](#page-26-32) incorporates a dedicated neural network sub-model, socalled augmentation module, to perform the mapping of input instances to desired transformations. In the training process, the augmentation module samples transformations from the set of transformation distributions and applies them to individual input instances in order to generate augmented samples. The resulting augmented samples are fed into a classification network which is then trained to make predictions and, hence, provides information about the quality of the augmentations. A comparison of the main search approaches is presented in Table [1.](#page-12-0)

## **4.3 NAS –based search space**

While most AutoML-based data augmentation methods typically learn effective data augmentation operations for fixed model architectures, an alternative approach to automated data augmentation is to explore the search space for possible neural network architectures that perform well on the given data. These approaches (e.g., ARDA [\[47\]](#page-24-34), Ref. [\[139\]](#page-26-34), T-AutoML [\[138\]](#page-26-35), Tr-AutoML [\[16\]](#page-23-15)), instead of learning transformation functions to perform explicit data manipulation, are concerned with automatically generating the network itself. The goal of neural architecture search [\[60\]](#page-24-39) is to automate the process for creating ML models. In essence, it aims to select the best topology (i.e., network structure, including details of synaptic connections) for a given dataset and task. The approach is to take an input dataset and problem specification, specifically, in this case transformation of input images, and generate a model architecture that solves the given problem better than all other architectures for the given dataset. This involves finding hyperparameters that define the model structure (e.g., filter size and configuration, synaptic connection schemes, pooling and sampling details, model width and depth). The procedure is to iterate through model selection, where in each iteration the algorithm generates a different network structure, sets model parameters and validate its effectiveness based on performance on the target task. The process is completed when the best performing model is found. A large number of studies are devoted to this subject. Some NAS-based automated data augmentation approaches have proposed to simultaneously find the best neural network architectures and effective augmentation policies to apply in order to achieve optimal results. The search space in this scenario consists of possible neural architectures, augmentation primitives and tunable hyperparameters. For instance, Kashima et al. in [\[35\]](#page-24-14) proposed a NAS-based approach that aims to jointly find best NN architectures and effective augmentation policies that optimizes the performance of these architectures. Their approach combined FasterAA [\[30\]](#page-24-9) and DARTS [\[141\]](#page-26-36) to jointly learn good neural architectures and the corresponding optimal data augmentation parameters. In this formulation, DARTS provides the set of possible model architectures while FasterAA implements the basic transformation operations that form the basis for generating data augmentation policies. Yang et al. [\[138\]](#page-26-35) argue that automating only some components of the ML task while handcrafting others can result in sub-optimal performance. They introduce a transformer-based AutoML framework that aims to automate the entire deep learning pipeline – model architecture, data augmentation, as well as hyperparameter optimization. Thus, their approach jointly formulates (the problems of) neural architecture search (NAS), data augmentation, model training and evaluation. To achieve this,

Table 1 A comparison of the main search space approaches for automated data augmentation

<span id="page-12-0"></span>

| Main direction                                      | Example works                                                               | Main strengths                                                               | Weaknesses                                                            |
|-----------------------------------------------------|-----------------------------------------------------------------------------|------------------------------------------------------------------------------|-----------------------------------------------------------------------|
|                                                     |                                                                             | Easy to design and implement                                                 |                                                                       |
| Fixed                                               | AA [17], DDAS [107],                                                        |                                                                              | Limited scope of data augmentation operations                         |
| augmentations                                       | [108],FasterAA [30], PAA [36]                                               | Intuitive and transparent                                                    | Requires domain expertise                                             |
|                                                     |                                                                             | Decreased search space                                                       |                                                                       |
|                                                     | GA3N [126], AdvAA [110],<br>OnlineAugment [120],                            | Saves labor (on constructing<br>transformation operations)                   | Only applicable in domains where<br>large data samples are accessible |
| Learned<br>augmentations                            |                                                                             | Less dependence on domain expertise                                          | Time-consuming training process                                       |
|                                                     | LADA [51],<br>Ref. [116], Ref. [116]                                        | Can model subtle instances that may not<br>be observable to human developers | May fail to encode rare examples                                      |
|                                                     |                                                                             | More flexible and adaptive augmentations                                     | Less transparent                                                      |
| Dynamic<br>augmentations                            | AdaAug [135], InstaAug [136],<br>DeepAA [131],<br>DivAug [132], SAPA [123], | Relatively wide range of augmentations<br>possible                           | Computationally expensive                                             |
|                                                     | MetaAugment [134]                                                           | More generic and easily transferable<br>to different tasks and datasets      | Design process not straightforward                                    |
|                                                     |                                                                             | May complement the traditional AutoML<br>data augmentation methods           |                                                                       |
| Automatically generated                             | T-AutoML [138], ARDA [47],                                                  |                                                                              | Generally unintuitive                                                 |
| neural architectures (i.e.<br>NAS-based techniques) | Ref. [139], Tr-AutoML [16],<br>Ref. [35], MedPipe [140]                     | Can result in more simple models with<br>powerful augmentation capabilities  | Requires more computational<br>resources                              |
|                                                     |                                                                             | Can be used in conjunction with other<br>approaches                          |                                                                       |

first, candidate architectures and augmentation operations, as well as the associated hyperparameters are represented as a one-dimentional vector. A predictor is then trained to compare different combinations and configurations neural architectures and augmentations while finding the best hyperparameter values.

One advantage of the NAS-based auto-augmentation approaches is that, compared to methods that perform explicit transformations (e.g., [\[17\]](#page-23-16), [\[30\]](#page-24-9), [\[34\]](#page-24-13), [\[36\]](#page-24-15), [\[108\]](#page-26-4)), they are able to generate far superior models that perform well on unseen datasets. However, the downside of most artificially generated models is that they tend to be more generic in nature and require relatively larger sizes, even for tasks where smaller models might suffice. Also, because of the need to train and validate all the possible neural architectures, the optimization process incurs very high computational costs and is unduly slow. Moreover, it requires huge amounts of storage resources since all candidate models need "live" for a little while in order to be trained and tested.

## **5 OPTIMIZATION OF AUGMENTATION POLICIES**

A naïve solution to the search problem is to test all possible augmentation operations and their possible combinations with different model configurations. Obviously, such a strategy is computationally costly and would be excessively time-consuming to practically realize. Therefore, various optimization techniques are used to heuristically find the most effective combination of augmentations and their corresponding hyperparameters without carrying out exhaustive search (i.e., testing all possible augmentations). Many approaches utilize well-known optimization techniques – socalled black-box optimization methods – such as Bayesian optimization [\[142\]](#page-26-38), evolutionary computation algorithms [\[143\]](#page-26-39) and reinforcement learning [\[144\]](#page-26-40). These techniques are well suited for finding effective transformation operations and their parameters from a discrete space of primitive operations that cannot be described by analytical relationships. In this section, we present common search strategies, highlighting the main principles of operation, as well as the key strengths and weaknesses of each method.

The optimization process is an iterative procedure whereby the optimization algorithm is executed repeatedly while comparing the results of each iteration until an optimal or a satisfactory result is achieved. Although gradient-based methods have become the de facto approach for optimizing deep neural networks, the discontinuous nature of augmentation operations and their associated hyperparameters make it difficult to apply these techniques out-of-the-box. Heuristic search strategies are therefore the most viable approach for finding effective augmentation policies. classical optimization methods include random search, particle swarm optimization (PSO), ant colony optimization (ACO), simulated annealing, greedy algorithm, genetic algorithms and particle swarm optimization. The techniques have been developed for solving large-scale optimization problems in computer science. The popularity of these techniques stem from their ability to solve complex and ill-formalized AI problems for which analytical search or gradient-based methods are unsuited or do not provide the required level of performance. While a large diversity of heuristic search optimization techniques exist, only a small subset of the methods has been applied for the purpose of automating data augmentation. They include reinforcement learning, Bayesian Optimization (BO) and evolutionary computational algorithms. New search space design strategies have also been proposed that allow much simpler search techniques to produce good performance. We discuss these approaches in this section.

#### **5.1 Reinforcement learning**

Reinforcement learning [\[144\]](#page-26-40) is one of the first optimization techniques to be used in automated data augmentation [\[17\]](#page-23-16). It is a classical optimization technique for solving ill-formed problems and has wide applications in machine learning. Indeed, a very large number of automated data augmentation approaches (e.g., AA [\[17\]](#page-23-16), FastAA [\[108\]](#page-26-4), AWS [\[145\]](#page-26-41), PAA [\[36\]](#page-24-15) Learn2Augment [\[146\]](#page-26-42), Ref. [\[119\]](#page-26-15) and RTS [\[83\]](#page-25-19)) utilize RL for the optimization task. The reinforcement learning approach is based on the principle of an artificial agent interacting with the environment through specific permissible actions and making observations about the outcomes of different actions through rewards and penalties. In the context of data augmentation, the actions are specified as sequences of basic data transformation operations. Observations are the performance results based on a predefined evaluation criterion. Through repeated actions (i.e., application of the specified augmentation operations), the agent finds optimal augmentation strategies that maximize performance over time. In one of the pioneering works on AutoML-based data augmentation, Cubuk et al. [\[17\]](#page-23-16) utilize a reinforcement learning technique to simultaneously find good augmentations policies and optimal model hyperparameters that produced state-of-the-art performance on several benchmark datasets (see Figures [16](#page-20-0) in Subsection [7.2\)](#page-17-0). The authors [\[17\]](#page-23-16) utilized a recurrent neural network (RNN) as a controller in the RL formulation to dynamically predict the most effective data augmentation policy for a given dataset in the course of training. Their model, AutoAugment (AA) [\[17\]](#page-23-16), searches for the best transformation operations, their probabilities, as well as the respective intensities with the help of the recurrent neural network (RNN)-based controller.

The approach is exceedingly expensive – even on such a relatively small dataset as CIFAR-10, it take about 5,000 GPU hours to train. Consequently, most subsequent works in this direction aim to achieve comparable performance while reducing the computational overheads. FasterAA [\[30\]](#page-24-9) and AWS [\[145\]](#page-26-41), for example, propose to improve computational efficiency by employing weight-sharing mechanism within a reinforcement learning framework and achieve comparable results as AA on image classification tasks but with significantly lower computational budget. Patch AutoAugment (PAA) [\[36\]](#page-24-15) formulates the data augmentation optimization problem as cooperative multi-agent RL problem in which each aent learns an optimal augmentation policy for a small image patch. A multi-agent reinforcement learning algorithm based on decentralized partially observable Markov decision process [\[147\]](#page-26-43), [\[148\]](#page-26-44) is then used to learn a joint optimal augmentation policy over the entire image.

Gowda et al. [\[146\]](#page-26-42) propose a reinforcement learning approach to automatically learn to select the most useful video frames for augmentations on video datasets without actually executing and evaluating these augmentations. The technique incorporates a so-called Semantic Matching submodule to exploit the natural association of activities (i.e., foregrounds) and backgrounds. Augmentations are created by combining a pair of useful video segments, where one segment's background is mixed with another's foreground consisting of actor and objects. The approach achieves a performance gain of up to 4.4% over classical augmentation methods.

Although many of the recent RL-based methods have significantly reduced computational cost of the optimization tasks, relative to other search methods, RL techniques are still more expensive for many practical purposes. Consequently, many alternative approaches are actively being explored.

#### **5.2 Bayesian Optimization**

Because of the enormous computational requirements of RL methods such as AutoAugment and many followup works, recent approaches have focused on reducing computational requirements without incurring significant generalization performance penalty. To this end, a large number of techniques [\[30\]](#page-24-9), [\[123\]](#page-26-19), [\[149\]](#page-26-45) have been devised based on Bayesian optimization (BO) [\[150\]](#page-27-0). BO methods, as opposed to reinforcement learning approaches discussed in the previous subsection, allow to encode domain knowledge by keeping track of, and using past evaluation results to generate better policies in subsequent searches. For these approaches, the search space is formulated as a probability distribution in which subsequent searches are more focused on areas where the likelihood of the best hyperparameters lie. Thus, the BO approach implements a highly efficiency sampling strategy by selecting only the most promising set of hyperparameters to evaluate based on previous calls to the "evaluator". A simplified workflow of the process is shown in Figure [12.](#page-13-0)

To further improve model efficiency, instead of training on the entire dataset, Fast AutoAugment (FastAA) [\[108\]](#page-26-4) divides the training dataset into smaller subsets which are then trained simultaneously on different sub-models using BO strategy to find optimal augmentation policies. BO approaches have shown competitive results with relatively lower computational overheads compared to RLbased approaches due to the ability to estimate the quality of augmentations and skip bad augmentations policies before they are evaluated.

![](_page_13_Figure_7.jpeg)

**Caption:** Figure 15 compares the predictive performance gains of automated data augmentation methods against classical techniques. The results indicate that automated methods consistently outperform traditional approaches, demonstrating their effectiveness in enhancing model accuracy across various datasets.

<span id="page-13-0"></span>Figure 12. Simplified flowchart of Bayesian optimization. The approach relies on probabilistic modeling to predict the best augmentation hyperparametrs for a givn dataset and task. Based on these hyperparameters, a deep neural network is then trained and evaluated to establish the quality of the predicted hyperparameters.

#### **5.3 Evolutionary computation algorithms**

As an alternative to the reinforcement learning and Bayesian optimization approaches, many works [\[151\]](#page-27-1) have proposed evolutionary computational techniques [\[143\]](#page-26-39) for automating the search for effective data augmentation policies. Algorithms based on such techniques utilize specialized operators inspired by biological evolution processes—specifically, natural selection, crossover and mutation—for searching for, and optimizing the performance of useful augmentations in an iterative process during training (see Figure [13\)](#page-14-0). These techniques use the concept of natural selection to ensure that only high performing augmentation policies are maintained from one iteration to the next. The basic idea is to search from an initial pool of possible augmentations and select good transformation operations, and during each iteration of the search process to continually eliminate non-optimal transformations. The augmentations obtained may be combined with other augmentations in a process called crossover. Further, the population-based technique periodically induces random changes in one or more augmentation operations of the current set by replacing some of the parameters with random parameters, thereby mutating the affected augmentations. Consequently, new and better set of augmentations are obtained by the process of crossover and mutation. Thus, in contrast to the other blackbox optimization approaches discussed earlier that search over static transformation operations, approaches employing evolutionary computation algorithms allow the underlying augmentation operations to be varied and improved in the course of training. The enhancement is achieved by periodically making random changes to the current best policies, and inter-mixing to produce better characteristics. These operation are known in scientific literature as mutation and crossover, respectively. One of the first works to use evolutionary algorithm method for data augmentation was PBA [\[37\]](#page-24-16). Subsequently, Cheng et al. proposed a modified version of PBA, Progressive Population Based Augmentation (PPBA) [\[151\]](#page-27-1), by gradually reducing the search space in the course of training. This augmentation strategy was applied on multimodal data and showed good results.

![](_page_14_Figure_1.jpeg)

**Caption:** Figure 16 illustrates the performance of automated data augmentation techniques versus classical methods on CIFAR-100. The results highlight the significant improvement in accuracy achieved by automated methods, reinforcing their superiority in data augmentation tasks.

<span id="page-14-0"></span>Figure 13. Basic principle of evolutionary computation algorithms. The is conecptually similar to the procss of natural selection in living organisms.

When composing a search space for this approach, the main focus is to construct an initial set of useful transformations and a corresponding set of policies which can evolve with time. In this case, the augmentations can be composed using a variety of methods. For example, they can be sample space transformation operations (e.g., [\[37\]](#page-24-16)) or feature space (e.g., [\[152\]](#page-27-2)). Cheung et al. [\[152\]](#page-27-2) propose an evolutionary computation approach to find good augmentation policies composed in the latent space. Poor performing augmentations in the search space are gradually eliminated in the course of training while good ones are retained and enhance over time.

#### **5.4 Gradient-based methods**

Gradient-based automated data augmentation approaches are designed to approximate the gradients of augmentation hyperparameters rather than to iteratively search a discrete space for good augmentation policies. They are mainly aimed at achieving higher efficency compared with computational methods like RL and evolutionary algorithms

While gradient-based methods have proven to be universal and well adapted for training deep neural networks to find optimal parameters in modern machine learning algorithms, they are ill-suited for out-of-the-box AutoMLbased data augmentation formulations. The application of gradient descent methods in solving automated data augmentation problems is constrained by the inherently nondifferentiable nature of the search space. This is as a result of problems associated with discrete nature of transformation hyperparameters (e.g., discrete scale and rotation angle specifications), making it difficult to apply simple and effective gradient-based optimization techniques.

To enable the use of gradient descent methods for automated data augmentation, it is required that the search space be necessarily both continuous and monotonous, and that at each iteration in the search process, the direction of the greatest increase (or decrease) in the objective function can be determined until an optimal augmentation parameters are found. Several workarounds exist for ensuring that these conditions are met. Many of these approaches are based on previously developed techniques for solving general black-box optimization problems using the concept of approximate gradient estimation [\[81\]](#page-25-32), [\[153\]](#page-27-3), [\[154\]](#page-27-4). The approximate gradient estimator is essentially a differential operator that takes discrete parameter values or random, continuous variables and returns the corresponding gradients; it is a generalization of the concept of a gradient descent for non-differentiable and discrete functions. The use of this concept makes it possible to apply GD methods for finding optimal augmentation policies in a discrete search space.

Many approaches (e.g., DHA [\[155\]](#page-27-5), DAAS [\[156\]](#page-27-6), AdvAA [\[110\]](#page-26-6)) invariably reformulate the search space in such a way that approximate numerical methods can be used for the computation of derivatives of the objective function. Faster AutoAugment [\[30\]](#page-24-9) uses straight-through estimator to simplify the representation of the search problem and allow the application of backpropagation to find optimal transformation operations. Similarly, instead of directly performing differentiation to estimate the gradient, MADAO [\[29\]](#page-24-8) data augmentation as a differentiable task using Neumann series approximation to compute implicit gradients for the objective function. Xu et al. [\[157\]](#page-27-7) employ stochastic relaxation method [\[158\]](#page-27-8) to approximate the representation of nondifferentiable augmentation hyperparameters in differentiable form to allow gradient-based policy optimization.

Some new methods such as [\[110\]](#page-26-6), [\[114\]](#page-26-10) are based on applying reinforcement learning concepts within a connectionist (i.e., network) framework to estimate the gradients of augmentation parameters. Zhang et al. [\[110\]](#page-26-6) proposed Adversarial AutoAugment (AdvAA) which computes approximate gradients with the aid of REINFORCE algorithm—a general statistical method based on reinforcement learning—proposed by Williams [\[81\]](#page-25-32). A similar approach is used in Online Hyper-parameter Learning for Auto-Augmentation (OHLAA) [\[114\]](#page-26-10) to estimate the gradient of the loss function with respect to the augmentation policy hyperparameters.

Different from the above methods, some approaches (e.g., [\[84\]](#page-25-20), [\[159\]](#page-27-9)) rely on proxy models where augmentation variables can be represented as continuous and differentiable parameters, and used to indirectly optimize the discrete augmentation hyperparameters (through joint training). DADA [\[159\]](#page-27-9), for example, proposes a continuous formulation of the discrete search space by introducing a continuous reparameterization of the discrete augmentation policy variables using a differentiable neural network as a surrogate model. The method is based on RELAX, one of several techniques proposed by Grathwohl et al. [\[153\]](#page-27-3) to extend gradient descent to non-differentiable black-box optimization problems. It eliminates the need for continuous relaxation of the discrete variables by utilizing a surrogate neural network, whose parameters can be used to control the augmentation variables through joint optimization with the augmentation policy hyperparameters. Likewise, Shirobokov et al. [\[84\]](#page-25-20) utilize differentiable surrogate neural networks that allow the optimization of simulator parameters for the synthesis of artificial data that are representative of real physical processes. We summarize the main strengths and weaknesses of the various optimization techniques covered in this work in Table [2.](#page-16-0)

#### **5.5 Ensemble optimization methods**

A recent hyperparameter search approach is to implement multiple optimization algorithms in a single AutoML model and then algorithmically determine the most effective ones for a given dataset and task. The ensemble search approach aims to leverage the strengths of different optimization methods to achieve higher performance by combining multiple search algorithms in a single framework. Since different optimization techniques are effective for different datasets and tasks [\[163\]](#page-27-10), these approaches are particularly useful for AutoML models designed for generic applications that need to be able to handle multimodal data or process a broad range of data types for different machine learning problems.

Predictably, modern large-scale AutoML frameworks (e.g., TPOT [\[164\]](#page-27-11), AutoDES [\[165\]](#page-27-12), Hyperopt-Sklearn [\[166\]](#page-27-13) and AutoWeka [\[167\]](#page-27-14)) typically rely on ensemble optimization techniques that can incorporate search strategies. In these frameworks, multiple optimization algorithms can be applied simultaneously. For instance, Auto-Tuned Models (ATM) [\[168\]](#page-27-15) defines Bayesian optimization and reinforcement learning (multi-armed bandit) algorithms in its pipeline which can be used simultaneously to find optimal hyperparametters for the input data. Some models such as H2O AutoML [\[169\]](#page-27-16) and AutoDES [\[165\]](#page-27-12) incorporate a flexible representation of plausible pipeline structures that can be applied depending on the target task or input data type. Despite the increased model complexity and computational cost, the approach is often justified when solving broad machine learning problems involving very large and complex data.

#### **5.6 Searchless optimization of data augmentation policies**

Although the optimization techniques discussed in Subsections 5.1 through 5.4 have demonstrated impressive results, they are still too expensive for most practical purposes. For instance, optimization methods employed in AutoAugment takes about 15,000 GPU hours to train on ImageNet [\[131\]](#page-26-27). To address the challenge of computational complexity, some recent works (e.g., [\[34\]](#page-24-13), [\[162\]](#page-27-17), [\[170\]](#page-27-18), [\[171\]](#page-27-19)) propose simplified search space design where good augmentation policies can be found using much simpler search strategies like random search [\[172\]](#page-27-20), grid search [\[173\]](#page-27-21) or greedy search [\[174\]](#page-27-22). Greedy AutoAugment [\[170\]](#page-27-18) proposes to reduce the search space by eliminating the need to search for different combinations of augmentation operations in a combinatorial manner. The basic idea is to dynamically expand the space of augmentation operations in the direction of effective augmentation policies by creating and modifying sub-policies with good performance. In the search process, only transformation type and intensity are the only hyperparameteres considered. The probability of applying the operations are determined later when the search is complete and is only applied on the effective policies found. This significantly reduces the amount of computations needed to find good augmentation strategies. Because of its simplicity and effectiveness, the greedy search policy optimization procedure has been used in several works [\[175\]](#page-27-23).

Approaches for further simplifying the search process have also been considered. In some cases, for example, UniformAugment (UA) [\[162\]](#page-27-17), these simplifications allow the search phase in the optimization process to be eliminated altogether without incurring significant performance penalty. RandomAugment (RA) [\[34\]](#page-24-13) employs just two tunable parameters – augmentation intensity (i.e., transformation magnitudes) and selection probability—as variables to characterize the search space. Given the simplicity of this formulation, a simple grid search is sufficient to effectively search for optimal values of augmentation parameters. Instead of modeling selection probabilities as independent hyperparameters, in RA [\[34\]](#page-24-13) the probability of applying any given augmentation operation is a constant value that is solely dependent on the number of applicable augmentation operations in the search space; it is computed as the inverse of the total number of operations. In the same way, the augmentation intensities are assumed to be uniform for all transformation operations. Based on this simplified reformulation of the search space, it is then possible to obtain optimal augmentation policies using only a single variable parameter, the augmentation intensity, and a constant—the total number of transformation operations which defines the application probability. RandomAugment RA [\[34\]](#page-24-13), is thus able to reduce the search space from 1032 possible operations to just 100. For this simple scenario, a naïve grid search provides very good results comparable to state-ofthe-art performance.

Unlike in RA [\[34\]](#page-24-13) and all previous optimization strategy formulations, Uniform Augment (UA) [\[162\]](#page-27-17) completely bypasses the search stage and instead propose to uniformly sample augmentation policy hyperparameters from the search space. To achieve this, the authors formulate the Table 2

A comparison of the main strengths and weaknesses of the common optimization techniques used for automated data augmentation.

<span id="page-16-0"></span>

| Optimization method     | Example works                  | Main strengths                                                                                  | Weaknesses                                      |  |
|-------------------------|--------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------|--|
|                         |                                | Effective when cannot be intuitively determined                                                 | Expensive to train                              |  |
| Reinforcement learning  | [17], [36], [108], [146]       | Does not require prior knowledge about<br>augmentation operations                               | Generally complex architecture                  |  |
|                         |                                |                                                                                                 | Less transparent                                |  |
| Bayesian optimization   | [30], [123], [149]             | More flexible augmentation process<br>Computationally efficient                                 | Computationally expensive                       |  |
|                         |                                | Explicit mechanism to adapt augmentation policies                                               | Design process not straightforward              |  |
|                         | [37], [151], [152]             | Evolution of policies can lead to better than can be                                            | Relatively expensive                            |  |
| Evolutionary Algorithms |                                | intuitively designed                                                                            | Relatively complex schemes                      |  |
|                         |                                | No rigid upper ceiling for performance<br>Fast training                                         | Often requires approximations; can              |  |
| Gradient methods        | [29], [30], [84], [114], [159] | Simpler models                                                                                  | compromise the fidelity of<br>representation    |  |
|                         |                                | Readily integrates with DNN training process<br>Allows to exploit the complementary benefits of | Not always possible                             |  |
|                         |                                | different methods                                                                               | Can result in very complex models               |  |
| Ensemble approaches     | [30], [110], [160], [161]      | Can generate more diverse augmentations than<br>single methods                                  | Unintended interactions may harm<br>performance |  |
|                         |                                | Potentially more robust                                                                         |                                                 |  |
| Searchless methods      |                                | Fast training                                                                                   | Less flexible augmentations                     |  |
|                         | [34], [162]                    | Relatively simpler models                                                                       | Performance may have a "hard"<br>upper ceiling  |  |

search space as distribution invariant by ensuring that the transformation operations and associated intensities result in label-preserving augmentations, and the transformed data remains within the distribution of the original input data. A machine learning model is then able to learn optimal augmentations by sampling randomly from the search space and optimizing model parameters using gradient descent. Uniform Augment, thus far, is the cheapest in terms of the number of computations needed to find optimal augmentation policies. Indeed, the number of search operations is theoretically zero.

## **6 EVALUATION METHODS**

An important step after selecting a subset of operations for the search space and an optimization method is to evaluate the performance of the resulting models. This process is repeated for different combinations of model configuration settings (i.e., all plausible sets of augmentation operations, hyperparameters and search methods). At the end of the process, performance results are compared and an optimal pipeline and hyperparameters chosen according to a specified performance criterion. The costly nature of the evaluation stage significantly limits the range of plausible configurations that can be explored to achieve optimal predictive performance. Instead of training the network to converge before evaluating its performance, approaches have been devised to accelerate the process by enabling near-optimal strategies to be found without exhaustive evaluations.

One of the most popular approaches is the so-called early stopping strategy [\[23\]](#page-24-2), a technique based on terminating the evaluation process for settings that are predicted to perform relatively poor on a validation set. Some works, for instance, RandAugment (RA) [\[34\]](#page-24-13), TrivialAugment (TA) [\[171\]](#page-27-19) and OHLAA [\[114\]](#page-26-10), reduce the range of augmentation operations and hyperparameters in the search space in the evaluation process. A popular method to speed up model evaluation is to reduce the fidelity of the input data [\[23\]](#page-24-2). In image augmentation, this is achieved by reducing the sizes or resolutions of the images used. Another common approach is to train on proxy tasks–i.e., employ reduced model size or subsets of training data. Examples of AutoMLbased data augmentation models that employ this strategy include AutoAugment (AA) [\[17\]](#page-23-16), FastAA [\[108\]](#page-26-4), [\[108\]](#page-26-4), FasterAA [\[30\]](#page-24-9), DADA [\[159\]](#page-27-9), AWS [\[145\]](#page-26-41), and PBA [\[37\]](#page-24-16). Another method for reducing the enormous computaional overhead at the evaluation stage is to employ surrogate models as evaluators [\[176\]](#page-27-26), [\[177\]](#page-27-27) to predict the performance of the target models. This approach circumvents the need to perform costly evaluation on different configurations of the real model.

# **7 QUANTITATIVE PERFORMANCE OF DATA AUG-MENTATION APPROACHES**

We present results on the performance of AutoML-based data augmentation methods and compare these with stateof-the-art data augmentation methods based on classical approaches. For fairness we compare methods that use the same datasets and similar training settings (i.e., similar model configuration and number of training epochs). The results presented here are curated from the original works. We highlight instances where results or other performance information from secondary sources are used.

We first describe the datasets and settings used in most of the works. We also introduce the common performance benchmarks and evaluation metrics commonly used to compare the data augmentation methods investigated in this work. Finally, we present quantitative performance results and compare AutoML-based methods against several stateof-the-art tradditional methods. In addition to performance comparisons, we also show the effect of combining classical and AutoML-based augmentations. These results show that appreciable improvements can be gained by combining the two classes of methods.

#### <span id="page-17-1"></span>**7.1 Datasets and model settings**

#### *7.1.1 Datasets*

To assess the predictive performance of automated data augmentation methods, test results on the following datasets were considered: CIFAR-10 and CIFAR-100, SHVN [\[112\]](#page-26-8), ImageNet [\[178\]](#page-27-28), and MS COCO [\[179\]](#page-27-29). We briefly each of these datasets in the next paragraphs.

The **CIFAR-10** [\[111\]](#page-26-7) and **CIFAR-100** [\[111\]](#page-26-7) are highly popular image classification datasets. Each of the datasets contains 60,000 labeled 32x32 RGB images that are divided into 50,000 training and 10,000 test images. The images in CIFAR-10 are divided into 10 classes of 6,000 images per class, while CIFAR-100 has 100 classes, each containing 600 (500 training and 10 test) images.

The **Street View House Numbers (SVHN)** [\[112\]](#page-26-8) is a digit (i.e., decimal numbers 0 to 9) recognition dataset containing 600,000 color (RGB) images. The dataset is made up of cropped, 32×32 images derived from Google Street View [\[180\]](#page-27-30). Thus, the images are pictures of real-world house number plates in challenging settings. SVHN include bounding box information in a separate file and can therefore be used for digit detection in addition to image classification.

**ImageNet** [\[178\]](#page-27-28) is a large-scale visual recognition dataset for generic computer vision tasks. A subset of the dataset used by most works for image classification –ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [\[181\]](#page-27-31)–has a total of 1,431,167 images divided into 1000 different object categories. The entire set is made up of 1,281,167 training, 100,000 test and 50,000 validation images.

The **Microsoft Common Objects in Context (MS COCO)** dataset [\[179\]](#page-27-29) is a large-scale dataset that can be used for many computer vision tasks. It is primarily designed for object detection, pose estimation, keypoint detection, image captioning, and segmentation tasks. It has a total of 330,000 images split into 80 classes.

#### *7.1.2 Performance metrics and model settings*

For the classification tasks, the performance metric commonly used is the generalization accuracy. Results for ImageNet include top-1% and top-5% accuracy measures. Mean average precision (mAP) is used to characterize performance of the object detection tasks, i.e., on the MS COCO dataset (Table [5\)](#page-19-0).

Performance on CIFAR-10 and CIFAR-100 has been tested using three different backbone models: Wide Residual Networks [\[182\]](#page-27-32), specifically, Wide-ResNet-28-10 (see the original work for a detailed description of this setting); Shake-Shake (26 2x32d) [\[183\]](#page-27-33); and PyramidNet [\[184\]](#page-27-34). Results for ImageNet dataset have are based on ResNet-50 and ResNet-200 backbone models (see He et al. [\[185\]](#page-27-35) for details). RetinaNet [\[186\]](#page-27-36) is used with various ResNet models [\[187\]](#page-27-37) on the MS COCO dataset.

#### <span id="page-17-0"></span>**7.2 Performance of AutoML-based data augmentation methods**

Most of the existing works report results for image classification using large-scale CNN models. The most popular datasets used for these purposes are the ImageNet and CIFAR (CIFAR-10 and CIFAR-100) family of datasets described in Subsection [7.1.](#page-17-1) Detailed performance results for automated data augmentation methods based on these datasets are summarized in Tables Tables [3,](#page-18-0) [4](#page-18-1) and [7.](#page-22-0) Table [3](#page-18-0) show image classification results for CIFAR-10 and CIFAR-10 for three different backbone models– WideResNet 28- 10 (WRN28-10) [\[182\]](#page-27-32), Shake-Shake 26-32 (S-S 26-32) [\[183\]](#page-27-33) and PyramidNet (PNet) [\[184\]](#page-27-34). For each data augmentation method, we indicate the average classification accuracy for the three backbone models. From the Table, the mean gain in accuracy range between 0.6 and 1.5 on CIFAR-10 and between 0.8% and 3.1% on CIFAR-100. This demonstrates consistentently strong performance for all methods. Indeed, the average performance gain for all the methods is 1.02% and 2.17% on CIFAR-10 and CIFAR-100, respectively. Note that for CIFAR-100, many of the methods do not have results for PyramidNet backbone on CIFAR-100. We exclude these methods in our average performance computations. Similar to Table [3,](#page-18-0) Table [4](#page-18-1) shows classification results for the ImageNet dataset based on ResNet-50 and ResNet-200 backbone models. Results are shown for top-1 and top-5% accuracies. The table also indicates percentage performance gain for each of these accuracy measures. The gains are consistent for all methods, with the lowest top-1% accuracy gain on RestNet-50 being +0.9% (for PBA method) and +1.5% on ResNet-200. The performance gains for various AutoMLbased data augmentation methods on the SVHN dataset are summarized in Figure [14.](#page-18-2) Again, the results show impressive performance on challenging digit classification tasks. In Table [7](#page-22-0) we compute the average performance of different categories of automated data augmentation methods based on the optimization strategies they employ. The results show that performance difference across different search methods, on average, is largely insignificant.

While the majority of approaches have reported results for image classification tasks, a few works have evaluated the performance of automated data augmentation techniques on machine learning tasks other than image classification. For instance, Liu et al. [\[107\]](#page-26-3), Cubuk et al. [\[34\]](#page-24-13) and Chen et al. [\[188\]](#page-27-38) investigate the performance of common automated data augmentation methods–AA [\[17\]](#page-23-16), DADA [\[31\]](#page-24-10), DDAS [\[107\]](#page-26-3)–on object detection tasks. The tests were conducted using large-scale detection models, specifically, ResNet-101 and RetinaNet. The results of these experiments are summarized in Table [5.](#page-19-0) These studies show that AutoML-based data augmentation methods are effective for object detection. Indeed, per the results in Table [5,](#page-19-0) the data augmentation techniques lead to an average performance improvement of 1.54% (mean average precision or mAP) for object detection models.

#### Table 3

<span id="page-18-0"></span>Performance of automated data augmentation methods on CIFAR-10 and CIFAR-100 datasets. The backbone models used are Wide-ResNet-28-10 (WRN 28-10), Shake-Shake-26 2x32d (S-S 26-32) and PyramidNet (PNet). The average recognition accuracy values over all three backbone models are indicated as mean.

| Method              | CIFAR-10 |             |      | CIFAR-100 |       |       |      |       |
|---------------------|----------|-------------|------|-----------|-------|-------|------|-------|
|                     | WRN28-10 | S-S<br>PNet |      |           | WRN   | S-S   |      |       |
|                     |          | 26-32       | +SD  | Mean      | 28-10 | 26-32 | PNet | Mean  |
| Baseline            | 96.1     | 97.1        | 97.3 | 96.83     | 81.2  | 82.9  | 86.0 | 83.37 |
| AutoAugment [17]    | 97.4     | 98.1        | 98.5 | 98.0      | 82.9  | 85.7  | 89.3 | 85.97 |
| AdaAug              | 97.4     |             |      |           |       |       |      |       |
| AdvAA [110]         | 98.1     | 98.2        | 98.6 | 98.3      | 84.5  | 85.9  | 89.6 | 86.67 |
| AWS [145]           | 98.0     | 98.3        | 98.7 | 98.3      | 84.7  | 85.9  | 89.6 | 86.73 |
| DADA [31]           | 97.3     | 98.0        | 98.3 | 97.9      | 82.5  | 84.7  | 88.8 | 85.33 |
| DDAS [107]          | 97.3     | 97.9        | -    | 97.6      | 83.4  | 84.9  | -    | 84.15 |
| DeepAA [131]        | 97.4     | 98.1        | -    | 97.8      | 83.7  | 85.2  | -    | 84.45 |
| DivAug [132]        | 98.1     | 98.1        | 98.5 | 98.2      | 84.2  | 85.3  | -    | 84.75 |
| FastAA [108]        | 97.3     | 98.0        | 98.3 | 97.87     | 82.8  | 85.4  | 88.3 | 85.50 |
| FasterAA [30]       | 97.4     | 98.0        | -    | 97.70     | 82.2  | 84.4  | -    | 83.30 |
| KeepAA              | 97.8     | 97.8        | 97.8 | 97.8      | -     | -     | -    | -     |
| MADAO               | 97.3     | -           | -    | 97.3      | -     | -     | -    | -     |
| MetaAugment [189]   | 97.7     | 98.3        | 98.6 | 98.2      | 83.8  | 86.0  | 89.5 | 86.43 |
| OLHA [114]          | 97.4     | -           | -    | 97.4      | -     | -     | -    | -     |
| OnlineAugment [120] | 97.6     | -           | -    | 97.6      |       |       |      |       |
| PAA [36]            | 97.8     | 98.2        | -    | 98.0      | 83.3  | -     | -    | 83.3  |
| PBA [37]            | 97.4     | 98.0        | 98.5 | 97.97     | 83.3  | 84.7  | 89.1 | 85.70 |
| RA [34]             | 97.3     | 98.0        | 98.5 | 98.0      | 83.3  | -     | -    | 83.30 |
| RUA [190]           | 97.4     | -           | 98.5 | 97.4      | 83.6  | -     | -    | 83.6  |
| TA [171]            | 97.5     | 98.2        | 98.6 | 98.1      | 84.3  | 86.2  | -    | 85.25 |
| TeachAugment [191]  | 97.5     | 98.0        | 98.5 | 98.0      | -     | -     | -    | -     |
| TDGA AA [192]       | 97.14    | -           | -    | 97.14     | -     | -     | -    | -     |
| UA [162]            | 97.3     | 98.1        | -    | 97.7      | 82.8  | 85.0  | -    | 83.90 |
| OnlineAugment [120] | 97.6     | -           | -    | 97.6      | 83.4  | -     | -    | 83.40 |

Table 4

<span id="page-18-1"></span>Performance of automated data augmentation methods on ImageNet dataset with ResNet-50 and ResNet-200 as backbone models. The gain in recognition accuracy is indicated as "Acc. improvement".

| Method               | ResNet-50 |       |       |                           | ResNet-200 |       |       |                           |
|----------------------|-----------|-------|-------|---------------------------|------------|-------|-------|---------------------------|
|                      | Top-1     | Top-5 | Top-1 | Acc. improvement<br>Top-5 | Top-1      | Top-5 | Top-1 | Acc. improvement<br>Top-5 |
| Baseline             | 76.3      | 93.1  | -     | -                         | 78.5       | 94.2  | -     | -                         |
| AA [17]              | 77.6      | 93.8  | +1.3  | +0.7                      | 80.0       | 95.0  | +1.5  | +0.8                      |
| AdvAA [110]          | 79.9      | 94.5  | +3.6  | +1.4                      | 81.3       | 95.3  | +2.8  | +1.1                      |
| AWS [145]            | 79.4      | 94.5  | +3.1  | +1.4                      | 81.4       | 95.3  | +2.9  | +1.1                      |
| DADA [31]            | 77.5      | 93.5  | +1.2  | +0.4                      | -          | -     | -     | -                         |
| FastAA [108]         | 77.6      | 93.7  | +1.3  | +0.6                      | 80.6       | 95.3  | +2.1  | +1.1                      |
| OLHA [114]           | 78.9      | 94.3  | +2.6  | +1.1                      | -          | -     | -     | -                         |
| OnlineAugment [OAug] | 77.6      | -     |       |                           |            |       |       |                           |
| MetaAugment [189]    | 79.7      | 94.6  | +3.4  | +1.5                      | 81.4       | 95.5  | +2.9  | +1.3                      |
| PAA [36]             | 77.5      | -     | +1.2  | -                         | -          | -     | -     | -                         |
| PBA [37]             | 77.2      | 93.4  | +0.9  | +0.3                      | -          | -     | -     | -                         |
| TeachAugment         | 77.8      | 93.7  |       |                           |            |       |       |                           |
| RA [34]              | 77.6      | 93.8  | +1.3  | +0.7                      | -          | -     | -     | -                         |
| RUA [190]            | 77.7      | -     | +1.4  | -                         | -          | -     | -     | -                         |
| OnlineAugment [120]  | 77.5      | -     | +1.2  | -                         | -          | -     | -     | -                         |
| TA [171]             | 78.1      | 93.9  | +1.8  | +0.8                      | -          | -     | -     | -                         |

**Percentage gain in accuracy over baseline using SVHN with WRN28-10** 

<span id="page-18-2"></span>![](_page_18_Figure_8.jpeg)

**Caption:** Figure 18 summarizes the performance gains of automated data augmentation methods on the SVHN dataset. The results indicate substantial improvements in classification accuracy, showcasing the effectiveness of these methods in challenging digit recognition tasks.

# **7.3 Comparision of performance of classical and AutoML-based data augmentation methods**

#### *7.3.1 Classical data augmentation methods*

The performance of many state-of-the-art classical data augmentation methods have also been evaluated for the considered benchmark datasets (i.e., CIFAR-10, CIFAR-100 and ImageNet) and model settings. The traditional augmentation methods compared on ImageNet include CutMix [\[125\]](#page-26-21), SuperMix [\[193\]](#page-28-0), MixUp [\[122\]](#page-26-18), StochasticDepth [\[194\]](#page-28-1), Table 5

<span id="page-19-0"></span>Object detection performance (in mean average precision) of different automated augmentation methods on MS COCO dataset. Results have been compiled from performance reports of various works. These are: [\[34\]](#page-24-13), [\[107\]](#page-26-3), [\[188\]](#page-27-38).

| Backbone model         | Aug. Method | mAP  | Gain in mAP | Results from |
|------------------------|-------------|------|-------------|--------------|
|                        | Baseline    | 36.9 | 0           |              |
|                        | DADA        | 38.4 | 1.5         |              |
| ResNet-50 + RetinaNet  | DDAS        | 38.1 | 1.2         | Ref. [107]   |
|                        | AA          | -    | -           |              |
|                        | Baseline    | 38.6 | 0           |              |
|                        | DADA        | 40.0 | 1.4         |              |
| ResNet-101 + RetinaNet | DDAS        | 40.1 | 1.5         | Ref. [188]   |
|                        | AA          | 39.8 | 1.2         |              |
|                        | Baseline    | 38.8 | 0           |              |
| ResNet-101 + RetinaNet | AA          | 40.4 | 1.6         | Ref. [34]    |
|                        | RA          | 40.1 | 1.3         |              |
| ResNet-200 + RetinaNet | Baseline    | 39.9 | 0           |              |
|                        | AA          | 42.1 | 2.2         | Ref. [34]    |
|                        | RA          | 41.9 | 2.0         |              |

![](_page_19_Figure_3.jpeg)

**Caption:** Figure 19 presents a comparative analysis of the performance of automated and classical data augmentation methods on the ImageNet dataset. The findings reveal that automated methods yield higher accuracy gains, emphasizing their advantages in enhancing model performance.

<span id="page-19-2"></span>Figure 15. A comparison of gain in predictive performance (percentage accuracy over baseline) of automated data augmentation methods and augmentation techniques based on conventional paradigms. The baseline accuracy is 96.1%.

ISDA [\[195\]](#page-28-2), Manifold Mixup [\[196\]](#page-28-3), PuzzleMix [\[197\]](#page-28-4), Drop-Block, IHDA [\[198\]](#page-28-5) and SaliencyMix [\[199\]](#page-28-6). For CIFAR-10 and CIFAR-100, the following methods are covered: MixUp [\[122\]](#page-26-18), CutOut [\[13\]](#page-23-12), CutMix [\[125\]](#page-26-21), ISDA [\[195\]](#page-28-2), AgMax [\[200\]](#page-28-7) and Random Erase (RE) [\[201\]](#page-28-8). The performance of these works are reported in their original sources and in various surveys. Using those results, we compute the performance gains for various datasets and models, and compare with the performance of automated data augmentation methods. These results are discussed in Subsection [7.3.2.](#page-19-1)

## <span id="page-19-1"></span>*7.3.2 Comparison of automated data augmentation methods and state-of-the art classical approaches*

In this section, we compare the performance of state-ofthe-art data agumentation methods based on classical approaches with automated data augmentation methods. The results are summarized in Figures [15,](#page-19-2) [16](#page-20-0) and [17.](#page-20-1) Again, to ensure a uniform point of reference for the assessment, we selected methods that have been evaluated on the same datasets and CNN backbone models for comparison. Specifically, the results provided for CIFAR-10 and CIFAR-100 have been tested with Wide-ResNet-28-10, Shake-Shake 26 2x32d and PyramidNet backbones; SVHN with Wide-ResNet-28-10 backbone; and ImageNet with ResNet-50 and ResNet-200 backbones.

For the sake of clarity, we computed and compared the gain in accuracy for all the methods based on quantitative results reported in the various original works. Overall, the results show consistently high performance for automated data augmentation methods over classical methods. In Figure [15,](#page-19-2) we compare the performance of the best automated data augmentation methods with state-of-the-

![](_page_20_Figure_0.jpeg)

**Caption:** Figure 20 illustrates the performance of automated data augmentation techniques compared to classical methods on the ImageNet dataset. The results demonstrate that automated methods achieve superior accuracy, highlighting their effectiveness in improving model generalization.

<span id="page-20-0"></span>Figure 16. Performance of automated data augmentation techniques versus manual methods on CIFAR-100 using Wide-ResNet-28-10 CNN backbone. The results depict improvement gain (in % accuracy) over the baseline. Baseline performance is81.2%.

![](_page_20_Figure_2.jpeg)

**Caption:** Figure 22 summarizes the average performance of different search strategies for automated data augmentation. The results indicate that while reinforcement learning methods yield high accuracy, simpler approaches like searchless methods can achieve competitive performance with significantly lower computational costs.

<span id="page-20-1"></span>Figure 17. Comparison of gain in performance for automated data augmentation and conventional methods on ImageNet dataset using ResNet-50. The baseline performance is 76.3% and 93.1% for top-1 and top-5% accuracy, respectively.

art approaches based on classical techniques on CIFAR-10. In the case of classical methods, IHDA [\[198\]](#page-28-5) shows the highest performance (+1.7%), followed by MixUP (+1.2%) and GridMask (+1.1%). These are all well-below the best automated augmentation methods, which achieve an average of +2.17% gain in classification accuracy. In Figure [15,](#page-19-2) it can be observed that only one classical data augmentation method, IHDA [\[198\]](#page-28-5) at

6 th

, ranks among the top ten data augmentation methods. Similarly, for CIFAR-100 (Figure [16\)](#page-20-0), the automated methods have convincingly outperformed the classical augmentation methods, averaging +1.47% gain in performance compared with +2.28% for classical methods. Only two classical methods–SuperMix(+2.4%) and GridMask (+2.2%)–are part of the ten best performing augmentation methods. Figure [17](#page-20-1) shows the relative performance of automated and trational methods on ImageNet dataset with ResNet-50 backbone. Results are shown for top-1% and top-5% accuracies. Here, too, AutoMl-based augmentation methods significantly outperform their classical counterparts. For instance, for the top-5% classification accuracies, four out of the top five and eight out of the top ten methods are automated augmentation methods. These results convincingly demonstrate the superior performance of data augmentation techniques based AutoML pipelines.

## *7.3.3 Improving performance by combining classical and AutoML methods*

Combining automated data augmentation strategies with multiple classical data augmentation methods has been shown by several authors (e.g., Atienza [\[200\]](#page-28-7) and Tang et al. [\[120\]](#page-26-16)) to be effective in image classification tasks. Atienza [\[200\]](#page-28-7) compared the gain in classification accuracy from AutoAugment (AA) and several other state-of-the-art classical data augmentation techniques (specifically, CutMix [\[202\]](#page-28-9), CutOut [\[13\]](#page-23-12), MixUp [\[122\]](#page-26-18) and AgMax [\[200\]](#page-28-7)) with a deep-learned augmentation strategy (AA [\[17\]](#page-23-16)).

They first assessed the performance of each technique separately before pairing AutoAugment with each of the classical augmentation methods. The results obtained by their experiments showed marked improvement by the paired augmentation strategies over AutoAugment. The combined augmentations also outperformed each of the classical methods when applied independently. All cases of combined augmentations resulted in significant performance improvements over corresponding single augmentations. More importantly, utilizing a combination of three augmentations also showed a marked improvement over those employing only two augmentation strategies. The results of the study are summarized in Table [6.](#page-21-0) The author used CIFAR10 dataset with WideResNet-40-2 backbone in their experimental setting. Note that the original works AA, MixUp and CutMix do not report results for the WideResNet-28-10 backbone. Because of the difference in training settings, the accuracies of individual methods reported (and shown in the Figure [15\)](#page-19-2) are slightly different from those obtained by the original sources. Nonetheless, they reflect the general performance of the models based on the specific techniques and dataset configurations. The experimental results show that while automated data augmentation methods hold significant promise, there is still scope for the application of classical methods to complement augmentations generated automatically. However, applying multiple augmentations in this manner ought to be carefully considered as combining augmentations have been shown to harm performance in some settings (e.g., [\[203\]](#page-28-10)).

## **8 DISCUSSIONS**

#### **8.1 The importance of computational efficiency**

Because of the enormous compute resource demand of earlier approaches, most works (e.g., FasterAA, PAA AdvAA, OHLAA and AWS) have focused more on balancing generalization accuracy and computational efficiency. These works have achieved comparable performance to AutoAugment, the original approach proposed by Cubuk et al. [\[17\]](#page-23-16) while reducing the computational overhead. Many studies investigate more efficient optimization techniques in order to overcome the inherent computational complexity of RL methods. For instance, results of DDAS, FastAA and RA all demonstrate equivalent or slightly lower generalization accuracy than AA [\[17\]](#page-23-16)—one of the original works that <span id="page-21-0"></span>Performance gain by combining classical and AutoML-based data augmentation methods. The models were tested according to the specific settings described by Atienza [\[200\]](#page-28-7).

| Data Augmentation                           |           |           |  |
|---------------------------------------------|-----------|-----------|--|
|                                             | mAP       | Acc. Gain |  |
| method                                      |           |           |  |
| AA and classical methods applied separately |           |           |  |
| Standard (no aug)                           | 95.1      | o         |  |
| AA [17]                                     | 95.9      | 0.8       |  |
| CutMix [125]                                | 96.2      | 1.1       |  |
| CutOut [13]                                 | 96.2      | 1.1       |  |
| MixUp [122]                                 | 95.8      | 0.7       |  |
| AgMax [200]                                 | 95.6      | 0.5       |  |
| Pairing of AA with one classical method     |           |           |  |
| AA + CutOut                                 | 96.4      | 1.3       |  |
| AA + MixUp                                  | 96.0      | 0.9       |  |
| AA + CutMix                                 | 96.4      | 1.3       |  |
| AA[5] + AgMax                               | 96.4(0.5) | 1.3       |  |
| Pairing of classical methods                |           |           |  |
| CutMix + AgMax                              | 96.7(0.5) | 1.6       |  |
| CutOut + AgMax                              | 96.6(0.4) | 1.5       |  |
| MixUp + AgMax                               | 96.3(0.5) | 1.2       |  |
| combination of two classical methods and AA |           |           |  |
| CutOut+AA + AgMax                           | 97.1(0.7) | 2.0       |  |
| MixUp+AA + AgMax                            | 96.6(0.6) | .5        |  |
| CutMix+AA + AgMax                           | 96.8(0.4) | 1.7       |  |

introduced the concept of data augmentation based AutoML—but significantly reduced the computation time from 5,000 GPU hours in AA to just 10 (e.g., 5 hours in PBA, 3.5 in FastAA, and 0.23 hours in FasterAA) . Some other works [e.g., UA and RA) focus on simplifying the search space so that good augmentation policies can be found using much simpler search strategies or without explicitly conducting search. These approaches, despite the significant reduction in compute time, have shown competitive performance. However, there seems to be little room to further extend their predictive performance.

# **8.2 Predictive performance versus computational requirements**

As stated earlier, a major problem with AutoML-based data augmentation approaches is the tendency to excessively expand the training set in a bid to increase predictive performance. This can lead to situations where small performance gains are achieved at the expense of a disproportionately high increase in model complexity and computational resource requirements. Consequently, in practical settings, there is often a trade-off between model predictive accuracy on one hand, and computational and space complexity and interpretability on the other. Some state-of-the-art methods such as [\[205\]](#page-28-11) and [\[206\]](#page-28-12) provide mechanisms to set priority levels to achieve the right balance of predictive performance, computational budget and model interpretability. For instance, Tsamardinos et al. [\[205\]](#page-28-11) design different model configuration options, with each configuration prioritizing a specific objective: interpretability, predictive performance, and minimization of model size through more aggressive feature reduction. These configuration settings allow users to customize the AutoML pipeline according to their particular needs and constraints. This capability is widely used

Table 7 Average performance of different search strategies for automated data augmentation

<span id="page-22-0"></span>

| Search strategy                 | Example works                                                      |               | Time**<br>(Avg) |
|---------------------------------|--------------------------------------------------------------------|---------------|-----------------|
| Reinforcement learning (RL)     | AA [17], AWS [145], PAA [36], Ref. [119], FasterAA [30], BDA [109] | (Avg)<br>78.2 | 210             |
| Evolutionary algorithm (EA)     | PBA [37]), MODALS [152], PPBA [151], TDGA [192]                    | 77.2          | 42              |
| Gradient descent (GD)           | DADA [159], AutoDO [204], OHLAA [114], AdvAA [110]                 | 78.8          | 3.5             |
| Bayesian optimization           | SAPA [123], BO-Aug [149], FastAA [108]                             | 77.6          | 6.3             |
| Greedy search and random search | GreedyAA [170] Ref. [170], [175]                                   | 77.5          | 8.8             |
| Searchless methods              | RA [34], UA [162]                                                  | 77.6          | 0.0***          |

in popular AutoML tools that are designed for generic applications.

# **8.3 Open problems and research directions**

Automated data augmentation methods have in recent years shown a lot of promise and, as confirmed by the comparative quantitative results in Section 7, have outperformed state-of-the-art manual data augmentation techniques on various benchmarks. Despite the impressive feat, there are a number of important challenges and unsolved problems. We summarize some of the key ones here.

- One of the most challenging tasks in the implementation of automated data augmentation, and indeed in the development of AutoML models in general, is the task of composing a good search space that can provide effective solution for the target application. Even though approaches that learn to automatically generate effective search spaces from data have been devised, they generally require substantial domain knowledge to design, making it challenging for nonexperts to accomplish. Recently, large language models (LMMs) have been leveraged to automate complex machine learning tasks. Preliminary work by Yang et al. [\[207\]](#page-28-14) has shown that with LLMs it will be possible to fully automate the development of AutoML and operation of frameworks in a way that allows lay users to build and use these models. For instance, leveraging the rich knowledge of LLMs will allow nonexpert developers to easily generate effective, context-relevant search spaces and associated hyperparameters for data augmentation. In addition, intuitive user interfaces based on LLMs will enable lay users to simply specify natural language instructions to configure various settings of the resulting model. These frameworks, through the LMM interfaces, can also provide useful feedback and suggestions, as well as explanations about the internal mechanisms and operation of the model.
- The automation of data augmentation is an extremely computationally intensive process. Given that for a dataset several augmentations can be combined in different ways (e.g., varying numbers of transformation operations and different ordering

of their application) and each transformation operation can be applied with infinitely wide range of intensities, the number of possible augmentations is effectively unlimited. In order to establish the effectiveness of any new augmentation using appropriate search strategies, it is usually necessary to conduct exhaustive training and subsequently validate the performance on a proxy task or the target task. This procedure is a combinatorial problem and, using current approaches, in some cases it is impractical to arrive at an optimal solution within a practical time frame. A potentially effective workaround is to leverage large language model prompts to guide the search process towards better solutions. Such a mechanism could also provide a means of highlevel interaction that allows developers' priorities and constraints (e.g., infrastructure limitations, economic constraints, time laxity, etc.) to be factored in the search process. The performance evaluation step could also benefit from such new techniques by leveraging real-time feedback from LLMs.

- One of the major problems of machine learning tasks that require data augmentation is imbalanced data—a situation where some classes are underrepresented while others are overrepresented. This results in a problem where predictive performance on minority classes is severely compromised. Even though there are data augmentation-based workarounds specifically designed to overcome this problem (i.e., to balance imbalanced data), automated data augmentation methods have not yet been extended to this domain. Future research is expected to produce dedicated AutoML frameworks specifically aimed at balancing imbalance training data.
- Currently, the automated data augmentation process is based on creating different variations of the input data and combing them in a random manner. However, it is known that the effectiveness of the data augmentation greatly depends on the order of augmentation. We expect future research to provide better theoretical grounding relating to the (general) ordering of augmentation operations for specific data types and tasks. Such an approach may rely on knowledge of the representative quality of the data with respect to the given task as various transforma-

tions are applied in sequence. Alternatively , principled formulations may be devised to quantify in advanced the effect of applying given transformations in specific sequences.

- In manual data augmentation processes, the human expert relies on intuition and domain expertise to determine the most suitable augmentations and their strengths. This greatly reduces the number of artificial samples that need to be created. It also increases robustness and reliability since the most important missing samples will logically be included in the augmented data. Automated augmentation methods, on the other hand, typically create a large number of redundant samples. In some situations, this can adversely harm performance and reliability. Overcoming this challenge requires the incorporation of context knowledge in automated data augmentation schemes. Context-aware automated data augmentation strategies would become vital in the near future as the requirements for machine learning systems are continuously been pushed to the limits. This objective may be achieved by introducing additional, domain-specific optimizations to force the generated data to align with real-world constraints . To accomplish this, logical rules or domain knowledge represented in any appropriate form may be utilized.
- While conventional data augmentation strategies rely on constructing dataset- and task-specific solutions, automatically learned policies have been shown (e.g., [\[17\]](#page-23-16)) to be generally more transferable to new datasets. This property could potentially be exploited to provide further insights towards developing generic augmentations strategies for a wider range of deep learning tasks that are independent of datasets. Some interesting results [\[208\]](#page-28-15) in this direction have already been reported. Future line of research will involve devising mechanisms to optimize models based on their transferability. This will enable the underlying models to encode more transferable architectureual features and hyperparameter settings, thereby generating task- and datasetagnostic AutoML frameworks.

## **9 CONCLUSION**

In this work we present a comprehensive survey of data augmentation methods based on AutoML techniques. We discuss different ways of realizing data augmentation using AutoML approaches. In particular, we cover data manipulation, data integration and data synthesis techniques. We also consider approaches for accomplishing all the subtasks of the data augmentation process: search space construction, model and hyperparameter optimization, and evaluation of intermediate solutions. Importantly, we provide a thorough discussion of the performance of automated data augmentation methods. In this regard, the performance of automated data augmentation methods are compared with results based on state-of-the-art classical approaches. The results show that automated data augmentaation methods are currently superior to classical approaches in terms of predictive performance. Their main drawback, however, is their relatively high complexity of models and the enormous computaional requirements. Because of their enormous performance advantage, the automated methods are expected to improve further and assume an even more dominant role in large-scale data augmentation tasks.

# **REFERENCES**

- <span id="page-23-0"></span>[1] D. Kollias, "Abaw: Learning from synthetic data & multi-task learning challenges," in *European Conference on Computer Vision*. Springer, 2023, pp. 157–172.
- <span id="page-23-1"></span>[2] J. Tabak, M. Poli´c, and M. Orsag, "Towards synthetic data: Dealing with the texture-bias in sim2real learning," in *Intelligent Autonomous Systems 17: Proceedings of the 17th International Conference IAS-17*. Springer, 2023, pp. 630–642.
- <span id="page-23-2"></span>[3] H. Murtaza, M. Ahmed, N. F. Khan, G. Murtaza, S. Zafar, and A. Bano, "Synthetic data generation: State of the art in health care domain," *Computer Science Review*, vol. 48, p. 100546, 2023.
- <span id="page-23-3"></span>[4] O. Kwon, J. Park, and S. Oh, "Renderable neural radiance map for visual navigation," *arXiv preprint [arXiv:2303.00304](http://arxiv.org/abs/2303.00304)*, 2023.
- <span id="page-23-4"></span>[5] M. Zhang, S. Zheng, Z. Bao, M. Hebert, and Y.-X. Wang, "Beyond rgb: Scene-property synthesis with neural radiance fields," in *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2023, pp. 795–805.
- <span id="page-23-5"></span>[6] M. V. da Silva, L. H. Silva, J. D. D. Junior, M. C. Escarpinati, A. R. Backes, and J. F. Mari, "Generating synthetic multispectral images using neural style transfer: A study with application in channel alignment," *Computers and Electronics in Agriculture*, vol. 206, p. 107668, 2023.
- <span id="page-23-6"></span>[7] Y. Feng, B. Q. Chandio, S. I. Thomopoulos, and P. M. Thompson, "Variational autoencoders for generating synthetic tractographybased bundle templates in a low-data setting," *bioRxiv*, pp. 2023– 02, 2023.
- <span id="page-23-7"></span>[8] R. Wang, V. Bashyam, Z. Yang, F. Yu, V. Tassopoulou, S. S. Chintapalli, I. Skampardoni, L. P. Sreepada, D. Sahoo, K. Nikita *et al.*, "Applications of generative adversarial networks in neuroimaging and clinical neuroscience," *NeuroImage*, p. 119898, 2023.
- <span id="page-23-8"></span>[9] S. Suri, I. F. Ilyas, C. Ré, and T. Rekatsinas, "Ember: No-code context enrichment via similarity-based keyless joins," *arXiv preprint [arXiv:2106.01501](http://arxiv.org/abs/2106.01501)*, 2021.
- <span id="page-23-9"></span>[10] J. Bai, J. Wang, Z. Li, D. Ding, J. Zhang, and J. Gao, "Atjnet: Auto-table-join network for automatic learning on relational databases," in *Proceedings of the Web Conference 2021*, 2021, pp. 1540–1551.
- <span id="page-23-10"></span>[11] Y. Li, X. Yu, and N. Koudas, "Data acquisition for improving machine learning models," *arXiv preprint [arXiv:2105.14107](http://arxiv.org/abs/2105.14107)*, 2021.
- <span id="page-23-11"></span>[12] R. G. Lopes, D. Yin, B. Poole, J. Gilmer, and E. D. Cubuk, "Improving robustness without sacrificing accuracy with patch gaussian augmentation," *arXiv preprint [arXiv:1906.02611](http://arxiv.org/abs/1906.02611)*, 2019.
- <span id="page-23-12"></span>[13] T. DeVries and G. W. Taylor, "Improved regularization of convolutional neural networks with cutout," *arXiv preprint [arXiv:1708.04552](http://arxiv.org/abs/1708.04552)*, 2017.
- <span id="page-23-13"></span>[14] R. Raileanu, M. Goldstein, D. Yarats, I. Kostrikov, and R. Fergus, "Automatic data augmentation for generalization in reinforcement learning," *Advances in Neural Information Processing Systems*, vol. 34, pp. 5402–5415, 2021.
- <span id="page-23-14"></span>[15] S. Ravuri and O. Vinyals, "Seeing is not necessarily believing: Limitations of biggans for data augmentation," 2019.
- <span id="page-23-15"></span>[16] C. Xue, J. Yan, R. Yan, S. M. Chu, Y. Hu, and Y. Lin, "Transferable automl by model sharing over grouped datasets," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2019, pp. 9002–9011.
- <span id="page-23-16"></span>[17] E. D. Cubuk, B. Zoph, D. Mane, V. Vasudevan, and Q. V. Le, "Autoaugment: Learning augmentation strategies from data," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2019, pp. 113–123.
- <span id="page-23-17"></span>[18] D. Kim, J. Koo, and U.-M. Kim, "A survey on automated machine learning: Problems, methods and frameworks," in *International Conference on Human-Computer Interaction*. Springer, 2022, pp. 57–70.
- <span id="page-23-18"></span>[19] C. Shorten and T. M. Khoshgoftaar, "A survey on image data augmentation for deep learning," *Journal of big data*, vol. 6, no. 1, pp. 1–48, 2019.
- <span id="page-23-19"></span>[20] C. Khosla and B. S. Saini, "Enhancing performance of deep learning models with different data augmentation techniques: A survey," in *2020 International Conference on Intelligent Engineering and Management (ICIEM)*. IEEE, 2020, pp. 79–85.
- <span id="page-24-0"></span>[21] A. Mumuni and F. Mumuni, "Data augmentation: A comprehensive survey of modern approaches," *Array*, vol. 16, p. 100258, 2022.
- <span id="page-24-1"></span>[22] J. Waring, C. Lindvall, and R. Umeton, "Automated machine learning: Review of the state-of-the-art and opportunities for healthcare," *Artificial intelligence in medicine*, vol. 104, p. 101822, 2020.
- <span id="page-24-2"></span>[23] X. He, K. Zhao, and X. Chu, "Automl: A survey of the state-ofthe-art," *Knowledge-Based Systems*, vol. 212, p. 106622, 2021.
- <span id="page-24-3"></span>[24] T. Nagarajah and G. Poravi, "A review on automated machine learning (automl) systems," in *2019 IEEE 5th International Conference for Convergence in Technology (I2CT)*. IEEE, 2019, pp. 1–6.
- <span id="page-24-4"></span>[25] L. Tuggener, M. Amirian, K. Rombach, S. Lörwald, A. Varlet, C. Westermann, and T. Stadelmann, "Automated machine learning in practice: state of the art and recent results," in *2019 6th Swiss Conference on Data Science (SDS)*. IEEE, 2019, pp. 31–36.
- <span id="page-24-5"></span>[26] S. K. Karmaker, M. M. Hassan, M. J. Smith, L. Xu, C. Zhai, and K. Veeramachaneni, "Automl to date and beyond: Challenges and opportunities," *ACM Computing Surveys (CSUR)*, vol. 54, no. 8, pp. 1–36, 2021.
- <span id="page-24-6"></span>[27] Z. Yang, R. O. Sinnott, J. Bailey, and Q. Ke, "A survey of automated data augmentation algorithms for deep learning-based image classification tasks," *Knowledge and Information Systems*, vol. 65, no. 7, pp. 2805–2861, 2023.
- <span id="page-24-7"></span>[28] T.-H. Cheung and D.-Y. Yeung, "A survey of automated data augmentation for image classification: Learning to compose, mix, and generate," *IEEE Transactions on Neural Networks and Learning Systems*, 2023.
- <span id="page-24-8"></span>[29] R. Hataya, J. Zdenek, K. Yoshizoe, and H. Nakayama, "Meta approach to data augmentation optimization," in *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2022, pp. 2574–2583.
- <span id="page-24-9"></span>[30] ——, "Faster autoaugment: Learning augmentation strategies using backpropagation," in *European Conference on Computer Vision*. Springer, 2020, pp. 1–16.
- <span id="page-24-10"></span>[31] Y. Li, G. Hu, Y. Wang, T. Hospedales, N. M. Robertson, and Y. Yang, "Differentiable automatic data augmentation," in *European Conference on Computer Vision*. Springer, 2020, pp. 580–595.
- <span id="page-24-11"></span>[32] S. Mounsaveng, I. Laradji, I. Ben Ayed, D. Vazquez, and M. Pedersoli, "Learning data augmentation with online bilevel optimization for image classification," in *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2021, pp. 1691–1700.
- <span id="page-24-12"></span>[33] H. Miao and L. T. Rahman, "Multi-class traffic sign classification using autoaugment and spatial transformer."
- <span id="page-24-13"></span>[34] E. Cubuk, B. Zoph, J. Shlens, Q. R. Le, and Randaugment, "Practical automated data augmentation with a reduced search space," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*, pp. 3008–3017.
- <span id="page-24-14"></span>[35] T. Kashima, Y. Yamada, and S. Saito, "Joint search of data augmentation policies and network architectures," *arXiv preprint [arXiv:2012.09407](http://arxiv.org/abs/2012.09407)*, 2020.
- <span id="page-24-15"></span>[36] S. Lin, T. Yu, R. Feng, X. Li, X. Jin, and Z. Chen, "Local patch autoaugment with multi-agent collaboration," *arXiv e-prints*, pp. arXiv–2103, 2021.
- <span id="page-24-16"></span>[37] D. Ho, E. Liang, X. Chen, I. Stoica, and P. Abbeel, "Population based augmentation: Efficient learning of augmentation policy schedules," in *International Conference on Machine Learning*. PMLR, 2019, pp. 2731–2741.
- <span id="page-24-17"></span>[38] M. Xu, S. Yoon, A. Fuentes, and D. S. Park, "A comprehensive survey of image augmentation techniques for deep learning," *Pattern Recognition*, p. 109347, 2023.
- <span id="page-24-18"></span>[39] T. Niu and M. Bansal, "Automatically learning data augmentation policies for dialogue tasks," *arXiv preprint [arXiv:1909.12868](http://arxiv.org/abs/1909.12868)*, 2019.
- <span id="page-24-19"></span>[40] S. Ren, J. Zhang, L. Li, X. Sun, and J. Zhou, "Text autoaugment: Learning compositional augmentation policy for text classification," *arXiv preprint [arXiv:2109.00523](http://arxiv.org/abs/2109.00523)*, 2021.
- <span id="page-24-20"></span>[41] H. Dai, Z. Liu, W. Liao, X. Huang, Y. Cao, Z. Wu, L. Zhao, S. Xu, W. Liu, N. Liu *et al.*, "Auggpt: Leveraging chatgpt for text data augmentation," *arXiv preprint [arXiv:2302.13007](http://arxiv.org/abs/2302.13007)*, 2023.
- <span id="page-24-21"></span>[42] H. Zhao, H. Chen, T. A. Ruggles, Y. Feng, D. Singh, and H.-J. Yoon, "Improving text classification with large language modelbased data augmentation," *Electronics*, vol. 13, no. 13, p. 2535, 2024.
- <span id="page-24-22"></span>[43] A. Tornede, D. Deng, T. Eimer, J. Giovanelli, A. Mohan, T. Ruhkopf, S. Segel, D. Theodorakopoulos, T. Tornede, H. Wachsmuth *et al.*, "Automl in the age of large language models: Current challenges, future opportunities and risks," *arXiv preprint [arXiv:2306.08107](http://arxiv.org/abs/2306.08107)*, 2023.
- <span id="page-24-23"></span>[44] A. Margeloiu, A. Bazaga, N. Simidjievski, P. Liò, and M. Jamnik, "Tabmda: Tabular manifold data augmentation for any classifier using transformers with in-context subsetting," *arXiv preprint [arXiv:2406.01805](http://arxiv.org/abs/2406.01805)*, 2024.
- <span id="page-24-24"></span>[45] S. Zhang and K. Balog, "Auto-completion for data cells in relational tables," in *Proceedings of the 28th ACM International Conference on Information and Knowledge Management*, 2019, pp. 761–770.
- <span id="page-24-25"></span>[46] J. Fang, C. Tang, Q. Cui, F. Zhu, L. Li, J. Zhou, and W. Zhu, "Semisupervised learning with data augmentation for tabular data," in *Proceedings of the 31st ACM International Conference on Information & Knowledge Management*, 2022, pp. 3928–3932.
- <span id="page-24-34"></span>[47] N. Chepurko, R. Marcus, E. Zgraggen, R. C. Fernandez, T. Kraska, and D. Karger, "Arda: automatic relational data augmentation for machine learning," *arXiv preprint [arXiv:2003.09758](http://arxiv.org/abs/2003.09758)*, 2020.
- <span id="page-24-26"></span>[48] S. Bazrafkan, T. Nedelcu, P. Filipczuk, and P. Corcoran, "Deep learning for facial expression recognition: A step closer to a smartphone that knows your moods," in *2017 IEEE International Conference on Consumer Electronics (ICCE)*. IEEE, 2017, pp. 217– 220.
- <span id="page-24-27"></span>[49] B. Gao, H. Gouk, and T. M. Hospedales, "Searching for robustness: Loss learning for noisy classification tasks," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2021, pp. 6670–6679.
- <span id="page-24-28"></span>[50] B. Gao, "Meta-learning to optimise: loss functions and update rules," 2023.
- <span id="page-24-29"></span>[51] Y.-Y. Kim, K. Song, J. Jang, and I.-C. Moon, "Lada: Look-ahead data acquisition via augmentation for deep active learning," *Advances in Neural Information Processing Systems*, vol. 34, pp. 22 919–22 930, 2021.
- <span id="page-24-30"></span>[52] Q. Yao, H. Yang, B. Han, G. Niu, and J. T.-Y. Kwok, "Searching to exploit memorization effect in learning with noisy labels," in *International Conference on Machine Learning*. PMLR, 2020, pp. 10 789–10 798.
- <span id="page-24-31"></span>[53] J. Shu, X. Yuan, D. Meng, and Z. Xu, "Dac-mr: Data augmentation consistency based meta-regularization for meta-learning," *arXiv preprint [arXiv:2305.07892](http://arxiv.org/abs/2305.07892)*, 2023.
- <span id="page-24-32"></span>[54] C. Gao, C. Liu, J. Shu, F. Liu, J. Liu, L. Yang, X. Gao, and D. Meng, "Are dense labels always necessary for 3d object detection from point cloud?" *arXiv preprint [arXiv:2403.02818](http://arxiv.org/abs/2403.02818)*, 2024.
- <span id="page-24-33"></span>[55] B. Gao, H. Gouk, Y. Yang, and T. Hospedales, "Loss function learning for domain generalization by implicit gradient," in *International Conference on Machine Learning*. PMLR, 2022, pp. 7002–7016.
- <span id="page-24-35"></span>[56] A. Kumar, J. Naughton, and J. M. Patel, "Learning generalized linear models over normalized data," in *Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data*, 2015, pp. 1969–1984.
- <span id="page-24-36"></span>[57] M. Esmailoghli, J.-A. Quiané-Ruiz, and Z. Abedjan, "Cocoa: Correlation coefficient-aware data augmentation." in *EDBT*, 2021, pp. 331–336.
- <span id="page-24-37"></span>[58] C. Koutras, G. Siachamis, A. Ionescu, K. Psarakis, J. Brons, M. Fragkoulis, C. Lofi, A. Bonifati, and A. Katsifodimos, "Valentine: Evaluating matching techniques for dataset discovery," in *2021 IEEE 37th International Conference on Data Engineering (ICDE)*. IEEE, 2021, pp. 468–479.
- <span id="page-24-38"></span>[59] G. Li, X. Zhou, and L. Cao, "Ai meets database: Ai4db and db4ai," in *Proceedings of the 2021 International Conference on Management of Data*, 2021, pp. 2859–2866.
- <span id="page-24-39"></span>[60] T. Elsken, J. H. Metzen, and F. Hutter, "Neural architecture search: A survey," *The Journal of Machine Learning Research*, vol. 20, no. 1, pp. 1997–2017, 2019.
- <span id="page-24-40"></span>[61] A. Kumar, J. Naughton, J. M. Patel, and X. Zhu, "To join or not to join? thinking twice about joins before feature selection," in *Proceedings of the 2016 International Conference on Management of Data*, 2016, pp. 19–34.
- <span id="page-24-41"></span>[62] A. Mustafa and M. Rahimi Azghadi, "Automated machine learning for healthcare and clinical notes analysis," *Computers*, vol. 10, no. 2, p. 24, 2021.
- <span id="page-25-0"></span>[63] N. O. Nikitin, P. Vychuzhanin, M. Sarafanov, I. S. Polonskaia, I. Revin, I. V. Barabanova, G. Maximov, A. V. Kalyuzhnaya, and A. Boukhanovsky, "Automated evolutionary approach for the design of composite machine learning pipelines," *Future Generation Computer Systems*, vol. 127, pp. 109–125, 2022.
- <span id="page-25-1"></span>[64] X. Shi, J. Mueller, N. Erickson, M. Li, and A. Smola, "Multimodal automl on structured tables with text fields," in *8th ICML Workshop on Automated Machine Learning (AutoML)*, 2021.
- <span id="page-25-2"></span>[65] N. Erickson, X. Shi, J. Sharpnack, and A. Smola, "Multimodal automl for image, text and tabular data," in *Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining*, 2022, pp. 4786–4787.
- <span id="page-25-3"></span>[66] N. Erickson, J. Mueller, A. Shirkov, H. Zhang, P. Larroy, M. Li, and A. Smola, "Autogluon-tabular: Robust and accurate automl for structured data," *arXiv preprint [arXiv:2003.06505](http://arxiv.org/abs/2003.06505)*, 2020.
- <span id="page-25-4"></span>[67] F. Nargesian, A. Asudeh, and H. Jagadish, "Responsible data integration: Next-generation challenges," in *Proceedings of the 2022 International Conference on Management of Data*, 2022, pp. 2458–2464.
- <span id="page-25-5"></span>[68] C. Chai, J. Liu, N. Tang, G. Li, and Y. Luo, "Selective data acquisition in the wild for model charging," *PVLDB*, vol. 15, no. 7, pp. 1466–1478, 2022.
- <span id="page-25-6"></span>[69] M. K. Shende, A. E. Feijoo-Lorenzo, and N. D. Bokde, "cleants: Automated (automl) tool to clean univariate time series at microscales," *Neurocomputing*, 2022.
- <span id="page-25-7"></span>[70] A. Mangrulkar, S. Rane, and V. Sunnapwar, "Image-based bio-cad modeling: overview, scope, and challenges," in *Journal of Physics: Conference Series*, vol. 1706, no. 1. IOP Publishing, 2020, p. 012189.
- <span id="page-25-8"></span>[71] S. I. Nikolenko, *Synthetic data for deep learning*. Springer, 2021, vol. 174.
- <span id="page-25-9"></span>[72] C. M. de Melo, A. Torralba, L. Guibas, J. DiCarlo, R. Chellappa, and J. Hodgins, "Next-generation deep learning based on simulators and synthetic data," *Trends in cognitive sciences*, 2021.
- <span id="page-25-10"></span>[73] J. Tremblay, A. Prakash, D. Acuna, M. Brophy, V. Jampani, C. Anil, T. To, E. Cameracci, S. Boochoon, and S. Birchfield, "Training deep networks with synthetic data: Bridging the reality gap by domain randomization," in *Proceedings of the IEEE conference on computer vision and pattern recognition workshops*, 2018, pp. 969–977.
- <span id="page-25-11"></span>[74] B. Starly, Z. Fang, W. Sun, A. Shokoufandeh, and W. Regli, "Three-dimensional reconstruction for medical-cad modeling," *Computer-Aided Design and Applications*, vol. 2, no. 1-4, pp. 431– 438, 2005.
- <span id="page-25-12"></span>[75] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su *et al.*, "Shapenet: An information-rich 3d model repository," *arXiv preprint [arXiv:1512.03012](http://arxiv.org/abs/1512.03012)*, 2015.
- <span id="page-25-13"></span>[76] S. Mishra, R. Panda, C. P. Phoo, C.-F. R. Chen, L. Karlinsky, K. Saenko, V. Saligrama, and R. S. Feris, "Task2sim: Towards effective pre-training and transfer from synthetic data," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2022, pp. 9194–9204.
- <span id="page-25-14"></span>[77] Y. Wang, N. Mu, D. Grandi, N. Savva, and J. Steinhardt, "A3d: Studying pretrained representations with programmable datasets," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2022, pp. 4878–4889.
- <span id="page-25-15"></span>[78] Y. Du, O. Watkins, T. Darrell, P. Abbeel, and D. Pathak, "Autotuned sim-to-real transfer," in *2021 IEEE International Conference on Robotics and Automation (ICRA)*. IEEE, 2021, pp. 1290–1296.
- <span id="page-25-16"></span>[79] J. L. Thompson, "Augmenting biological pathway extraction with synthetic data and active learning," Ph.D. dissertation, University of Missouri–Columbia, 2022.
- <span id="page-25-17"></span>[80] O. Owoyele, P. Pal, A. Vidal Torreira, D. Probst, M. Shaxted, M. Wilde, and P. K. Senecal, "Application of an automated machine learning-genetic algorithm (automl-ga) coupled with computational fluid dynamics simulations for rapid engine design optimization," *International Journal of Engine Research*, vol. 23, no. 9, pp. 1586–1601, 2022.
- <span id="page-25-32"></span>[81] R. J. Williams, "Simple statistical gradient-following algorithms for connectionist reinforcement learning," *Machine learning*, vol. 8, no. 3, pp. 229–256, 1992.
- <span id="page-25-18"></span>[82] H. S. Behl, A. G. Baydin, R. Gal, P. H. Torr, and V. Vineet, "Autosimulate:(quickly) learning synthetic data generation," in *European Conference on Computer Vision*. Springer, 2020, pp. 255– 271.
- <span id="page-25-19"></span>[83] N. Ruiz, S. Schulter, and M. Chandraker, "Learning to simulate," *arXiv preprint [arXiv:1810.02513](http://arxiv.org/abs/1810.02513)*, 2018.
- <span id="page-25-20"></span>[84] S. Shirobokov, V. Belavin, M. Kagan, A. Ustyuzhanin, and A. G. Baydin, "Black-box optimization with local generative surrogates," *Advances in Neural Information Processing Systems*, vol. 33, pp. 14 650–14 662, 2020.
- <span id="page-25-21"></span>[85] D. Sun, D. Vlasic, C. Herrmann, V. Jampani, M. Krainin, H. Chang, R. Zabih, W. T. Freeman, and C. Liu, "Autoflow: Learning a better training set for optical flow," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2021, pp. 10 093–10 102.
- <span id="page-25-22"></span>[86] A. Kar, A. Prakash, M.-Y. Liu, E. Cameracci, J. Yuan, M. Rusiniak, D. Acuna, A. Torralba, and S. Fidler, "Meta-sim: Learning to generate synthetic datasets," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2019, pp. 4551–4560.
- <span id="page-25-23"></span>[87] Y. Ge, H. Behl, J. Xu, S. Gunasekar, N. Joshi, Y. Song, X. Wang, L. Itti, and V. Vineet, "Neural-sim: Learning to generate training data with nerf," in *European Conference on Computer Vision*. Springer, 2022, pp. 477–493.
- <span id="page-25-24"></span>[88] Y. Han, K. Luo, A. Luo, J. Liu, H. Fan, G. Luo, and S. Liu, "Realflow: Em-based realistic optical flow dataset generation from videos," in *European Conference on Computer Vision*. Springer, 2022, pp. 288–305.
- <span id="page-25-25"></span>[89] A. Kortylewski, B. Egger, A. Schneider, T. Gerig, A. Morel-Forster, and T. Vetter, "Analyzing and reducing the damage of dataset bias to face recognition with synthetic data," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*, 2019, pp. 0–0.
- <span id="page-25-26"></span>[90] S. E. Ebadi, S. Dhakad, S. Vishwakarma, C. Wang, Y.-C. Jhang, M. Chociej, A. Crespi, A. Thaman, and S. Ganguly, "Psp-hdri +: A synthetic dataset generator for pre-training of human-centric computer vision models," *arXiv preprint [arXiv:2207.05025](http://arxiv.org/abs/2207.05025)*, 2022.
- <span id="page-25-27"></span>[91] N. Mayer, E. Ilg, P. Hausser, P. Fischer, D. Cremers, A. Dosovitskiy, and T. Brox, "A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation," in *Proceedings of the IEEE conference on computer vision and pattern recognition*, 2016, pp. 4040–4048.
- <span id="page-25-28"></span>[92] A. Dosovitskiy, P. Fischer, E. Ilg, P. Hausser, C. Hazirbas, V. Golkov, P. Van Der Smagt, D. Cremers, and T. Brox, "Flownet: Learning optical flow with convolutional networks," in *Proceedings of the IEEE international conference on computer vision*, 2015, pp. 2758–2766.
- <span id="page-25-29"></span>[93] D. J. Butler, J. Wulff, G. B. Stanley, and M. J. Black, "A naturalistic open source movie for optical flow evaluation," in *European conference on computer vision*. Springer, 2012, pp. 611–625.
- <span id="page-25-30"></span>[94] A. Geiger, P. Lenz, and R. Urtasun, "Are we ready for autonomous driving? the kitti vision benchmark suite," in *2012 IEEE conference on computer vision and pattern recognition*. IEEE, 2012, pp. 3354–3361.
- <span id="page-25-31"></span>[95] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, "Smote: synthetic minority over-sampling technique," *Journal of artificial intelligence research*, vol. 16, pp. 321–357, 2002.
- <span id="page-25-33"></span>[96] W. Wang and T.-W. Pai, "enhancing small tabular clinical trial dataset through hybrid data augmentation: combining smote and wcgan-gp," *Data*, vol. 8, no. 9, p. 135, 2023.
- <span id="page-25-34"></span>[97] D. Dablain, B. Krawczyk, and N. V. Chawla, "Deepsmote: Fusing deep learning and smote for imbalanced data," *IEEE Transactions on Neural Networks and Learning Systems*, vol. 34, no. 9, pp. 6390– 6404, 2022.
- <span id="page-25-35"></span>[98] M. V. C. Aragão, M. de Freitas Carvalho, T. de Morais Pereira, F. A. P. de Figueiredo, and S. B. Mafra, "Enhancing automl performance for imbalanced tabular data classification: A selfbalancing pipeline," 2024.
- <span id="page-25-36"></span>[99] H. Rashidi, S. Albahra, B. Rubin, and B. Hu, "Stng (synthetic tabular neural generator): A novel and fully automated platform for synthetic tabular data generation and validation," 2023.
- <span id="page-25-37"></span>[100] S. Xu, S. J. Semnani, G. Campagna, and M. S. Lam, "Autoqa: From databases to qa semantic parsers with only synthetic training data," *arXiv preprint [arXiv:2010.04806](http://arxiv.org/abs/2010.04806)*, 2020.
- <span id="page-25-38"></span>[101] Z. Li, L. Si, C. Guo, Y. Yang, and Q. Cao, "Data augmentation for text-based person retrieval using large language models," *arXiv preprint [arXiv:2405.11971](http://arxiv.org/abs/2405.11971)*, 2024.
- <span id="page-25-39"></span>[102] A. Glazkova and O. Zakharova, "Evaluating llm prompts for data augmentation in multi-label classification of ecological texts," *arXiv preprint [arXiv:2411.14896](http://arxiv.org/abs/2411.14896)*, 2024.
- <span id="page-25-40"></span>[103] J. Xu, J. Li, Z. Liu, N. A. V. Suryanarayanan, G. Zhou, J. Guo, H. Iba, and K. Tei, "Large language models synergize with automated machine learning," *arXiv preprint [arXiv:2405.03727](http://arxiv.org/abs/2405.03727)*, 2024.
- <span id="page-26-0"></span>[104] L. Ma, N. Li, G. Yu, X. Geng, S. Cheng, X. Wang, M. Huang, and Y. Jin, "Pareto-wise ranking classifier for multi-objective evolutionary neural architecture search," *IEEE Transactions on Evolutionary Computation*, 2023.
- <span id="page-26-1"></span>[105] L. Ma, H. Kang, G. Yu, Q. Li, and Q. He, "Single-domain generalized predictor for neural architecture search system," *IEEE Transactions on Computers*, 2024.
- <span id="page-26-2"></span>[106] Y. Sun, B. Xue, M. Zhang, G. G. Yen, and J. Lv, "Automatically designing cnn architectures using the genetic algorithm for image classification," *IEEE transactions on cybernetics*, vol. 50, no. 9, pp. 3840–3854, 2020.
- <span id="page-26-3"></span>[107] A. Liu, Z. Huang, Z. Huang, and N. Wang, "Direct differentiable augmentation search," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2021, pp. 12 219–12 228.
- <span id="page-26-4"></span>[108] S. Lim, I. Kim, T. Kim, C. Kim, and S. Kim, "Fast autoaugment," *Advances in Neural Information Processing Systems*, vol. 32, 2019.
- <span id="page-26-5"></span>[109] S. Lu, M. Zhao, S. Yuan, X. Wang, L. Yang, and D. Niu, "Bda: Bandit-based transferable autoaugment," in *Proceedings of the 2023 SIAM International Conference on Data Mining (SDM)*. SIAM, 2023, pp. 550–558.
- <span id="page-26-6"></span>[110] X. Zhang, Q. Wang, J. Zhang, and Z. Zhong, "Adversarial autoaugment," *arXiv preprint [arXiv:1912.11188](http://arxiv.org/abs/1912.11188)*, 2019.
- <span id="page-26-7"></span>[111] A. Krizhevsky, G. Hinton *et al.*, "Learning multiple layers of features from tiny images," 2009.
- <span id="page-26-8"></span>[112] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng, "Reading digits in natural images with unsupervised feature learning," 2011.
- <span id="page-26-9"></span>[113] L. Wei, A. Xiao, L. Xie, X. Zhang, X. Chen, and Q. Tian, "Circumventing outliers of autoaugment with knowledge distillation," in *European Conference on Computer Vision*. Springer, 2020, pp. 608– 625.
- <span id="page-26-10"></span>[114] C. Lin, M. Guo, C. Li, X. Yuan, W. Wu, J. Yan, D. Lin, and W. Ouyang, "Online hyper-parameter learning for autoaugmentation strategy," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2019, pp. 6579–6588.
- <span id="page-26-11"></span>[115] Y. Gao, Z. Tang, M. Zhou, and D. Metaxas, "Enabling data diversity: efficient automatic augmentation via regularized adversarial training," in *International Conference on Information Processing in Medical Imaging*. Springer, 2021, pp. 85–97.
- <span id="page-26-12"></span>[116] A. Zhao, G. Balakrishnan, F. Durand, J. V. Guttag, and A. V. Dalca, "Data augmentation using learned transformations for one-shot medical image segmentation," in *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*, 2019, pp. 8543–8553.
- <span id="page-26-13"></span>[117] M. Jaderberg, K. Simonyan, A. Zisserman *et al.*, "Spatial transformer networks," *Advances in neural information processing systems*, vol. 28, 2015.
- <span id="page-26-14"></span>[118] J. Dai, H. Qi, Y. Xiong, Y. Li, G. Zhang, H. Hu, and Y. Wei, "Deformable convolutional networks," in *Proceedings of the IEEE international conference on computer vision*, 2017, pp. 764–773.
- <span id="page-26-15"></span>[119] C.-T. Chu, M. Rohmatillah, C.-H. Lee, and J.-T. Chien, "Augmentation strategy optimization for language understanding," in *ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2022, pp. 7952–7956.
- <span id="page-26-16"></span>[120] Z. Tang, Y. Gao, L. Karlinsky, P. Sattigeri, R. Feris, and D. Metaxas, "Onlineaugment: Online data augmentation with less domain knowledge," in *European Conference on Computer Vision*. Springer, 2020, pp. 313–329.
- <span id="page-26-17"></span>[121] E. D. Cubuk, B. Zoph, D. Mane, V. Vasudevan, and Q. V. Le, "Autoaugment: Learning augmentation policies from data," *arXiv preprint [arXiv:1805.09501](http://arxiv.org/abs/1805.09501)*, 2018.
- <span id="page-26-18"></span>[122] H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, "mixup: Beyond empirical risk minimization," *arXiv preprint [arXiv:1710.09412](http://arxiv.org/abs/1710.09412)*, 2017.
- <span id="page-26-19"></span>[123] T.-Y. Hu, A. Shrivastava, J.-H. R. Chang, H. Koppula, S. Braun, K. Hwang, O. Kalinli, and O. Tuzel, "Sapaugment: Learning a sample adaptive policy for data augmentation," in *ICASSP 2021- 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2021, pp. 4040–4044.
- <span id="page-26-20"></span>[124] H. Inoue, "Data augmentation by pairing samples for images classification," *arXiv preprint [arXiv:1801.02929](http://arxiv.org/abs/1801.02929)*, 2018.
- <span id="page-26-21"></span>[125] S. Yun, D. Han, S. J. Oh, S. Chun, J. Choe, and Y. Yoo, "Cutmix: Regularization strategy to train strong classifiers with localizable features," in *Proceedings of the IEEE/CVF international conference on computer vision*, 2019, pp. 6023–6032.
- <span id="page-26-22"></span>[126] V. Chinbat and S.-H. Bae, "Ga3n: Generative adversarial autoaugment network," *Pattern Recognition*, vol. 127, p. 108637, 2022.
- <span id="page-26-23"></span>[127] X. Peng, Z. Tang, F. Yang, R. S. Feris, and D. Metaxas, "Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation," in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2018, pp. 2226–2234.
- <span id="page-26-24"></span>[128] S. Liu, S. Lu, X. Chen, Y. Feng, K. Xu, A. Al-Dujaili, M. Hong, and U.-M. O'Reilly, "Min-max optimization without gradients: Convergence and applications to adversarial ml," *arXiv preprint [arXiv:1909.13806](http://arxiv.org/abs/1909.13806)*, 2019.
- <span id="page-26-25"></span>[129] D. J.-L. Lee and S. Macke, "A human-in-the-loop perspective on automl: Milestones and the road ahead," *IEEE Data Engineering Bulletin*, 2020.
- <span id="page-26-26"></span>[130] Y. Li, Z. Wang, Y. Xie, B. Ding, K. Zeng, and C. Zhang, "Automl: From methodology to application," in *Proceedings of the 30th ACM International Conference on Information & Knowledge Management*, 2021, pp. 4853–4856.
- <span id="page-26-27"></span>[131] Y. Zheng, Z. Zhang, S. Yan, and M. Zhang, "Deep autoaugment," *arXiv preprint [arXiv:2203.06172](http://arxiv.org/abs/2203.06172)*, 2022.
- <span id="page-26-28"></span>[132] Z. Liu, H. Jin, T.-H. Wang, K. Zhou, and X. Hu, "Divaug: Plug-in automated data augmentation with explicit diversity maximization," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2021, pp. 4762–4770.
- <span id="page-26-29"></span>[133] Y. Chen, P. Zhang, T. Kong, Y. Li, X. Zhang, L. Qi, J. Sun, and J. Jia, "Scale-aware automatic augmentations for object detection with dynamic training," *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 2022.
- <span id="page-26-30"></span>[134] F. Zhou, J. Li, C. Xie, F. Chen, L. Hong, R. Sun, and Z. Li, "Metaaugment: Sample-aware data augmentation policy learning," in *Proceedings of the AAAI conference on artificial intelligence*, vol. 35, no. 12, 2021, pp. 11 097–11 105.
- <span id="page-26-31"></span>[135] T.-H. Cheung and D.-Y. Yeung, "Adaaug: Learning class-and instance-adaptive data augmentation policies," in *International Conference on Learning Representations*, 2021.
- <span id="page-26-32"></span>[136] N. Miao, T. Rainforth, E. Mathieu, Y. Dubois, Y. W. Teh, A. Foster, and H. Kim, "Learning instance-specific augmentations by capturing local invariances," 2023.
- <span id="page-26-33"></span>[137] J. Yoo and S. Kang, "Class-adaptive data augmentation for image classification," *IEEE Access*, vol. 11, pp. 26 393–26 402, 2023.
- <span id="page-26-35"></span>[138] D. Yang, A. Myronenko, X. Wang, Z. Xu, H. R. Roth, and D. Xu, "T-automl: Automated machine learning for lesion segmentation using transformers in 3d medical imaging," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2021, pp. 3962–3974.
- <span id="page-26-34"></span>[139] V. Lopes, A. Gaspar, L. A. Alexandre, and J. Cordeiro, "An automl-based approach to multimodal image sentiment analysis," in *2021 International Joint Conference on Neural Networks (IJCNN)*. IEEE, 2021, pp. 1–9.
- <span id="page-26-37"></span>[140] X. Chu and X. He, "Medpipe: End-to-end joint search of data augmentation policy and neural architecture for 3d medical image classification," 2022.
- <span id="page-26-36"></span>[141] H. Liu, K. Simonyan, and Y. Yang, "Darts: Differentiable architecture search," *arXiv preprint [arXiv:1806.09055](http://arxiv.org/abs/1806.09055)*, 2018.
- <span id="page-26-38"></span>[142] J. Snoek, H. Larochelle, and R. P. Adams, "Practical bayesian optimization of machine learning algorithms," *Advances in neural information processing systems*, vol. 25, 2012.
- <span id="page-26-39"></span>[143] T. Bäck, D. B. Fogel, and Z. Michalewicz, "Handbook of evolutionary computation," *Release*, vol. 97, no. 1, p. B1, 1997.
- <span id="page-26-40"></span>[144] L. P. Kaelbling, M. L. Littman, and A. W. Moore, "Reinforcement learning: A survey," *Journal of artificial intelligence research*, vol. 4, pp. 237–285, 1996.
- <span id="page-26-41"></span>[145] K. Tian, C. Lin, M. Sun, L. Zhou, J. Yan, and W. Ouyang, "Improving auto-augment via augmentation-wise weight sharing," *Advances in Neural Information Processing Systems*, vol. 33, pp. 19 088–19 098, 2020.
- <span id="page-26-42"></span>[146] S. N. Gowda, M. Rohrbach, F. Keller, and L. Sevilla-Lara, "Learn2augment: learning to composite videos for data augmentation in action recognition," in *European conference on computer vision*. Springer, 2022, pp. 242–259.
- <span id="page-26-43"></span>[147] D. J. White, "A survey of applications of markov decision processes," *Journal of the operational research society*, vol. 44, no. 11, pp. 1073–1096, 1993.
- <span id="page-26-44"></span>[148] M. T. Spaan, "Partially observable markov decision processes," in *Reinforcement Learning*. Springer, 2012, pp. 387–414.
- <span id="page-26-45"></span>[149] C. Zhang, X. Li, Z. Zhang, J. Cui, and B. Yang, "Bo-aug: learning data augmentation policies via bayesian optimization," *Applied Intelligence*, pp. 1–16, 2022.
- <span id="page-27-0"></span>[150] X. Wang, Y. Jin, S. Schmitt, and M. Olhofer, "Recent advances in bayesian optimization," *ACM Computing Surveys*, vol. 55, no. 13s, pp. 1–36, 2023.
- <span id="page-27-1"></span>[151] S. Cheng, Z. Leng, E. D. Cubuk, B. Zoph, C. Bai, J. Ngiam, Y. Song, B. Caine, V. Vasudevan, C. Li *et al.*, "Improving 3d object detection through progressive population based augmentation," in *European Conference on Computer Vision*. Springer, 2020, pp. 279–294.
- <span id="page-27-2"></span>[152] T.-H. Cheung and D.-Y. Yeung, "Modals: Modality-agnostic automated data augmentation in the latent space," in *International Conference on Learning Representations*, 2020.
- <span id="page-27-3"></span>[153] W. Grathwohl, D. Choi, Y. Wu, G. Roeder, and D. Duvenaud, "Backpropagation through the void: Optimizing control variates for black-box gradient estimation," *arXiv preprint [arXiv:1711.00123](http://arxiv.org/abs/1711.00123)*, 2017.
- <span id="page-27-4"></span>[154] G. Tucker, A. Mnih, C. J. Maddison, J. Lawson, and J. Sohl-Dickstein, "Rebar: Low-variance, unbiased gradient estimates for discrete latent variable models," *Advances in Neural Information Processing Systems*, vol. 30, 2017.
- <span id="page-27-5"></span>[155] K. Zhou, L. Hong, S. Hu, F. Zhou, B. Ru, J. Feng, and Z. Li, "Dha: end-to-end joint optimization of data augmentation policy, hyper-parameter and architecture," *arXiv preprint [arXiv:2109.05765](http://arxiv.org/abs/2109.05765)*, 2021.
- <span id="page-27-6"></span>[156] X. Wang, X. Chu, J. Yan, and X. Yang, "Daas: Differentiable architecture and augmentation policy search," *arXiv preprint [arXiv:2109.15273](http://arxiv.org/abs/2109.15273)*, 2021.
- <span id="page-27-7"></span>[157] J. Xu, M. Li, and Z. Zhu, "Automatic data augmentation for 3d medical image segmentation," in *Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part I 23*. Springer, 2020, pp. 378–387.
- <span id="page-27-8"></span>[158] Y. Akimoto, S. Shirakawa, N. Yoshinari, K. Uchida, S. Saito, and K. Nishida, "Adaptive stochastic natural gradient method for one-shot neural architecture search," in *International Conference on Machine Learning*. PMLR, 2019, pp. 171–180.
- <span id="page-27-9"></span>[159] Y. Li, G. Hu, Y. Wang, T. Hospedales, N. M. Robertson, and Y. Yang, "Dada: Differentiable automatic data augmentation," *arXiv preprint [arXiv:2003.03780](http://arxiv.org/abs/2003.03780)*, 2020.
- <span id="page-27-24"></span>[160] Z. Luo, Z. He, J. Wang, M. Dong, J. Huang, M. Chen, and B. Zheng, "Autosmart: An efficient and automatic machine learning framework for temporal relational data," in *Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining*, 2021, pp. 3976–3984.
- <span id="page-27-25"></span>[161] A. Alaa and M. Schaar, "Autoprognosis: Automated clinical prognostic modeling via bayesian optimization with structured kernel learning," in *International conference on machine learning*. PMLR, 2018, pp. 139–148.
- <span id="page-27-17"></span>[162] T. C. LingChen, A. Khonsari, A. Lashkari, M. R. Nazari, J. S. Sambee, and M. A. Nascimento, "Uniformaugment: A searchfree probabilistic data augmentation approach," *arXiv preprint [arXiv:2003.14348](http://arxiv.org/abs/2003.14348)*, 2020.
- <span id="page-27-10"></span>[163] M. Feurer and F. Hutter, "Towards further automation in automl," in *ICML AutoML workshop*, 2018, p. 13.
- <span id="page-27-11"></span>[164] R. S. Olson and J. H. Moore, "Tpot: A tree-based pipeline optimization tool for automating machine learning," in *Workshop on automatic machine learning*. PMLR, 2016, pp. 66–74.
- <span id="page-27-12"></span>[165] Y. Zhao, "Autodes: Automl pipeline generation of classification with dynamic ensemble strategy selection," *arXiv preprint [arXiv:2201.00207](http://arxiv.org/abs/2201.00207)*, 2022.
- <span id="page-27-13"></span>[166] B. Komer, J. Bergstra, and C. Eliasmith, "Hyperopt-sklearn: automatic hyperparameter configuration for scikit-learn," in *ICML workshop on AutoML*, vol. 9. Citeseer, 2014, p. 50.
- <span id="page-27-14"></span>[167] C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown, "Autoweka: Combined selection and hyperparameter optimization of classification algorithms," in *Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining*, 2013, pp. 847–855.
- <span id="page-27-15"></span>[168] T. Swearingen, W. Drevo, B. Cyphers, A. Cuesta-Infante, A. Ross, and K. Veeramachaneni, "Atm: A distributed, collaborative, scalable system for automated machine learning," in *2017 IEEE international conference on big data (big data)*. IEEE, 2017, pp. 151– 162.
- <span id="page-27-16"></span>[169] E. LeDell and S. Poirier, "H2o automl: Scalable automatic machine learning," in *Proceedings of the AutoML Workshop at ICML*, vol. 2020, 2020.
- <span id="page-27-18"></span>[170] A. Naghizadeh, M. Abavisani, and D. N. Metaxas, "Greedy autoaugment," *Pattern Recognition Letters*, vol. 138, pp. 624–630, 2020.
- <span id="page-27-19"></span>[171] S. G. Müller and F. Hutter, "Trivialaugment: Tuning-free yet stateof-the-art data augmentation," in *Proceedings of the IEEE/CVF International Conference on Computer Vision*, 2021, pp. 774–782.
- <span id="page-27-20"></span>[172] D. C. Karnopp, "Random search techniques for optimization problems," *Automatica*, vol. 1, no. 2-3, pp. 111–121, 1963.
- <span id="page-27-21"></span>[173] S. M. LaValle, M. S. Branicky, and S. R. Lindemann, "On the relationship between classical grid search and probabilistic roadmaps," *The International Journal of Robotics Research*, vol. 23, no. 7-8, pp. 673–692, 2004.
- <span id="page-27-22"></span>[174] C. Wilt, J. Thayer, and W. Ruml, "A comparison of y search algorithms," in *Proceedings of the International Symposium on Combinatorial Search*, vol. 1, no. 1, 2010, pp. 129–136.
- <span id="page-27-23"></span>[175] M. Momeny, A. A. Neshat, A. Gholizadeh, A. Jafarnezhad, E. Rahmanzadeh, M. Marhamati, B. Moradi, A. Ghafoorifar, and Y.-D. Zhang, "Greedy autoaugment for classification of mycobacterium tuberculosis image via generalized deep cnn using mixed pooling based on minimum square rough entropy," *Computers in Biology and Medicine*, vol. 141, p. 105175, 2022.
- <span id="page-27-26"></span>[176] Q. Yao, M. Wang, Y. Chen, W. Dai, Y.-F. Li, W.-W. Tu, Q. Yang, and Y. Yu, "Taking human out of learning applications: A survey on automated machine learning," *arXiv preprint [arXiv:1810.13306](http://arxiv.org/abs/1810.13306)*, 2018.
- <span id="page-27-27"></span>[177] M.-A. Zöller and M. F. Huber, "Benchmark and survey of automated machine learning frameworks," *Journal of artificial intelligence research*, vol. 70, pp. 409–472, 2021.
- <span id="page-27-28"></span>[178] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, "Imagenet: A large-scale hierarchical image database," in *2009 IEEE conference on computer vision and pattern recognition*. Ieee, 2009, pp. 248–255.
- <span id="page-27-29"></span>[179] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick, "Microsoft coco: Common objects in context," in *Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13*. Springer, 2014, pp. 740–755.
- <span id="page-27-30"></span>[180] D. Anguelov, C. Dulong, D. Filip, C. Frueh, S. Lafon, R. Lyon, A. Ogale, L. Vincent, and J. Weaver, "Google street view: Capturing the world at street level," *Computer*, vol. 43, no. 6, pp. 32–38, 2010.
- <span id="page-27-31"></span>[181] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein *et al.*, "Imagenet large scale visual recognition challenge," *International journal of computer vision*, vol. 115, pp. 211–252, 2015.
- <span id="page-27-32"></span>[182] S. Zagoruyko and N. Komodakis, "Wide residual networks," *arXiv preprint [arXiv:1605.07146](http://arxiv.org/abs/1605.07146)*, 2016.
- <span id="page-27-33"></span>[183] X. Gastaldi, "Shake-shake regularization," *arXiv preprint [arXiv:1705.07485](http://arxiv.org/abs/1705.07485)*, 2017.
- <span id="page-27-34"></span>[184] T.-Y. Lin, P. Dollár, R. Girshick, K. He, B. Hariharan, and S. Belongie, "Feature pyramid networks for object detection," in *Proceedings of the IEEE conference on computer vision and pattern recognition*, 2017, pp. 2117–2125.
- <span id="page-27-35"></span>[185] K. He, X. Zhang, S. Ren, and J. Sun, "Identity mappings in deep residual networks," in *Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part IV 14*. Springer, 2016, pp. 630–645.
- <span id="page-27-36"></span>[186] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, "Focal loss for dense object detection," in *Proceedings of the IEEE international conference on computer vision*, 2017, pp. 2980–2988.
- <span id="page-27-37"></span>[187] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in *Proceedings of the IEEE conference on computer vision and pattern recognition*, 2016, pp. 770–778.
- <span id="page-27-38"></span>[188] P. Chen, S. Liu, H. Zhao, and J. Jia, "Gridmask data augmentation," *arXiv preprint [arXiv:2001.04086](http://arxiv.org/abs/2001.04086)*, 2020.
- <span id="page-27-39"></span>[189] F. Zhou, J. Li, C. Xie, F. Chen, L. Hong, R. Sun, and Z. Li, "Metaaugment: Sample-aware data augmentation policy learning," *arXiv preprint [arXiv:2012.12076](http://arxiv.org/abs/2012.12076)*, 2020.
- <span id="page-27-40"></span>[190] X. Dong, M. Potter, G. Kumar, Y.-C. Tsai, and V. R. Saripalli, "Automating augmentation through random unidimensional search," *arXiv preprint [arXiv:2106.08756](http://arxiv.org/abs/2106.08756)*, 2021.
- <span id="page-27-41"></span>[191] T. Suzuki, "Teachaugment: Data augmentation optimization using teacher knowledge," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2022, pp. 10 904– 10 914.
- <span id="page-27-42"></span>[192] A. Terauchi and N. Mori, "Evolutionary approach for autoaugment using the thermodynamical genetic algorithm," in *Proceedings of the AAAI Conference on Artificial Intelligence*, vol. 35, no. 11, 2021, pp. 9851–9858.
- <span id="page-28-0"></span>[193] A. Dabouei, S. Soleymani, F. Taherkhani, and N. M. Nasrabadi, "Supermix: Supervising the mixing data augmentation," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2021, pp. 13 794–13 803.
- <span id="page-28-1"></span>[194] G. Huang, Y. Sun, Z. Liu, D. Sedra, and K. Q. Weinberger, "Deep networks with stochastic depth," in *European conference on computer vision*. Springer, 2016, pp. 646–661.
- <span id="page-28-2"></span>[195] Y. Wang, X. Pan, S. Song, H. Zhang, G. Huang, and C. Wu, "Implicit semantic data augmentation for deep networks," *Advances in Neural Information Processing Systems*, vol. 32, 2019.
- <span id="page-28-3"></span>[196] V. Verma, A. Lamb, C. Beckham, A. Najafi, I. Mitliagkas, D. Lopez-Paz, and Y. Bengio, "Manifold mixup: Better representations by interpolating hidden states," in *International Conference on Machine Learning*. PMLR, 2019, pp. 6438–6447.
- <span id="page-28-4"></span>[197] J.-H. Kim, W. Choo, and H. O. Song, "Puzzle mix: Exploiting saliency and local statistics for optimal mixup," in *International Conference on Machine Learning*. PMLR, 2020, pp. 5275–5285.
- <span id="page-28-5"></span>[198] A. Khan and K. Fraz, "Post-training iterative hierarchical data augmentation for deep networks," *Advances in Neural Information Processing Systems*, vol. 33, pp. 689–699, 2020.
- <span id="page-28-6"></span>[199] A. Uddin, M. Monira, W. Shin, T. Chung, S.-H. Bae *et al.*, "Saliencymix: A saliency guided data augmentation strategy for better regularization," *arXiv preprint [arXiv:2006.01791](http://arxiv.org/abs/2006.01791)*, 2020.
- <span id="page-28-7"></span>[200] R. Atienza, "Improving model generalization by agreement of learned representations from data augmentation," in *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2022, pp. 372–381.
- <span id="page-28-8"></span>[201] Z. Zhong, L. Zheng, G. Kang, S. Li, and Y. Yang, "Random erasing data augmentation," in *Proceedings of the AAAI conference on artificial intelligence*, vol. 34, no. 07, 2020, pp. 13 001–13 008.
- <span id="page-28-9"></span>[202] D. Walawalkar, Z. Shen, Z. Liu, and M. Savvides, "Attentive cutmix: An enhanced data augmentation approach for deep learning based image classification," *arXiv preprint [arXiv:2003.13048](http://arxiv.org/abs/2003.13048)*, 2020.
- <span id="page-28-10"></span>[203] Y. Wen, G. Jerfel, R. Muller, M. W. Dusenberry, J. Snoek, B. Lakshminarayanan, and D. Tran, "Combining ensembles and data augmentation can harm your calibration," *arXiv preprint [arXiv:2010.09875](http://arxiv.org/abs/2010.09875)*, 2020.
- <span id="page-28-13"></span>[204] D. Gudovskiy, L. Rigazio, S. Ishizaka, K. Kozuka, and S. Tsukizawa, "Autodo: Robust autoaugment for biased data with label noise via scalable probabilistic implicit differentiation," in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2021, pp. 16 601–16 610.
- <span id="page-28-11"></span>[205] I. Tsamardinos, P. Charonyktakis, G. Papoutsoglou, G. Borboudakis, K. Lakiotaki, J. C. Zenklusen, H. Juhl, E. Chatzaki, and V. Lagani, "Just add data: automated predictive modeling for knowledge discovery and feature selection," *NPJ precision oncology*, vol. 6, no. 1, pp. 1–17, 2022.
- <span id="page-28-12"></span>[206] I. Xanthopoulos, I. Tsamardinos, V. Christophides, E. Simon, and A. Salinger, "Putting the human back in the automl loop." in *EDBT/ICDT Workshops*, 2020.
- <span id="page-28-14"></span>[207] Z. Yang, W. Zeng, S. Jin, C. Qian, P. Luo, and W. Liu, "Autommlab: Automatically generating deployable models from language instructions for computer vision tasks," *arXiv preprint [arXiv:2402.15351](http://arxiv.org/abs/2402.15351)*, 2024.
- <span id="page-28-15"></span>[208] K. Cao, J. You, J. Liu, and J. Leskovec, "Autotransfer: Automl with knowledge transfer–an application to graph neural networks," *arXiv preprint [arXiv:2303.07669](http://arxiv.org/abs/2303.07669)*, 2023.