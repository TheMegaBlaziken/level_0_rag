# BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER

Sreyan Ghosh★ University of Maryland, College Park College Park, MD, USA sreyang@umd.edu

Sonal Kumar★ University of Maryland, College Park College Park, MD, USA skbrahee@gmail.com

#### ABSTRACT

Biomedical Named Entity Recognition (BioNER) is the fundamental task of identifying named entities from biomedical text. However, BioNER suffers from severe data scarcity and lacks high-quality labeled data due to the highly specialized and expert knowledge required for annotation. Though data augmentation has shown to be highly effective for low-resource NER in general, existing data augmentation techniques fail to produce factual and diverse augmentations for BioNER. In this paper, we present BioAug, a novel data augmentation framework for low-resource BioNER. BioAug, built on BART, is trained to solve a novel text reconstruction task based on selective masking and knowledge augmentation. Post training, we perform conditional generation and generate diverse augmentations conditioning BioAug on selectively corrupted text similar to the training stage. We demonstrate the effectiveness of BioAug on 5 benchmark BioNER datasets and show that BioAug outperforms all our baselines by a significant margin (1.5%-21.5% absolute improvement) and is able to generate augmentations that are both more factual and diverse. Code: https://github.com/Sreyan88/BioAug.

### CCS CONCEPTS

• Computing methodologies → Information extraction; Natural language generation.

#### KEYWORDS

Named Entity Recognition, Information Extraction, Biomedical

#### ACM Reference Format:

Sreyan Ghosh★, Utkarsh Tyagi★, Sonal Kumar★, and Dinesh Manocha. 2023. BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23), July 23–27, 2023, Taipei, Taiwan. ACM, New York, NY, USA, [6](#page-5-0) pages.<https://doi.org/10.1145/3539618.3591957>

★Equal technical contribution.

![](_page_0_Picture_12.jpeg)

**Caption:** Figure 1 illustrates the BioAug framework, detailing its five-step sentence corruption process for fine-tuning. Steps include keyword extraction, relation extraction, dynamic masking, sequence linearization, and knowledge augmentation, culminating in the generation of diverse and factual augmentations for low-resource biomedical NER.

[This work is licensed under a Creative Commons Attribution](https://creativecommons.org/licenses/by/4.0/) [International 4.0 License.](https://creativecommons.org/licenses/by/4.0/)

SIGIR '23, July 23–27, 2023, Taipei, Taiwan © 2023 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9408-6/23/07. <https://doi.org/10.1145/3539618.3591957>

Utkarsh Tyagi★ University of Maryland, College Park College Park, MD, USA utkarsh4430@gmail.com

Dinesh Manocha University of Maryland, College Park College Park, MD, USA dmanocha@umd.edu

## 1 INTRODUCTION

Biomedical Named Entity Recognition (BioNER) is the task of detecting named entities (NEs) from unstructured biomedical text (e.g., chemicals, diseases, genes, etc.), which are further utilized in many important downstream tasks (e.g., classifying drug-drug interaction). Compared to NER in the general domain (e.g., news), BioNER is much more challenging due to the syntactically complex nature of NEs [\[29\]](#page-4-0), large variations in NE mentions [\[15,](#page-4-1) [18\]](#page-4-2), and the rapidly emerging nature of NEs in biomedical literature [\[30\]](#page-4-3). Biomedical NLP, however, suffers from acute data scarcity due to the high cost involved in leveraging extensive domain knowledge for annotation [\[39\]](#page-4-4). Our experiments show that the performance of the state-of-the-art NER system [\[45\]](#page-5-1), when compared to CoNLL 2003 [\[36\]](#page-4-5) (news domain), drops by 35% and 21% respectively, on lowand high-resource settings (100 and 2000 gold training samples) when evaluated on the BC2GM dataset [\[37\]](#page-4-6) (biomedical domain).

Data augmentation has proven to be an effective solution for lowresource BioNER [\[16,](#page-4-7) [35\]](#page-4-8) and low-resource NER in general [\[7,](#page-4-9) [44\]](#page-5-2). The primary aim is to find n transforms of the original training samples that can be added to the original training data to improve learning. However, this area is relatively under-explored due to the difficulty of the task - generic augmentation systems which work for classification tasks suffer from token-label misalignment issues when applied to NER, as the labels in a classification dataset are less sensitive to the sequence of text than the semantics [\[16,](#page-4-7) [44\]](#page-5-2). Adding to this, existing NER data augmentations based on token replacement [\[5\]](#page-4-10) or Pre-trained Language Models (PLMs) [\[28,](#page-4-11) [44\]](#page-5-2) often fail to generate diverse, and factual[1](#page-0-0) augmentations - biomedical NEs are linguistically complex than NEs in the general domain and methods like synonym replacement [\[5\]](#page-4-10) often lead to counterfactual augmentations. Moreover, PLMs suffer from inadequacy of knowledge about these NEs due to their inability to generalize over rapidly increasing biomedical concepts (examples in Figure [2\)](#page-2-0). We argue that both these metrics are extremely important for data augmentation in BioNER. Factual augmentations promote a model to store factual knowledge in their parameters, which is crucial for the knowledge-intensive nature of BioNLP [\[42\]](#page-4-12). On the other hand, diversity in augmentations has proven to be a key metric benefiting low-resource NLP [\[3\]](#page-4-13).

<span id="page-0-0"></span><sup>1</sup>We call a generated augmentation counterfactual if it has a context-entity mismatch, e.g., a NE belonging to a skin disease is placed in the context of leg pain, Context not contributing to defining the NEs can take any form and promote diversity.

<span id="page-1-0"></span>![](_page_1_Figure_2.jpeg)

**Caption:** Figure 2 presents augmentation examples generated by BioAug compared to baseline methods on the EBMNLP and BC5DR datasets. The left side shows original and augmented sentences, while the right side provides explanations. BioAug consistently produces factually accurate and contextually relevant augmentations, highlighting its effectiveness.

Figure 1: Overview of BioAug: BioAug builds on BioBART [\[41\]](#page-4-14) and follows a 5-step sentence corruption process for fine-tuning: ○1 Keyword Extraction: We use a pre-trained entity extraction model to extract keywords from a sentence which we call keywords. ○2 Relation Extraction: We then use another pre-trained model to extract entity-entity, entity-NE, and NE-NE relations. ○3 Dynamic and Selective Masking: We randomly mask % of the keywords at each iteration. ○4 Sequence Linearization: We perform linearization and add label tokens before and after each NE token. ○5 Knowledge Augmentation: We verbalize extracted relations and concatenate them with the masked sentence as knowledge triples. Post fine-tuning, we corrupt a sentence following steps ○1 - ○4 and feed it to BioAug to generate diverse and factual augmentations.

Main Results. In this paper, we present BioAug, a novel data augmentation framework for low-resource biomedical NER. BioAug builds on the core idea of conditional generation and has 2 main steps, fine-tuning, and generation: (1) In the fine-tuning step, we use a pre-trained transformer-based auto-regressive Encoder-Decoder model (BioBart [\[41\]](#page-4-14) in our case) and fine-tune it on a novel text reconstruction or denoising task. Different from usual denoisingbased PLM pre-training objectives [\[6,](#page-4-15) [25\]](#page-4-16), which randomly mask tokens in the sentence to corrupt it, we perform selective masking and mask all tokens in the sentence except the ones belonging to the NEs and a small percentage of keywords. These keywords are other important tokens that belong to other entities extracted from an entity extraction model beyond the gold-annotated NEs and are selected randomly for each sentence at each training epoch. Additionally, to improve biomedical text understanding with highquality knowledge facts, which are difficult to learn from just raw text, we provide the model with contextually relevant external knowledge and train it to use this knowledge. To be precise, in the fine-tuning stage, together with the corrupted sentence, we concatenate knowledge triples in the form of inter-entity relations, which are obtained from a relation extraction (RE) model trained on a large-scale biomedical RE dataset. We explain our rationale behind every step in Section [3.1.](#page-2-1) (2) Post fine-tuning, to generate augmentations, we feed randomly corrupted training data to the model and ask the model to reconstruct sentences from it. Fig. [1](#page-1-0) shows a clear pictorial representation of BioAug fine-tuning and generation steps. In practice, BioAug generates augmentations that are both diverse and factual and outperforms all our baselines on benchmark BioNER datasets by a significant margin with absolute improvements in the range of 1.5% - 21.5%.

## 2 RELATED WORK

Bio-medical NER. Bio-medical NER is an emerging field of research with numerous systems proposed in the past decade [\[21,](#page-4-17) [23,](#page-4-18) [38\]](#page-4-19). Different from NER in the general domain, biomedical NER

suffers from (1) high semantic and syntactic complexity [\[19\]](#page-4-20), (2) knowledge-intensive nature with ever-growing biomedical concepts [\[19\]](#page-4-20), and (3) acute data scarcity [\[16\]](#page-4-7). To overcome these, researchers have proposed newer architectures [\[10\]](#page-4-21) or resorted to using knowledge-enhanced, or in-domain pre-trained PLMs [\[24,](#page-4-22) [31\]](#page-4-23). Contrary to this, data augmentation for low-resource BioNER, or NER in general, is a very under-explored problem in literature.

Data augmentation for low-resource NER. Data augmentation for low-resource NLP is a widely studied problem [\[9\]](#page-4-24). Most of these systems, when applied to the task of NER, suffer from token-label misalignment, thus demanding specially designed data augmentation techniques. Data augmentation for low-resource NER is a relatively under-studied problem, with systems built on simple word-level modifications like entity replacement [\[5\]](#page-4-10) or synonym replacement [\[5\]](#page-4-10) or sophisticated neural learning techniques like LSTM-based Language Modeling [\[7\]](#page-4-9), Masked Language Modeling with PLMs [\[44\]](#page-5-2), or auto-regressive language modeling using PLMs [\[28\]](#page-4-11). Systems built specifically for BioNER include [\[35\]](#page-4-8), which modifies the original entity replacement method from [\[5\]](#page-4-10) and replaces entities of the same type from sentences that are semantically similar to the original sentence. On similar lines, UMLS-EDA [\[16\]](#page-4-7) proposes to replace a UMLS concept from the original sentence and replace it with a randomly selected synonym from UMLS [\[27\]](#page-4-25). Though these systems perform well on benchmark datasets, we acknowledge that none of these systems explicitly focus on the factuality and diversity measures of generated augmentations.

## 3 METHODOLOGY

In this section, we give an overview of our proposed BioAug finetuning and generation approach. Fig. [1](#page-1-0) shows a pictorial representation of the entire workflow. A sentence from our training dataset is first passed through a series of pre-processing steps, and the sentence is corrupted and augmented with external factual knowledge for BioAug fine-tuning. Next, for generating augmentations, the

<span id="page-2-0"></span>

| Original      | The authors assessed the [safety]OUTCOME and [effectiveness]OUTCOME of [atomoxetine]INTERVENE monotherapy<br>compared with combined [atomoxetine/fluoxetine therapy]INTERVENE in a [population of children and<br>adolescents with ADHD and concurrent symptoms of anxiety]PATIENT .                                                                                          |  The sentence describes a study on the effects of atomoxetine<br>monotherapy on children and ADHD-impacted adolescents.                                                                                          |  |
|---------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|
| SR-UMLS [16]  | The generator tax the [prophylactic]OUTCOME and [potency]OUTCOME of [atomoxetine]INTERVENE monotherapy<br>compared with combined [atomoxetine/fluoxetine therapy]INTERVENE in [universe of minor and teen with<br>ADHD and coincidental symptoms of anxiousness]PATIENT .                                                                                                     | × SR-UMLS replaces words with their synonyms, changing the<br>context and meaning of the sentence, as can be seen in the<br>replacement of 'assessed' with 'tax' and 'safety' with 'prophylactic'.                |  |
| MELM [44]     | The authors undertook this study to further evaluate the [level of adenosine deaminase (ADA)]OUTCOME in<br>[patients with chronic schizophrenia]PATIENT treated with [monotherapy of haloperidol, risperidone or<br>clozapine]INTERVENE and correlation between the [ADA level]OUTCOME with response to treatment.                                                            | × MELM replaces the named entities with newly generated entities<br>that do not correspond to real-world entities. This results in<br>factually incorrect generations, as seen in the given sentence.             |  |
| BioAUG (ours) | The present study assessed the [safety]OUTCOME and [effectiveness]OUTCOME of [atomoxetine]INTERVENE therapy<br>compared with a combination of [atomoxetine and fluoxetine]INTERVENE in the same [population of children<br>participants and adolescents with ADHD]PATIENT ( n = 60 ), and these two groups were also compared in terms of<br>the frequency of these symptoms. |  BioAUG generates factually correct augmentations. Unlike other<br>systems, it places all entities in the right context.                                                                                         |  |
|               |                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                                                                                                   |  |
| Original      | During an 18-month period of study 41 hemodialyzed patients receiving [desferrioxamine]CHEMICAL (10-40 mg/kg<br>BW/3 times weekly) for the first time were monitored for detection of [audiovisual toxicity]DISEASE .                                                                                                                                                         |  The first sentence describes a study of patients receiving a drug<br>for the first time and being monitored for the disease.                                                                                    |  |
| SR-UMLS [16]  | During an 18-month menstruation of survey 41 hemodialyzed patients find [desferrioxamine]CHEMICAL (10-forty<br>magnesium/kilogram bw/triplet times weekly) for the showtime time were monitored for detecting of [audiovisual<br>perniciousness]DISEASE .                                                                                                                     | × UMLS-EDA replaces words with their synonyms, changing the<br>context and meaning of the sentence, as can be seen in the<br>replacement of 'period' with 'menstruation' and 'toxicity' with<br>'perniciousness.' |  |
| MELM [44]     | During an 18-month period of study 41 hemodialyzed patients receiving [glucoferriopamine]CHEMICAL (10-40 mg/kg<br>BW/3 times weekly ) for the first time were monitored for detection of [administration cycloone]DISEASE .                                                                                                                                                   | × MELM replaces the named entities with newly generated entities<br>that do not correspond to real-world entities. This results in<br>factually incorrect generations, as seen in the given sentence.             |  |
|               | BioAUG (ours) During a 12-month period , the study population consisted of 50 hemodialyzed patients receiving<br>[desferrioxamine]CHEMICAL , who were monitored for [audiovisual toxicity]DISEASE .                                                                                                                                                                           |  BioAUG generates factually correct augmentations. Unlike other<br>systems, it places all entities in the right context.                                                                                         |  |

Figure 2: Augmentation examples (left) on the EBMNLP dataset (top) and BC5DR dataset (bottom) and their explanations (right). Words in red are Named Entities, and words underlined are keywords. BioAug generates augmentations that are both more factual and diverse.

training samples are corrupted similarly to fine-tuning, and the finetuned BioAug is conditioned on the corrupted text to generate new augmentations. These generated augmentations are finally added to the training data, followed by fine-tuning a simple transformer model for token-level NER.

#### <span id="page-2-1"></span>3.1 Training BioAug

(1) Keyword Extraction. For each sentence in our training dataset with gold NE annotations, we first extract keywords from our sentence that provides contextually relevant knowledge about the target NE (e.g., in Figure [1](#page-1-0) "mutation" and "frequency" are important keywords that define the NEs HNPCC and Colorectal Cancer). To achieve this, we use a pre-trained entity extraction model to extract all possible entities from the sentence. Note that for our work, entities differ from the actual annotated NEs - we define entities as domain-specific phrases in the sentence with one or multiple tokens that are not NEs but deemed to be important in the context of the sentence. Extracting these entities ensures that while corrupting our sentence (described in later paragraphs), we retain words that help a model understand the true word sense of linguistically complex biomedical NEs. We use SciSpaCy [\[33\]](#page-4-26) as our pre-trained entity extraction model.

(2) Relation Extraction as Additional External Knowledge. As discussed earlier, knowledge-intensive tasks like BioNER benefit greatly from storing factual knowledge in their parameters. Though retaining extra entities in a sentence around the NE for text denoising provide additional local context to the model, to provide better global context and enhance its biomedical language understanding capabilities, we add knowledge facts to the corrupted sentence during fine-tuning in the form of entity-entity, entity-NE and NE-NE relation triplets. Augmenting additional external contextual knowledge for text denoising makes the model use and learn this knowledge during training, which in turn prevents the model from hallucinating [\[11,](#page-4-27) [40,](#page-4-28) [43\]](#page-4-29) thus allowing it to generate more factual augmentations. Our knowledge augmentation procedure has similarities with knowledge-augmented LM training systems

in literature [\[17,](#page-4-30) [43\]](#page-4-29) but differs in one key area - unlike prior systems in literature that use knowledge graph neighbors of entity mentions in the sentence as knowledge triples, we use domainspecific biomedical relations between entities as knowledge triples (example in Fig. [1\)](#page-1-0). Doing this is better suited for our denoising task and allows us to filter knowledge irrelevant to the sentence. To extract these relations, we train a simple relation extraction model [\[12\]](#page-4-31) on a large-scale biomedical relation extraction dataset built in an unsupervised manner using UMLS Metathesaurus knowledge graph [\[2\]](#page-4-32) on PubMed abstracts [\[32\]](#page-4-33). For more details on building the RE dataset, we refer our readers to [\[13\]](#page-4-34).

(3) Dynamic & Selective Masking. Out of all the entities in a sentence identified by SciSpaCy, we first remove the entities that overlap with the original NE and randomly select e% of the remaining entities which we call keywords. e is sampled from a from a Gaussian distribution N (, <sup>2</sup> ), where the Gaussian variance is set to 1/ and is the total number of entities identified by SciSpaCy. Next, we mask all other tokens in the sentence except the NEs and the identified entities and merge consecutive mask tokens.

(4) Sequence Linearization. Post selective masking, inspired by various works in literature [\[7,](#page-4-9) [44\]](#page-5-2), we perform sequence linearization and add label tokens before and after each NE token and treat that as the normal context in the sentence. This helps the model to explicitly take label information into consideration.

(5) Knowledge Augmentation. Finally, only knowledge triples belonging to NE and entities left in the sentence are verbalized and concatenated to the masked and linearized sentence from the previous step. This leaves us with a total of 2 relations where is the total number of NEs and keywords in the sentence.

(6) Fine-tuning. For fine-tuning BioAug, we solve a text reconstruction or denoising task using BioBART, where given a corrupted sentence, BioBART learns to recover the entire linearized sentence.

#### 3.2 Augmentation Generation

Post fine-tuning BioAug on our novel text reconstruction task, we feed a corrupted sentence to BioAug to generate augmentation. We repeat this for times to generate × augmented samples and finally add this data to the training dataset for fine-tuning our final token classification NER model. Since we generate augmentations auto-regressively, we do top-k random sampling with beam search to boost generation diversity. Note that we do not add external knowledge to the corrupted sentence in this step.

## 4 EXPERIMENTS AND RESULTS

#### 4.1 Datasets

To prove the efficacy of BioAug, we experiment on 5 biomedical NER datasets, namely BC2GM [\[22\]](#page-4-35), BC5DR [\[26\]](#page-4-36), NCBI [\[8\]](#page-4-37), EBMNLP [\[34\]](#page-4-38), and JNLPBA [\[4\]](#page-4-39). BC2GM is annotated with gene mentions and has 15197/3061/6325 samples in train/dev/test sets, respectively. BC5DR is annotated with chemical and disease mentions and has 5228/5330/5865 samples in train/dev/test sets, respectively. NCBI is annotated with disease mentions and has 5432/787/960 samples in train/dev/test sets, respectively. EBMNLP is annotated with participants, interventions, comparisons, and outcomes spans and has 35005/10123/6193 samples in train/dev/test sets, respectively. JNLPBA is annotated with chemical mentions and has 46750/4551/8662 samples in train/dev/test sets, respectively. For low-resource NER, we sample 100, 200, and 500 sentences from the training dataset and downsample the dev dataset proportionately. We evaluate our NER models on the entire test dataset for all our experiments.

#### 4.2 Experimental Setup and Baselines

Experimental Setup. For BioAug, we use BioBART-large [\[41\]](#page-4-14) as our auto-regressive PLM. We fine-tune BioAug for 10 epochs with a batch size of 16 using Adam optimizer [\[20\]](#page-4-40) with a learning rate of 1 5 . For NER, we use BioBERT-large [\[24\]](#page-4-22) with a linear head and follow the token-level classification paradigm using the flair framework [\[1\]](#page-4-41). We train all our models for 100 epochs with a batch size of 16 using Adam optimizer with a learning rate of 1 2 .

Baselines. Gold-only is NER trained on only gold-annotated data from the respective datasets and low-resource splits without any added augmentation. SR-UMLS [\[16\]](#page-4-7) or Synonym Replacement with UMLS, identifies all the UMLS concepts in the sentence and randomly replaces one concept with a randomly selected synonym from UMLS. DAGA [\[7\]](#page-4-9) or Data Augmentation with a Generation Approach, trains a single-layer LSTM-based recurrent neural network language model (RNNLM) by optimizing for nexttoken prediction with linearized sentences. At the generation step, DAGA uses random sampling to generate entirely new sentences auto-regressively. MulDA [\[28\]](#page-4-11) or Multilingual Data Augmentation Framework, is trained on a similar objective to DAGA but using BART instead of RNNLM. MELM [\[44\]](#page-5-2) or Masked Entity Language Modeling, fine-tunes a transformer-encoder-based PLM using masked language modeling on linearized sentences. MELM outperforms all other prior art on low-resource settings on the CoNLL 2003 dataset.

### 4.3 Results and Analysis

Quantitative Analysis. Table [1](#page-3-0) reports the average micro-averaged F1 over 3 runs with 3 different random seeds for BioAug and all

<span id="page-3-0"></span>Table 1: Result comparison on 5 benchmark BioNER datasets across 4 dataset size settings. BioAug outperforms all our baselines.

| #Size | Model         | BC2GM | BC5DR | NCBI  | EBMNLP | JNLPBA | Avg.  |
|-------|---------------|-------|-------|-------|--------|--------|-------|
| 100   | Gold Only     | 56.94 | 74.90 | 72.99 | 18.81  | 44.37  | 53.60 |
|       | DAGA          | 38.63 | 60.96 | 58.26 | 17.48  | 43.85  | 43.84 |
|       | MulDA         | 39.67 | 62.35 | 59.56 | 20.32  | 45.66  | 45.51 |
|       | SR-UMLS       | 54.83 | 75.64 | 68.35 | 21.68  | 55.66  | 55.23 |
|       | MELM          | 48.56 | 74.70 | 65.74 | 24.64  | 50.32  | 52.79 |
|       | BioAug (ours) | 60.17 | 77.58 | 75.14 | 27.35  | 60.00  | 60.05 |
| 200   | Gold Only     | 62.16 | 76.08 | 76.02 | 23.96  | 54.26  | 58.50 |
|       | DAGA          | 48.95 | 68.69 | 70.92 | 23.53  | 53.58  | 53.13 |
|       | MulDA         | 50.11 | 69.35 | 72.28 | 25.37  | 55.28  | 54.48 |
|       | SR-UMLS       | 62.88 | 78.18 | 74.43 | 27.14  | 63.59  | 61.24 |
|       | MELM          | 58.78 | 79.06 | 73.49 | 21.19  | 58.18  | 58.14 |
|       | BioAug (ours) | 67.17 | 80.30 | 78.33 | 29.66  | 65.40  | 64.17 |
|       | Gold Only     | 65.97 | 82.55 | 80.18 | 31.48  | 62.04  | 64.44 |
|       | DAGA          | 53.95 | 76.60 | 78.70 | 32.41  | 61.72  | 60.68 |
|       | MulDA         | 54.92 | 78.04 | 79.92 | 33.53  | 62.63  | 61.81 |
| 500   | SR-UMLS       | 65.43 | 82.70 | 79.16 | 32.92  | 65.36  | 65.11 |
|       | MELM          | 58.78 | 81.19 | 75.49 | 32.26  | 61.64  | 61.87 |
|       | BioAug (ours) | 70.61 | 84.48 | 80.64 | 37.94  | 68.07  | 68.35 |
|       | Gold Only     | 82.33 | 89.01 | 87.33 | 42.98  | 74.36  | 75.20 |
|       | DAGA          | 79.62 | 86.69 | 85.15 | 42.46  | 72.52  | 73.29 |
|       | MulDA         | 80.21 | 87.55 | 86.93 | 44.54  | 73.78  | 74.60 |
| All   | SR-UMLS       | 82.18 | 88.48 | 84.66 | 45.75  | 74.93  | 75.20 |
|       | MELM          | 81.46 | 89.18 | 83.95 | 40.38  | 73.82  | 73.76 |
|       | BioAug (ours) | 83.83 | 89.33 | 88.14 | 47.26  | 75.49  | 76.81 |

our baselines. As clearly evident, BioAug outperforms all our baselines and achieves absolute improvement in the range of 1.5%-21.5%. PLM-based baselines (DAGA, MulDA and MELM) under-perform across all settings, which we attribute to the lack of inadequate knowledge for generating factual augmentations. On the contrary, though PLM-based, BioAug generates effective augmentations due to the local and global context provided to it during fine-tuning. Table [2](#page-3-1) compares generated augmentations on the quantitative measures of perplexity and diversity. Perplexity [\[14\]](#page-4-42), calculated using BioGPT [\[31\]](#page-4-23), can also be seen as a measure of factuality. We calculate two measures of diversity - the average absolute length difference between actual and generated samples (Diversity-L) and the average percentage of new tokens in augmentations (Diversity). BioAug outperforms all prior art in all these metrics.

Qualitative Analysis. Fig. [2](#page-2-0) shows an example of augmentations generated from our baselines and BioAug. As clearly evident, BioAug generated augmentations that are both more factual and diverse.

<span id="page-3-1"></span>Table 2: Quantitative evaluation of generation quality from various systems on the measures of perplexity and diversity.

| #Gold | Method        | Perplexity(↓) | Diversity(↑) | Diversity-L(↑) |
|-------|---------------|---------------|--------------|----------------|
|       | SR-UMLS       | 115.76        | 14.65        | 2.38           |
| 100   | MELM          | 110.50        | 15.83        | 0.0            |
|       | BioAug (ours) | 39.69         | 47.88        | 9.074          |
|       | SR-UMLS       | 110.23        | 15.33        | 2.56           |
| 200   | MELM          | 97.78         | 18.65        | 0.0            |
|       | BioAug (ours) | 32.45         | 45.67        | 9.67           |
|       | SR-UMLS       | 102.55        | 14.98        | 2.42           |
| 500   | MELM          | 94.65         | 14.87        | 0.0            |
|       | BioAug (ours) | 31.14         | 44.72        | 10.17          |

## 5 CONCLUSION AND LIMITATIONS

In this paper, we propose BioAug, a novel data augmentation framework for low-resource BioNER. BioNER is fine-tuned on a novel text reconstruction task and is able to generate diverse and factual augmentations for BioNER. We empirically show that augmentations generated by BioAug prove to be extremely effective for low-resource BioNER. As part of future work we would tackle BioAug's limitation of not introducing new NEs in augmentations. BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER SIGIR '23, July 23–27, 2023, Taipei, Taiwan

#### REFERENCES

- <span id="page-4-41"></span>[1] Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, and Roland Vollgraf. 2019. FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations). Association for Computational Linguistics, Minneapolis, Minnesota, 54–59. [https://doi.org/10.](https://doi.org/10.18653/v1/N19-4010) [18653/v1/N19-4010](https://doi.org/10.18653/v1/N19-4010)
- <span id="page-4-32"></span>[2] Razvan Bunescu and Raymond Mooney. 2007. Learning to extract relations from the web using minimal supervision. In Proceedings of the 45th annual meeting of the association of computational linguistics. 576–583.
- <span id="page-4-13"></span>[3] Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, and Diyi Yang. 2021. An empirical survey of data augmentation for limited data learning in NLP. arXiv preprint arXiv:2106.07499 (2021).
- <span id="page-4-39"></span>[4] Nigel Collier and Jin-Dong Kim. 2004. Introduction to the bio-entity recognition task at JNLPBA. In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications (NLPBA/BioNLP). 73–78.
- <span id="page-4-10"></span>[5] Xiang Dai and Heike Adel. 2020. An analysis of simple data augmentation for named entity recognition. arXiv preprint arXiv:2010.11683 (2020).
- <span id="page-4-15"></span>[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).
- <span id="page-4-9"></span>[7] Bosheng Ding, Linlin Liu, Lidong Bing, Canasai Kruengkrai, Thien Hai Nguyen, Shafiq Joty, Luo Si, and Chunyan Miao. 2020. DAGA: Data augmentation with a generation approach for low-resource tagging tasks. arXiv preprint arXiv:2011.01549 (2020).
- <span id="page-4-37"></span>[8] Rezarta Islamaj Doğan, Robert Leaman, and Zhiyong Lu. 2014. NCBI disease corpus: a resource for disease name recognition and concept normalization. Journal of biomedical informatics 47 (2014), 1–10.
- <span id="page-4-24"></span>[9] Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard Hovy. 2021. A survey of data augmentation approaches for NLP. arXiv preprint arXiv:2105.03075 (2021).
- <span id="page-4-21"></span>[10] Mourad Gridach. 2017. Character-level neural network for biomedical named entity recognition. Journal of biomedical informatics 70 (2017), 85–91.
- <span id="page-4-27"></span>[11] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020. REALM: Retrieval-Augmented Language Model Pre-Training. In Proceedings of the 37th International Conference on Machine Learning (ICML'20). JMLR.org, Article 368, 10 pages.
- <span id="page-4-31"></span>[12] Xu Han, Tianyu Gao, Yuan Yao, Deming Ye, Zhiyuan Liu, and Maosong Sun. 2019. OpenNRE: An Open and Extensible Toolkit for Neural Relation Extraction. In Proceedings of EMNLP-IJCNLP: System Demonstrations. 169–174. [https://doi.org/](https://doi.org/10.18653/v1/D19-3029) [10.18653/v1/D19-3029](https://doi.org/10.18653/v1/D19-3029)
- <span id="page-4-34"></span>[13] William Hogan, Molly Huang, Yannis Katsis, Tyler Baldwin, Ho-Cheol Kim, Yoshiki Vazquez Baeza, Andrew Bartko, and Chun-Nan Hsu. 2021. Abstractified multi-instance learning (amil) for biomedical relation extraction. arXiv preprint arXiv:2110.12501 (2021).
- <span id="page-4-42"></span>[14] Fred Jelinek, Robert L Mercer, Lalit R Bahl, and James K Baker. 1977. Perplexity—a measure of the difficulty of speech recognition tasks. The Journal of the Acoustical Society of America 62, S1 (1977), S63–S63.
- <span id="page-4-1"></span>[15] Chen Jia, Xiaobo Liang, and Yue Zhang. 2019. Cross-Domain NER using Cross-Domain Language Modeling. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Florence, Italy, 2464–2474.<https://doi.org/10.18653/v1/P19-1236>
- <span id="page-4-7"></span>[16] Tian Kang, Adler Perotte, Youlan Tang, Casey Ta, and Chunhua Weng. 2021. UMLS-based data augmentation for natural language processing of clinical research literature. Journal of the American Medical Informatics Association 28, 4 (2021), 812–823.
- <span id="page-4-30"></span>[17] Jivat Kaur, Sumit Bhatia, Milan Aggarwal, Rachit Bansal, and Balaji Krishnamurthy. 2022. LM-CORE: Language Models with Contextually Relevant External Knowledge. In Findings of the Association for Computational Linguistics: NAACL 2022. Association for Computational Linguistics, Seattle, United States, 750–769. <https://doi.org/10.18653/v1/2022.findings-naacl.57>
- <span id="page-4-2"></span>[18] Donghyeon Kim, Jinhyuk Lee, Chan Ho So, Hwisang Jeon, Minbyul Jeong, Yonghwa Choi, Wonjin Yoon, Mujeen Sung, and Jaewoo Kang. 2019. A neural named entity recognition and multi-type normalization tool for biomedical text mining. IEEE Access 7 (2019), 73729–73740.
- <span id="page-4-20"></span>[19] Hyunjae Kim and Jaewoo Kang. 2022. How do your biomedical named entity recognition models generalize to novel entities? Ieee Access 10 (2022), 31513– 31523.
- <span id="page-4-40"></span>[20] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).
- <span id="page-4-17"></span>[21] Veysel Kocaman and David Talby. 2021. Biomedical named entity recognition at scale. In Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part I. Springer, 635–646.
- <span id="page-4-35"></span>[22] Martin Krallinger, Obdulia Rabal, Florian Leitner, Miguel Vazquez, David Salgado, Zhiyong Lu, Robert Leaman, Yanan Lu, Donghong Ji, Daniel M Lowe, et al. 2015. The CHEMDNER corpus of chemicals and drugs and its annotation principles. Journal of cheminformatics 7, 1 (2015), 1–17.
- <span id="page-4-18"></span>[23] Robert Leaman and Graciela Gonzalez. 2008. BANNER: an executable survey of advances in biomedical named entity recognition. In Biocomputing 2008. World Scientific, 652–663.
- <span id="page-4-22"></span>[24] Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. 2020. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics 36, 4 (2020), 1234–1240.
- <span id="page-4-16"></span>[25] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461 (2019).
- <span id="page-4-36"></span>[26] Jiao Li, Yueping Sun, Robin J Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis, Carolyn J Mattingly, Thomas C Wiegers, and Zhiyong Lu. 2016. BioCreative V CDR task corpus: a resource for chemical disease relation extraction. Database 2016 (2016).
- <span id="page-4-25"></span>[27] Donald AB Lindberg, Betsy L Humphreys, and Alexa T McCray. 1993. The unified medical language system. Yearbook of medical informatics 2, 01 (1993), 41–51.
- <span id="page-4-11"></span>[28] Linlin Liu, Bosheng Ding, Lidong Bing, Shafiq Joty, Luo Si, and Chunyan Miao. 2021. MulDA: A multilingual data augmentation framework for low-resource cross-lingual NER. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 5834–5846.
- <span id="page-4-0"></span>[29] Shengyu Liu, Buzhou Tang, Qingcai Chen, and Xiaolong Wang. 2015. Drug name recognition: approaches and resources. Information 6, 4 (2015), 790–810.
- <span id="page-4-3"></span>[30] Ling Luo, Zhihao Yang, Pei Yang, Yin Zhang, Lei Wang, Hongfei Lin, and Jian Wang. 2018. An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition. Bioinformatics 34, 8 (2018), 1381–1388.
- <span id="page-4-23"></span>[31] Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. 2022. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Briefings in Bioinformatics 23, 6 (09 2022). <https://doi.org/10.1093/bib/bbac409> arXiv[:https://academic.oup.com/bib/article](https://arxiv.org/abs/https://academic.oup.com/bib/article-pdf/23/6/bbac409/47144271/bbac409.pdf)[pdf/23/6/bbac409/47144271/bbac409.pdf](https://arxiv.org/abs/https://academic.oup.com/bib/article-pdf/23/6/bbac409/47144271/bbac409.pdf) bbac409.
- <span id="page-4-33"></span>[32] Jo McEntyre and Jim Ostell. 2002. The NCBI handbook. Bethesda (MD): National Center for Biotechnology Information (US) (2002).
- <span id="page-4-26"></span>[33] Mark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. 2019. ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing. In Proceedings of the 18th BioNLP Workshop and Shared Task. Association for Computational Linguistics, Florence, Italy, 319–327.<https://doi.org/10.18653/v1/W19-5034> arXiv[:arXiv:1902.07669](https://arxiv.org/abs/arXiv:1902.07669)
- <span id="page-4-38"></span>[34] Benjamin Nye, Junyi Jessy Li, Roma Patel, Yinfei Yang, Iain J Marshall, Ani Nenkova, and Byron C Wallace. 2018. A corpus with multi-level annotations of patients, interventions and outcomes to support language processing for medical literature. In Proceedings of the conference. Association for Computational Linguistics. Meeting, Vol. 2018. NIH Public Access, 197.
- <span id="page-4-8"></span>[35] Uyen Phan and Nhung Nguyen. 2022. Simple Semantic-based Data Augmentation for Named Entity Recognition in Biomedical Texts. In Proceedings of the 21st Workshop on Biomedical Language Processing. 123–129.
- <span id="page-4-5"></span>[36] Erik F Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. arXiv preprint cs/0306050 (2003).
- <span id="page-4-6"></span>[37] Larry Smith, Lorraine K Tanabe, Cheng-Ju Kuo, I Chung, Chun-Nan Hsu, Yu-Shi Lin, Roman Klinger, Christoph M Friedrich, Kuzman Ganchev, Manabu Torii, et al. 2008. Overview of BioCreative II gene mention recognition. Genome biology 9, 2 (2008), 1–19.
- <span id="page-4-19"></span>[38] Yiqi Tong, Fuzhen Zhuang, Deqing Wang, Haochao Ying, and Binling Wang. 2022. Improving Biomedical Named Entity Recognition with a Unified Multi-Task MRC Framework. In ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 8332–8336. [https://doi.org/10.](https://doi.org/10.1109/ICASSP43922.2022.9746482) [1109/ICASSP43922.2022.9746482](https://doi.org/10.1109/ICASSP43922.2022.9746482)
- <span id="page-4-4"></span>[39] Yanshan Wang, Sunghwan Sohn, Sijia Liu, Feichen Shen, Liwei Wang, Elizabeth J Atkinson, Shreyasee Amin, and Hongfang Liu. 2019. A clinical text classification paradigm using weak supervision and deep representation. BMC medical informatics and decision making 19 (2019), 1–13.
- <span id="page-4-28"></span>[40] Sondre Wold. 2022. The Effectiveness of Masked Language Modeling and Adapters for Factual Knowledge Injection. arXiv preprint arXiv:2210.00907 (2022).
- <span id="page-4-14"></span>[41] Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, and Sheng Yu. 2022. BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model. In Proceedings of the 21st Workshop on Biomedical Language Processing. Association for Computational Linguistics, Dublin, Ireland, 97–109. <https://doi.org/10.18653/v1/2022.bionlp-1.9>
- <span id="page-4-12"></span>[42] Taolin Zhang, Zerui Cai, Chengyu Wang, Minghui Qiu, Bite Yang, and Xiaofeng He. 2021. SMedBERT: A knowledge-enhanced pre-trained language model with structured semantics for medical text mining. arXiv preprint arXiv:2108.08983 (2021).
- <span id="page-4-29"></span>[43] Taolin Zhang, Zerui Cai, Chengyu Wang, Minghui Qiu, Bite Yang, and Xiaofeng He. 2021. SMedBERT: A Knowledge-Enhanced Pre-trained Language Model with Structured Semantics for Medical Text Mining. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th

<span id="page-5-0"></span>SIGIR '23, July 23–27, 2023, Taipei, Taiwan Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, & Dinesh Manocha

International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Association for Computational Linguistics, Online, 5882–5893. [https:](https://doi.org/10.18653/v1/2021.acl-long.457) [//doi.org/10.18653/v1/2021.acl-long.457](https://doi.org/10.18653/v1/2021.acl-long.457)

<span id="page-5-2"></span>[44] Ran Zhou, Xin Li, Ruidan He, Lidong Bing, Erik Cambria, Luo Si, and Chunyan Miao. 2022. MELM: Data Augmentation with Masked Entity Language Modeling for Low-Resource NER. In Proceedings of the 60th Annual Meeting

of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Dublin, Ireland, 2251–2262. [https:](https://doi.org/10.18653/v1/2022.acl-long.160) [//doi.org/10.18653/v1/2022.acl-long.160](https://doi.org/10.18653/v1/2022.acl-long.160)

<span id="page-5-1"></span>[45] Wenxuan Zhou and Muhao Chen. 2021. Learning from noisy labels for entitycentric information extraction. arXiv preprint arXiv:2104.08656 (2021).